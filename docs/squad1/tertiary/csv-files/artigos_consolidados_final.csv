ID,Artigo,Ano,Score Total,Fonte,Q1,Q2,Q3,Q4,Q5,Q6,Q7,Quem extraiu,Autores,País,Afiliação,Veículo de Publicação,Tipo ,"Quais são as contribuições da Engenharia de Software (ES) em estudos de IA ou ML (técnicas, processos, ferramentas, métricas)?",Atividade de Engenharia de Software,Quais são as técnicas de IA gen exploradas em estudos de ES?,"Quais são os Modelos de Aprendizado de Máquina (MLMs), Modelos de Aprendizado de Máquina (SLMs), prompts e arquiteturas explorados em IA gen para estudos de ES?",Tipo do Modelo,Modelo de IA Generativa,Técnica utilizada,Tamanho do modelo (em parametros),	Acesso,Quais são as ferramentas que dão suporte à IA gen para estudos de ES?,Quais técnicas de avaliaçãoção são exploradas em IA gen para estudos de ES?,Métricas utilizadas,Benefícios em usar genAI para ES,Limitações de usar genAI para ES,Lacunas (oportunidades de pesquisa) para usar genAI para ES,Trabalhos Futuros indicados no artigo, Desafios de usar genAI para ES,Outros comentários,Trechos interessantes do artigo
A1,A Catalog of Data Smells for Coding Tasks,2025,5.0,Scopus,Partially attended to,Fully attended to,Not attended to,Fully attended to,Fully attended to,Partially attended to,Fully attended to,Heitor e Henrique da Rocha Lima,"Antonio Vitale, Rocco Oliveto, e Simone Scalabrino",Itália,"Automatica e Informatica, Politecnico di Torino, Torino, Italy and Department ofBiosciences and Territory, University of Molise, Pesche, Italy",ACM Transactions on Software Engineering and Methodology (TOSEM),journal,"O estudo identifica como oportunidade futura a aplicação de princípios da Engenharia de Software para a engenharia sistemática de dados, visando mitigar data smells em datasets de pré-treinamento, fine-tuning e benchmarks. Essa abordagem busca reduzir vieses de avaliação e melhorar a confiabilidade e generalização de modelos de IA generativa aplicados à Engenharia de Software.",Construção/Codificação,"Fine-Tuning,","- O estudo focou na arquitetura Tranformer das redes neurais profundas, com trechos explicando com sua estrutura funciona, apresentando então sobre o pré-processamento e o fine-tuning do modelo e qual a relação com os data smells (dados com ""odores"" ruins). O estudo não faz comparação entre modelos específicos (ex.: GPT-3 vs Codex vs CodeBERT). O foco está no uso geral de LLMs, não em arquiteturas individuais.

- O estudo não reporta o uso de Small Language Models (SLMs)

- Prompts não são analisados nem caracterizados.",LLM,"GPT-x, Llama, outros",,,,Não se aplica,"Avaliação baseada em benchmarks de tarefas de codificação e métricas de desempenho reportadas nos estudos primários.

O estudo não explora técnicas alternativas ou avançadas de avaliação.",outros,"O estudo reconhece que modelos de IA generativa são amplamente utilizados para automatizar e apoiar tarefas de codificação como geração de código, correção de bugs, refatoração, tradução de código, sumarização e revisão de código.","O estudo apresenta limitações nas atividades atreladas a codificação, como refatoração de código, correção de código,revisão de código, tradução de código, sumarização de código, completação de código, entre outros. Ao longo do estudo, é determinado que os LLMs, em especificos os de arquitetura Transformer, ao trabalhar com codificação, tende a gerar saídas com qualidade inferior devido os ""data smells"", que são dados com uma qualidade ruim. De acordo com o estudo, quando um Transformer, seja na etapa de pré-processamento ou na etapa de fine-tuning, tem esse tipo de dado para realizar seu treinamento, ele tende a gerar códigos sub-ótimos ou não funcionais.","1 - Falta de evidência empírica sobre o impacto real dos data smells
2 - Ausência de análise sistemática de data smells em datasets amplamente usados
3 - O catálogo foi construído focando Transformers, e alguns data smells podem não ser diretamente transferíveis para outras arquiteturas.
4 - Falta de benchmarks livres de data smells para avaliação justa
5 - Algumas tarefas importantes de ES ignoram completamente certos tipos de data smells, mesmo sendo tarefas amplamente estudadas.","1 - ""Updating existing pre-trained LLMs for coding tasks on cleaned versions of existingdatasets (e.g., CodeSearchNet) might have benefits for most future works.""
2 - "" It is essential to investigate the diffusion of data smells in widely used datasets.""
3 - ""Even when empirical evidence is provided that specific data smells negatively affect themodel, much more work is needed to enrich our knowledge on what effects they might haveand what benefits it could bring removing them. Future work should aim to empiricallyanalyze how most of the data smells of code-related tasks affect training.""
4 - ""Future work should aim at devising more precise strategies for detecting data smellsand more advanced procedures for improving the quality of datasets. Such work shouldrigorously validate both the detection and fixing procedures.""
5 - ""Future work should investigate the impact of data smells on non-functional aspects, suchas training time, sustainability, robustness, security, and performance.""","1 - Antes deste estudo, não existia um catálogo específico de data smells para tarefas de programação, dificultando ações sistemáticas de mitigação. 
2 - Limpar, filtrar e manter datasets livres de data smells exige tempo, esforço humano e recursos computacionais. 
3 - Embora filtros de qualidade sejam amplamente usados, não se sabe claramente o quanto eles realmente melhoram os modelos.","- Para a etapa de pré-treinamento, os tipos de data smells mais abordados foram Limited Informativeness e as Instâncias (Quase) Duplicadas. ""More specifically, as for the pre-training stage, we observed that Limited Informativeness and the (Near) Duplicated Instances categories are the most addressed data smells. - pag 20""

-  ""A categoria mais abordada é a de Instâncias (Quase) Duplicadas (41%), seguida por Informatividade Limitada (37%) e Problemas de Qualidade do Código-Fonte (31%). Por outro lado, Repositórios de Código Inadequados (Inadequate Source Repositories) (16%) e Vazamento de Dados (Data Leakage) (10%) são as menos abordadas. Isso levanta preocupações quanto à avaliação real da eficácia dos modelos, que pode superestimar seu desempenho em um cenário do mundo real."" -> ""The most addressed is the (Near) Duplicated Instances category (41%), followed by Limited Informativeness (37%), and Source Code Quality Issues (31%). On the other hand, Inadequate Source Repositories (16%)","""The most addressed is the (Near) Duplicated Instances category (41%), followed by Limited Informativeness (37%), and Source Code Quality Issues (31%). On the other hand, Inadequate Source Repositories (16%) and Data Leakage (10%) are the less addressed ones. This raises concerns regarding the actual evaluation of the models effectiveness, which may overestimate their performance in a real-world setting - pag 20""

"" The last row, instead, reports the number of papers by task. It is worth noting that, for some tasks, the large majority of papers use some categories of quality filters. For example, almost all the papers (8 out of 12) tackling the Code Completion task use quality filters to address Limited Informativeness smells. On the other hand, some smells are not taken into account at all for some tasks. An example is given by the Data Leakage category, which has never been addressed for the Bug-Fixing task. Similarly, Data Distribution Issues has never been taken into account for t"
A2,A Pilot Study on AI-Assisted Code Generation with Large Language Models for Software Engineering,2024,0.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Brenno - EC1 - Full text not avaliable for free on the Web or on the CAPES Periódicos platform,,,,,,,,,,,,,,,,,,,,,,,,
A3,A Review of Reasoning in Artificial Agents using Large Language Models,2025,0.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,"Filipe Campos Matunaga Batista - Excluído (EC4: Does not address genAI for SE activities).
Ana Karolina - Excluído (EC4: Does not address genAI for SE activities)",Nagraj Naidu e Omar El-Gayar,Estados Unidos,Dakota State University,Proceedings of the 58th Hawaii International Conference on System Sciences | 2025,journal,,,,,,,,,,,,,,,,,,,
A4,A Survey of Natural Language-Based Editing of Low-Code Applications Using Large Language Models,2024,0.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,"Ana Karolina (EXCLUÍDO: EC1: Full text not available for free on the Web or on the CAPES Periódicos plataform)
Filipe Campos (EXCLUÍDO: EC1: Full text not available for free on the Web or on the CAPES Periódicos plataform)","Gorissen, Simon Cornelius; Sauer, Stefan; Beckmann, Wolf G.",Alemanha,"SICP Software Innovation Lab and Computer Science Department, Paderborn University, Warburger Str. 100, Paderborn, 33098, Germany",Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics),conference,,,,,,,,,,,,,,,,,,,
A5,A Systematic Literature Review of 10 years of Research on Program Synthesis and Natural Language Processing,2024,6.5,Scopus,Partially attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Brenno,"Ramirez-Rueda, Rolando and Benítez-Guerrero, Edgard and Mezura-Godoy, Carmen and Bárcenas, Everardo",México,Facultad de Ingeniería Universidad Nacional Autónoma de México,Programming and Computer Software,conference,"Como destacado no artigo, a Engenharia de Software (ES) contribui fornecendo a estrutura do ciclo de vida de desenvolvimento, incluindo especificação de requisitos, design, prototipagem e testes. Além disso utiliza modelos de abstração para facilitar a geração automática de códigos e utiliza técnicas para avaliação da qualidade dos resultados da IA, como pode ser observado no trecho ""The development of a software system encompasses a detailed life cycle that includes stages such as requirement specification, design, prototyping, and testing."" - Pág. 1","Construção/Codificação, Gestão de projeto, Requisitos, Testes","Como ponto focal do artigo, as técnicas exploradas são de síntese indutiva e dedutiva, processamento de linguagem natural (NLP) e programação genética guiada por gramática (evolução do código até chegar ao resultado desejado) - ""Program synthesis employs distinct methods, primarily classified into deductive and inductive synthesis...""","O estudo foca bastante em Modelos de Linguagem de Larga Escala (LLMs), explorando principalmente o uso de prompts de programação para guiar a IA na geração de código, destaque para o trecho ""..exploration of models like GPT-4 and other advanced transformer architectures to understand how they can be adapted for interpreting natural language program specifications."" mostrando o uso de ferramentas como o CPT-4 nesse estudo.","LLM, multimodal","GPT-x, outros",prompt engineering,,comercial,"Como suporte para a IA foi tido ferramentas interativas de síntese de programas (Jigsaw e HISyn), algumas plataformas de criação de bots e ambientes de desenvolvimento integrado (IDES) que possuem ferramentas de snippets de código.","Foi aplicado casos testes (como a execução do código gerado), análise estatística de padrões de uso de código e mediação de similaridade","custo, precisão, produtividade, qualidade, segurança","Como benefícios, foram destacados no artigo o aumento da eficiência do desenvolvedor, a democratização do desenvolvimento de software para pessoas de fora da área através da elaboração de requisitos por linguagem humana e automação de tarefas repetitivas e rotineiras","Muita ambiguidade no que se refere a linguagem natural, dificuldade em interpretar requisitos e a necessidade de alto poder computacional para verificar especificações completas. Destacado no trecho - ""The research problem centers on the complexity of automatically generating accurate and robust code from high-level, ambiguous natural language descriptions...""","A principal lacuna identificada foi a de interpretação da linguagem. natural, o que garantiria um desenvolvimento mais rápido e fácil do software, pois hoje ainda demanda um alto poder computacional e a genIA apresenta dificuldades nessa interpretação","1- Melhoria de interpretabilidade e confiança
2- Modelos de domínio específicos
3- Escalabilidade e Eficiência
4- Técnicas de desambiguação","Apesar da genIA representar o futuro para a ES, o artigo mostrou que muitos desafios ainda permeiam esse cenário, dentre eles o fato de como fazer a máquina entender de maneira mais clara e fácil a linguagem natural, para assim, facilitar as etapas de transformação dos requisitos em trechos de código, o que foi notado que em vários cenários, precisa-se de uma escalabilidade muito grande para chegar ao que se espera de um requisito, destaca-se também o fato de que esses trechos são mais sucetíveis a erros do que quando o profissional interpreta e transforma o requisito","Achei interessante a forma como o artigo aborda a genIA tratando-a como uma maneira de democratizar a criação de software, destacando que através dela muitas pessoas que não são da área podem se aventurar para criar aplicações e códigos, isso pode estimular cada vez mais pessoas a ingressar nesse mundo e trará muitos avanços para a ES. E também a forma como aborda o quesito da ética nessa democratização.","""The synthesis of programs through natural language represents a significant advance in software engineering, aiming to democratize software development by allowing non-expert users to create programs from high-level descriptions.""

""Improving the accessibility and usability of applications through natural language interfaces is a promising field that could revolutionize human-computer interaction."" - destaca que em trabalhos futuros o objetivo é torna mais acessível essa tecnologia"
A6,A Systematic Literature Review of Large Language Model Applications in Industry,2025,6.0,Scopus,Fully attended to,Fully attended to,Partially attended to,Partially attended to,Fully attended to,Fully attended to,Fully attended to,Jeniffer e Leonardo,"Norbert Moenks, Pascal Penava, Ricardo Buettner",Alemanha,"Chair of Hybrid Intelligence, Helmut-Schmidt-University/University of the Federal Armed Forces Hamburg",IEEE Access,journal,"Técnicas: Integração de LLMs em sistemas empresariais, geração de código, teste automatizado, geração de documentação.
Processos: Automação de workflows de desenvolvimento, suporte à tomada de decisão, otimização de processos industriais.
Ferramentas: Frameworks para LLMs em manufatura, assistentes de código (GitHub Copilot), agentes autônomos baseados em LLM.
Métricas: Eficiência operacional, qualidade de código, redução de tempo de desenvolvimento, precisão em diagnósticos.","Construção/Codificação, Design, Manutenção, Operações/DevOps, Requisitos, Testes","Sistemas multiagentes; engenharia de prompts (implícita em interações de agentes); aprendizado autossupervisionado; chain of thought (via raciocínio multiturnos em agentes). A revisão abrange IA generativa para automação industrial, incluindo geração de código e otimização de processos, que se intersectam com ES (ex.: agentes LLMs para suporte a decisões em indústrias intensivas em software, como sistemas de energia).","MLMs/SLMs: Tongyi Qianwen, Wenxin, Baichuan-13B, ChatGLM-6B (LLMs de tamanho médio em Chen et al. [3]); GPT-4-Turbo, GPT-3.5-Turbo, Claude-2.1 (em Arnautov e Akimov [34]). Prompts: Não detalhados explicitamente, mas implícitos em sugestões e verificações de agentes (ex.: prompting para melhorias em redes). Arquiteturas: Causal Decoder (ex.: modelos GPT), Encoder-Decoder (ex.: T5 ou BART mencionados em preliminares), Prefix Decoder (ex.: modelos GLM), Autoregressive. A revisão classifica arquiteturas de LLMs e nota seu uso em tarefas relacionadas a ES, como simulação de código e otimização.",LLM,"Claude, GPT-x, Llama","chain of thought, multiagent, outros, prompt engineering",7000000000.0,"comercial, open source","GitHub Copilot
LangChain
Frameworks de automação (RPA integrado a LLMs)
Sistemas de banco de dados vetoriais (para RAG)
Ferramentas de teste automatizado baseadas em LLM","Testes empíricos em casos de uso reais; 
Análise comparativa entre LLMs (ex.: médio vs. grande modelos);
Experimentos fictícios (ex.: otimização de sistemas de energia); 
Revisão qualitativa de estudos peer-reviewed; 
SLR baseada em PRISMA para síntese.
Métricas de precisão, recall, F1-score
Benchmark com datasets específicos de domínio","custo, precisão, produtividade, qualidade, recall, redução de esforço, segurança","Aumento de produtividade em desenvolvimento de software
Automação de tarefas repetitivas (documentação, testes)
Melhoria na qualidade de código e detecção de bugs
Suporte à tomada de decisão em operações industriais
Personalização de soluções para domínios específicos","Limitado a casos de uso isolados, deixando lacunas em integração (ex.: logística, procurement); Desafios em governança de dados, conformidade regulatória e explicabilidade; Altos custos computacionais para modelos grandes; Viés, preocupações com privacidade e adaptabilidade de domínio; Dependência excessiva de modelos proprietários restringe o controle; Aplicações em estágio inicial em indústrias como óleo/gás.","Áreas subexploradas na cadeia de valor de Porter (ex.: logística inbound/outbound, procurement, funções voltadas ao cliente); Necessidade de frameworks padronizados para PMEs na preparação e implementação de dados; Oportunidades em sistemas multiagentes para atividades mais amplas de ES (ex.: pipelines DevOps completos); Questões éticas, mitigação de viés e impacto ambiental; Customização específica de domínio além do fine-tuning; Integração com infraestrutura crítica sem interrupções operacionais.","Desenvolver agendas de pesquisa baseadas em clusters de tarefas empíricas; Explorar atividades subrepresentadas na cadeia de valor; Padronizar frameworks metodológicos para implantação de LLMs em PMEs; Abordar desafios de implementação como ética, privacidade e custos; Investigar tipos de arquitetura para aplicações específicas de ES; SLRs futuras sobre evoluções de LLMs e visões cross-setoriais.","Proteção de dados confidenciais
Falta de padrões de interoperabilidade
Habilidade organizacional e readiness tecnológico
Viés nos modelos e falta de transparência","Existem desafios persistentes que impedem uma adoção industrial mais ampla, incluindo problemas relacionados ao alinhamento do modelo, riscos éticos e o impacto ambiental decorrente do alto consumo de recursos. Dessa forma, enquanto a arquitetura de Transformers continua sendo a base técnica predominante, a tendência futura aponta para a integração de sistemas mais sofisticados, como agentes autônomos e o uso de técnicas de Prompt Engineering para refinar a precisão e a confiabilidade em ambientes de manufatura inteligente e design colaborativo.","""LLM adoption is heavily concentrated in technology-focused and internal operational activities across industries, where they offer immediate benefits at lower risk.""
""Areas such as logistics, procurement, and customer-facing functions remain largely unexplored.""
""Current deployments are primarily limited to isolated, manageable use cases, leaving substantial innovation potential unrealized.""
""The black-box character of current LLMs presents a fundamental barrier to explainability, which is particularly problematic in safety-critical or compliance-sensitive domains."""
A7,A Systematic Literature Review on Using Natural Language Processing in Software Requirements Engineering,2024,6.0,Scopus,Fully attended to,Partially attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Partially attended to,Jeniffer e Leonardo,"Sabina Cristiana Necula, Florin Dumitriu e Valerică Greavu Serban.",Romênia,Alexandru Ioan Cuza University of Iași (Faculty of Economics and Business Administration),Electronics (MDPI),journal,"O artigo mostra como técnicas de NLP, ML e DL são integradas para automatizar, apoiar e melhorar atividades de Engenharia de Requisitos, incluindo: detecção de ambiguidades, classificação de requisitos, extração de entidades, geração de modelos (ex.: UML), priorização e avaliação de qualidade. A contribuição da ES está principalmente na aplicação prática de IA em processos formais de desenvolvimento.","Design, Requisitos","O artigo não foca exclusivamente em IA Generativa, mas aponta a emergência recente de LLMs como tendência (2022–2023), inclusive para classificação, análise semântica e compreensão contextual de requisitos.","Redes Neurais Convencionais (CNN), Redes Neurais Recorrentes (RNN), K-means para agrupamento, e Modelos de Linguagem (LMs).","LLM, outro","GPT-x, outros","outros, prompt engineering",7000000000.0,"comercial, open source","Visual Narrator, QuARS, QVScribe, Qualicen Requirements Scout, IBM Engineering Requirements Quality Assistant; além de bibliotecas NLP e pipelines acadêmicos.","NLP clássico (tokenização, POS-tagging, parsing), classificação supervisionada, clustering, deep learning, extração de entidades, análise semântica, dependency extraction.","correção funcional, precisão, qualidade, recall, redução de esforço","Automação de tarefas manuais, melhoria da qualidade dos requisitos, redução de ambiguidades, escalabilidade, suporte a sistemas complexos, apoio a requisitos ágeis (user stories).","Ambiguidade linguística persistente, dependência de dados de treinamento, dificuldade com contexto de domínio, baixa generalização entre projetos, pouca explicabilidade dos modelos.","Uso sistemático de LLMs e GenAI, engenharia de prompts para requisitos, integração com DevOps, avaliação longitudinal em ambientes reais, explicabilidade, métricas padronizadas.","Explorar modelos de linguagem avançados, ampliar estudos empíricos, integrar NLP + IA com práticas ágeis e ferramentas industriais, estudar impacto organizacional.","Integração em workflows existentes, confiança nos resultados automáticos, validação humana, adaptação a múltiplos idiomas, adoção industrial.","O artigo é panorâmico e histórico, cobrindo mais de 30 anos (1991–2023), sendo particularmente forte em análise bibliométrica e evolução temática, mas menos profundo em detalhes técnicos de GenAI.","“This period marks the definitive rise of large language models, showcasing their potential to redefine the boundaries of research and practical applications within the software requirements engineering field.”"
A8,A Systematic Mapping Study of LLM Applications in Mobile Device Research,2025,0.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,"Ana Karolina (EXLUÍDO: EC1: Full text not available for free on the Web or on the CAPES Periódicos plataform.)
Filipe Campos (EXLUÍDO: EC1: Full text not available for free on the Web or on the CAPES Periódicos plataform.)","Zhang W., Tung A., Zheng Z., Yang Z., Wang X., Guo H.",China,"School of Computer Science and Technology, Beijing Jiaotong University, Beijing, China","Communications in Computer and Information Science: 7th International Workshop on Knowledge Graph Management and Applications, KGMA 2024, 6th International Workshop on Semi-structured Big Data Management and Applications, SemiBDMA 2024, 1st International Workshop on Mobile Applications and Data Management, MADM 2024, 1st International Workshop on Artificial Intelligence in Education and Educational Data Mining, AIEDM 2024 and 1st International Workshop on Spatio-Temporal Big Data Management, STBDM 2024 held in conjunction with APWeb-WAIM 2024",conference,,,,,,,,,,,,,,,,,,,
A9,A Systematic Review of AI-Enabled Frameworks in Requirements Elicitation,2024,6.0,Scopus,Fully attended to,Fully attended to,Partially attended to,Fully attended to,Fully attended to,Partially attended to,Fully attended to,"Leonardo Lima e Silva
Jeniffer","Vaishali Siddeshwar, Sanaa Alwidian, Masoud Makrehchi",Canadá,Ontario Tech University (University of Ontario Institute of Technology),IEEE Access,journal,"O artigo identifica e classifica 15 tarefas de elicitação de requisitos que são atualmente suportadas por Inteligência Artificial. Estas tarefas incluem a identificação de abstrações, geração de modelos de requisitos, análise de qualidade de requisitos e identificação de requisitos. O estudo também contribui mapeando 12 fontes de dados disponíveis publicamente usadas para treinar estas abordagens.",Requisitos,"O artigo cobre um espectro amplo de técnicas de IA, não se limitando apenas à IA Generativa. As técnicas exploradas incluem Machine Learning (Aprendizado de Máquina), Redes Neurais, Deep Learning (Aprendizado Profundo) e Natural Language Processing (Processamento de Linguagem Natural).","O estudo revisa 122 artigos que utilizam diversas arquiteturas, desde algoritmos clássicos de ML supervisionado até arquiteturas de Deep Learning e NLP. Não há um foco exclusivo em um único modelo de arquitetura (como apenas Transformers), mas sim na aplicação variada dessas técnicas para automatizar a elicitação.",outro,outros,outros,0.0,open source,"O artigo identifica a escassez de ferramentas robustas e aponta principalmente para fontes de dados (datasets) provenientes de repositórios de software, revisões online, blogs e discussões, que servem de base para o treinamento de ferramentas de elicitação.","O artigo realiza uma Revisão Sistemática da Literatura (SLR) cobrindo estudos de 1991 a 2023. Ele avalia a performance dos algoritmos reportados nos estudos primários, identificando limitações na precisão e eficácia das soluções atuais.",outros,"Automatização de tarefas complexas e manuais de elicitação; capacidade de processar grandes volumes de dados (repositórios, feedback de usuários) para identificar requisitos; suporte à identificação de abstrações e geração de modelos a partir de texto em linguagem natural.",Escassez de datasets de acesso aberto para treinamento; limitações de desempenho dos algoritmos atuais em tarefas complexas de elicitação; falta de estudos que cubram um espectro amplo de tarefas de elicitação (a maioria foca em nichos específicos).,"O estudo aponta que as revisões anteriores não cobriam um espectro amplo de tarefas de elicitação nem detalhavam as fontes de dados. Há uma oportunidade clara para padronização de datasets, melhoria na performance dos algoritmos e expansão para tarefas de elicitação menos exploradas.",Desenvolvimento de novos frameworks de IA que abordem as limitações de desempenho identificadas; criação e disponibilização de mais fontes de dados públicas (datasets) para treinar modelos de elicitação; aplicação de técnicas mais avançadas para cobrir as 15 tarefas de elicitação identificadas.,"Integrar soluções de IA de forma eficaz no processo de Engenharia de Requisitos, lidando com a ambiguidade da linguagem natural e a necessidade de alta precisão na definição de requisitos técnicos.","Este artigo é derivado de pesquisas que também exploram o uso de LLMs para geração de modelos de objetivos (Goal Models), indicando que os autores têm expertise na transição de ML clássico para GenAI na área de requisitos.","""This literature review identifies fifteen elicitation tasks currently supported by artificial intelligence and presents twelve publicly available data sources used for training these approaches."" ""The study uncovers common limitations in current studies and suggests potential research directions."""
A10,A systematic literature review on logging smell detection,2026,4.5,Scopus,Not attended to,Fully attended to,Not attended to,Partially attended to,Fully attended to,Fully attended to,Fully attended to,"Filipe Campos Matunaga Batista;
Ana Karolina",Nora Madi e Manal Binkhonain,Arábia Saudita,"Department of Software Engineering, College of Computer and Information Sciences, King Saud University, P.O. Box 51178, Riyadh 11543, Saudi Arabia",Information and Software Technology,journal,"Não se aplica.
;
O estudo é uma revisão sistema de literatura que se utiliza da técnica do snowbouling para encontrar artigos relevantes que tratem sobre a detecção de problemas no registro de logs e são abordados trabalhos que tratam o uso da IA/ML para auxiliar nessa detecção.","Manutenção, Operações/DevOps","Random Forest, Naïve Bayes, Logistic Regression, Decision Trees, Ensemble methods, clustering methods, Bidirectional Long Short-Term Memory, Natural language processing. (só foram citados, mas não explorados)
; 
Stemming, stopword removal, Term Frequency","Log Sculptor, GPT 4, QuLog, LogUpdater",LLM,"GPT-x, outros",outros,,outro,Não se aplica.,"Não foi mostrado.
;
Os autores discorrem que foram encontradas métricas quantitativas de desempenho em 17 estudos como: recall, F1-score, accuracy e Area Under the ROC Curve (AUC), não são especificados em quais trabalhos apenas ""especially those involving machine or deep learning models""","precisão, recall","Machine Learning/Deep Learning: Integra diversos recursos (sintáticos, semânticos, históricos) – Detecta questões sutis não percebidas por ferramentas rule-based – Adaptável a diversas arquiteturas e tarefas – Pode gerar dados sintéticos de treinamento.
LLMs: –Pode detectar uma ampla gama de logging errors –Os prompts podem ser enriquecidos com conhecimento específico de defeitos ou específico do projeto e logging guidelines –Pode raciocinar sobre linguagem natural em log statements –Pode ser rapidamente adaptado a novos projetos ou tipos de defeitos sem necessidade de re-treinamento.","Machine Learning/Deep Learning: –Requer grandes conjuntos de dados de alta qualidade –Raciocínio limitado –Alguns modelos não generalizam entre projetos –Propensos a vieses de rótulos manuais.
LLMs: –Executar em grandes bases de código pode ser lento e computacionalmente caro –Previsões corretas podem vir acompanhadas de explicações incompletas ou incorretas –Propenso a classificar incorretamente como defeituosas declarações de log corretas sem filtragem ou verificação adicional –Frequentemente ausentam de consciência estrutural do código, limitando a interpretação do fluxo de controle/dados .",Desenvolvimento de abordagens automatizadas avançadas para detectar registro indevido e a necessidade de declarações de registro de qualidade excepcional para benchmarking.,"LLMs mostram potencial para aprimorar a interpretabilidade de logs. Trabalhos futuros poderiam explorar mais a integração deles em ferramentas de log para permitir uma análise mais aprofundada. Além disso, como desenvolver uma única solução que abranja uma ampla gama de defeitos continua sendo um desafio em aberto, essa limitação pode ser mitigada aproveitando as capacidades avançadas dos LLMs.
;
Além disso, como é evidenciada uma escassez de benchmarks, para trabalhos futuros os autores citam a necessidade de se criar benchmarks acordados pela comunidade.","1. Usando o GPT 4, o Log Sculptor inicialmente detectou apenas 10,6% das instruções de log, mas uma etapa de pré-processamento aumentou a taxa de detecção para 90,6%. Isso destaca a importância do pré-processamento, mesmo ao utilizar técnicas avançadas como LLMs.
2. QuLog destaca que, mesmo com métodos de deep learning, podem ocorrer classificações incorretas nos níveis de log, ressaltando o desafio contínuo de alcançar alta precisão sem introduzir falsos positivos ou negativos em excesso","1. De 2012 a 2021, a análise estática e o aprendizado de máquina tradicional eram dominantes. A partir de 2022, houve um aumento gradual na adoção de técnicas de deep learning. Em 2024 LLMs são introduzidas, sinalizando o mais recente avanço na detecção de logging smells.
2. Para uma detecção de múltiplos logging smells, estudos recentes mostraram que LLMs podem agir como soluções unificadas.
;
3.O trabalho só deixa claro que há o uso de IA ou ML na sessão onde são apresentados os resultados que respondam a Questão de pesquisa 2 que se trata das técnicas utilizadas para identificar problemas de registro de logs, até então fiquei me questionando se talvez o trabalho não deveria ser excluído pois a princípio não fica clara essa relação e o foco do estudo não é encontrar especificamente trabalhos que usem IA para detectar esses problemas.","""Recently, LLMs are employed to enhance the analysis and generation of log statements through their advanced understanding of natural language and code. For example, in S01, several LLMs (i.e., GPT 4o [34], Llama3.3 [35], DeepSeek-R1 [36], and Qwen2.5-72B [37]) are leveraged to detect and reason about logging code defects through a benchmark framework called Defects4Log.""
""They evaluate various prompting strategies (e.g., Chain of Thought (CoT) [38]) and contextual inputs (e.g., control flow) to test LLMs’ ability to detect and explain these defects."""
A11,AI and Teamwork in Agile Software Development: A Systematic Mapping Study,2026,5.0,Scopus,Partially attended to,Fully attended to,Not attended to,Partially attended to,Fully attended to,Fully attended to,Fully attended to,Ana Karolina e Filipe Campos,Ya Ting Crystal Kwok e Mahum Adil,Itália,"Free University of Bozen-Bolzano, Bolzano, Itália","Agile Processes in Software  Engineering and Extreme  Programming – Workshops (XP 2025 Workshops Brugg-Windisch, Switzerland, June 2–5, 2025 Revised Selected Papers)",conference,"O trabalho busca fazer uma revisão sistemática dos trabalhos existentes para o uso de IA no desenvolvimento ágil com o foco em trabalho em equipe (pensando nos 3Cs, comunicação, coordenação e colaboração). Como o ponto que tange a Engenharia de Software é justamente o modelo de desenvolvimento ágil, ele engloba todas as atividades de engenharia de software. Os autores buscaram fazer um levantamento desde janeiro de 2001 até janeiro de 2025 com o objetivo de verificar o processo de evolução dos estudos que englobem o escopo de interesse, locais de publicação, lacunas e possibilidades futuras para a área.","Arquitetura, Construção/Codificação, Design, Gestão de projeto, Manutenção, Operações/DevOps, Requisitos, Testes","Os artigos levantados abordam o uso de Processamento de linguagem natural (PLN), linguagem de maquina (ML), LLM, agentes, assistentes e bots.",Os resultados apresentados não mostram nenhum modelo específico,LLM,,prompt engineering,,,Não se aplica,Não são apresentadas técnicas de avaliação,,"Os benefícios do uso da IA para equipes de trabalho no desenvolvimento ágil são: na coordenação, a IA otimiza a alocação de tarefas, melhora a estimativa de esforço e apoia o gerenciamento de projetos; na colaboração, ela aprimora a programação em pares, a tomada de decisões e a documentação; e na comunicação, a IA facilita as reuniões de equipe e analisa o sentimento da equipe.","As limitações apresentadas são apenas nessa lacuna da quantidade de estudos, o artigo não trata profundamente sobre o que foi encontrado nos artigos analisados.","Desenvolver trabalhos com funções de IA de alto nível (já que a maioria se concentra em funções de baixo nível) e como consequência o uso de IA com maior autonomia para gerir as atividades do trabalho em equipe.;
Ainda não existem muitos estudos que abordam a aplicação prática dessas tecnologia, mantendo-se principalmente nos estudos empíricos.",O trabalho levanta que pesquisas futuras poderiam estudar o impacto da IA ​​com maior autonomia nas interações da equipe e como a IA pode transitar de uma mera ferramenta para um agente autônomo que apoia ativamente o trabalho em equipe. Como a maioria dos artigos analisados se concentram em funções de IA de baixo nível o artigo sugere que trabalhos futuros possam se concentrar em funções de IA de alto nível.,"O artigo não apresenta descobertas ou comentários que discorram sobre desafios do uso da IA em si para auxiliar o trabalho em equipe e isso pode se dar por 2 fatores que não foram abordados, seja pelo fato de não existirem dificuldades relevantes ou por conta da quantidade reduzida de trabalhos que foram encontrados que contemplem os objetivos da pesquisa.","É uma área pouquíssimo explorada, os autores comentam a dificuldade em encontrar trabalhos que abordem especificamente os 3Cs em trabalhos em equipe, assim como no geral após usar os critérios de exclusão e inclusão terem restado apenas 20 artigos. Como a maior parte dos trabalhos existentes abordem apenas aplicações de baixo nível, existe uma lacuna para ser preenchida com aplicações de alto nível.","""AI-driven techniques like machine learning (ML) and natural language processing (NLP) are increasingly integrated into Agile software development to enhance productivity and efficiency""
""In recent years, research on AI in Agile software development has increased, with most studies focusing on improving workflows, processes and tools. However, the exploration into AI in teamwork, one of the core aspect of Agile software development, remains unclear, as far as the authors are aware of.""
""Building on existing systematic mapping studies, t his study provides an overview of AI’s role in Agile teamwork, specifically in relation to 3C within Agile teams.""
""only three journal articles published from 2024 onwards. This indicates that research in this area is still in its early stages."""
A12,AI-Based Approaches for Software Tasks Effort Estimation: A Systematic Review of Methods and Trends,2025,5.0,Scopus,Partially attended to,Fully attended to,Partially attended to,Partially attended to,Fully attended to,Partially attended to,Fully attended to,"Filipe Campos Matunaga Batista;
Ana Karolina",Bruno Budel Rossi e Lisandra Manzoni Fontoura,Brasil,"Programa de Pós-Graduação em Ciência da Computação, Federal University of Santa Maria (UFSM), Brazil","Proceedings of the 27th International Conference on Enterprise Information Systems (ICEIS 2025) - Volume 2, pages 144-151",journal,"Não se aplica.
;
O Estudo é uma revisão sistema referente ao uso de IA/ML para realizar a estimativa de esforço em tarefas de software",Gestão de projeto,"IA: rule-based systems, Bayesian networks, topic modeling, Latent Dirichlet Allocation
Machine learning: Neural networks (DNNs, CNNs, RNNs, LSTM, CCNN), SVM, KNN, decision trees, ensemble learning, SBERT, Word2Vec,",Não se aplica.,LLM,GPT-x,outros,,outro,Não se aplica.,"Métricas Usadas para Avaliar o Desempenho do Modelo:
1. Mean Magnitude of Relative Error (MMRE).
2. Median Magnitude of Relative Error (MdMRE).
3. PRED(X).
4. Mean Absolute Error (MAE) and Root Mean
Square Error (RMSE).","carga cognitiva, custo, precisão, qualidade","1. gerar boas representações semânticas, melhorando as comparações de descrições de tarefas. (SBERT)
2. identificar similaridades de tarefas com custos computacionais mais baixos. (Word2Vec).
3. capturar a complexidade dos dados do projeto. (Redes Neurais).
4. precisão preditiva com dados extensos. (DNNs).
5. são eficazes na modelagem de dados sequenciais e na captura de dependências de longo prazo, fundamentais para projetos em evolução. (LSTM).","1. Alta demanda computacional.
2. menos eficaz na compreensão de frases complexas.
3. altos custos de treinamento em termos de tempo e recursos computacionais.
4. exigem ajustes consideráveis e grandes volumes de dados de treinamento.
5. exige esforço computacional significativo e enfrentam desafios como o problema do vanishing gradient.","Não especificados.
;
Os autores concluem que a adoção de modelos de IA sem ML (redes Bayesianas) permanece limitado, assim como o uso da própria ML está ainda em estágio iniciais, como eles concluem que o uso de IA/ML tem se tornado cada vez mais frequente nesse campo, essa é uma área ainda pouco explorada que se mostra promissora.",Não especificados.,"Necessidade de supervisão humana para interpretar mudanças de contextos. IA sem aprendizado de máquina peca em aprendizado dinâmico, limitando o uso em contextos de grandes dados. Redes Bayesianas realizam tarefas ágeis de forma eficaz, mas têm dificuldade com novos inputs não antecipados durante as fases iniciais de modelagem.","O uso de modelos híbridos (combinando abordagens de machine learning) superam limitações individuais.
;
O trabalho se mostrou promissor ao especificar o processo utilizado para realizar a revisão sistemática porém, o trabalho carece de gráficos que demonstrem uma relação de quantidade de trabalhos para as técnicas constatadas, não é apresentada uma lista dos 66 artigos que foram selecionados e a conclusão se enquadrou mais em um resumo","""The study highlights that while LLMs excel in automated large-scale data analysis, human experts are crucial for interpreting contextual nuances, especially in complex, dynamic maintenance tasks.""
""The application of AI techniques, particularly ML, has become adominant approach for effort estimation in software projects,"""
A13,AI-assisted Software Engineering: A tertiary study,2023,0.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,"Filipe Campos Matunaga Batista - Excluído (EC3: Not a secundary study)
Ana Karolina-  Excluído (EC3: Not a secundary study)",,,,,,,,,,,,,,,,,,,,,,,,"""We employed a systematic literature review of other existing reviews approach based on recommendations provided by Kitchenham [2], to identify research gaps and future research opportunities."""
A14,AI-enabled Software Engineer: A Taxonomy of Challenges and Success Factors,2024,0.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Brenno - EC1 - Full text not avaliable for free on the Web or on the CAPES Periódicos platform,"Shameem, Mohammad and Niazi, Mahmood K. and Nadeem, Mohammad Anas and Kumar, Ankur",Arábia Saudita,Knowledge Systems Institute Graduate School,"Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE",conference,,,,,,,,,outro,,,,,,,,,,
A15,Agent design pattern catalogue: A collection of architectural patterns for foundation model based agents,2025,0.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Ana Karolina EXCLUÍDO (EC4: Does not address genAI for SE activities),"Yue Liu, Sin Kit Lo, Qinghua Lu, Liming Zhu, Dehai Zhao, Xiwei Xu, Stefan Harrer, Jon Whittle",Australia,"Data61, CSIRO, Sydney, Australia",Journal of Systems and Software,journal,,,,,,,,,,,,,,,,,,,
A16,Artificial intelligence in web accessibility: A systematic mapping study,2026,5.5,Scopus,Partially attended to,Fully attended to,Fully attended to,Partially attended to,Fully attended to,Partially attended to,Fully attended to,Henrique da Rocha Lima,"Campoverde-Molina, Milton and Luján-Mora, Sergio","Equador
Espanha","Universidad Católica de Cuenca, Cuenca, 010107, Azuay
Universidad de Alicante, San Vicente del Raspeig, 03690, Alicante",Computer Standards and Interfaces,journal,"O artigo mostra que a Engenharia de Software contribui principalmente por meio da automação de testes de acessibilidade, correção automática de código HTML conforme WCAG, geração de interfaces acessíveis, integração de IA em ferramentas de desenvolvimento (como plugins, APIs e extensões) e definição de boas práticas para o uso de IA generativa no desenvolvimento de software acessível.","Arquitetura, Construção/Codificação, Design, Testes","As técnicas incluem geração automática de texto alternativo para imagens, geração e correção de código acessível, avaliação automática de conformidade com WCAG, adaptação dinâmica de interfaces com base nas preferências do usuário e uso de agentes conversacionais para navegação acessível.","O artigo indica que os modelos mais explorados são Modelos de Linguagem de Grande Porte (LLMs), principalmente para geração de código acessível, avaliação automática de acessibilidade e criação de texto alternativo para imagens. Também são utilizados modelos de visão computacional e NLP, como arquiteturas baseadas em Transformers, além de combinações CNN-RNN para tarefas multimodais. O uso de prompts bem definidos é essencial para orientar a geração de código e descrições acessíveis. Não há menção específica ao uso de SLMs, nem detalhamento explícito de tamanhos de modelo ou fine-tuning.",LLM,"Deepseek, GPT-x, Llama, outros","outros, prompt engineering",,"comercial, open source","As principais ferramentas incluem ChatGPT, Copilot, DeepSeek, Bard, HuggingChat, Jasper AI, Perplexity AI, Poe, Bing AI, além de ferramentas especializadas como GenA11y, WEBSumm, CodeA11y, extensões do Visual Studio Code, extensões de navegadores e APIs voltadas à acessibilidade.","São utilizadas avaliações automáticas de conformidade com WCAG, comparações entre descrições geradas por humanos e por IA, testes com usuários finais (especialmente pessoas com deficiência), análises da acessibilidade de interfaces geradas por IA e validação de código produzido por modelos generativos.","cobertura, correção funcional, precisão, qualidade","Os principais benefícios incluem redução do esforço humano na avaliação de acessibilidade, aumento da produtividade dos desenvolvedores, geração automática de código e descrições acessíveis, melhoria na conformidade com padrões WCAG e promoção da inclusão digital.","As limitações envolvem violações frequentes de acessibilidade em código gerado por IA, necessidade constante de revisão humana, dependência de prompts bem formulados, baixa confiabilidade em alguns tipos de avaliação automática e qualidade inconsistente das descrições geradas.","O artigo aponta oportunidades para desenvolver modelos mais confiáveis, integrar melhor a IA aos fluxos de desenvolvimento, padronizar métricas de avaliação, investigar impactos de longo prazo e melhorar a acessibilidade das próprias ferramentas de IA.","Os autores sugerem o desenvolvimento de novas ferramentas de avaliação automática, exploração de novos modelos e arquiteturas, ampliação de estudos empíricos com usuários reais, análise de aspectos éticos e sociais e aprimoramento da geração automática de conteúdo acessível.","Os principais desafios incluem garantir conformidade real com WCAG, evitar vieses e erros nos modelos, tornar ferramentas de IA acessíveis, assegurar transparência e responsabilidade no uso da IA e reduzir a dependência excessiva de automação.",,"O estudo destaca que a IA ajudou a gerar código HTML acessível por meio de prompts bem definidos, que modelos de linguagem de grande porte (LLMs) foram os mais utilizados e que ferramentas como ChatGPT apresentaram violações de acessibilidade em uma parcela significativa dos casos, reforçando a necessidade de revisão humana."
A17,Assessing the Effectiveness of ChatGPT in Secure Code Development: A Systematic Literature Review,2025,5.5,Scopus,Partially attended to,Partially attended to,Fully attended to,Fully attended to,Fully attended to,Partially attended to,Fully attended to,Brenno,"Bouzid, Rezika and Khoury, Raphaël",Canadá,University of  Quebec in Outaouais,ACM Computing Surveys,journal,"O artigo classifica e sintetiza estudos sobre o uso do ChatGPT para geração de código seguro, detecção de vulnerabilidades (VD) e reparo de código (CR). Ele identifica técnicas de prompt engineering eficazes para segurança, compara o desempenho do ChatGPT contra ferramentas estáticas (SAST) e outros LLMs, e propõe uma taxonomia baseada em tarefas de segurança","Arquitetura, Construção/Codificação, Manutenção, Testes","As técnicas principais incluem Geração de Código, Detecção de Vulnerabilidades, Reparo de Código (Code Repair) e Fuzzing. O estudo destaca o uso de Prompt Engineering avançado e abordagens iterativas (refinamento com feedback de ferramentas)","O foco principal é no ChatGPT (GPT-3.5, GPT-3.5-Turbo, GPT-4). Para comparação, são explorados: StarCoder, CodeGen, InCoder, CodeBERT, GraphCodeBERT, GitHub Copilot, Amazon CodeWhisperer e Bard.",LLM,"GPT-x, StarCoder, outros","chain of thought, outros, prompt engineering, self refine",,"comercial, open source","As ferramentas de suporte são principalmente ferramentas de Análise Estática de Segurança (SAST) usadas para validar o output da IA: CodeQL, SonarQube, Bandit, Semgrep, Flawfinder, Cppcheck, Snyk, Fortify e ESBMC","Inspeção manual (revisão humana do código), análise estática automatizada, análise dinâmica, benchmarks","correção funcional, precisão, produtividade, qualidade, recall, segurança","Demonstrou a superioridade do ChatGPT-4 superando outras ferramentas estáticas tradicionais, correção iterativa, mostrou capacidade de corrigir ensinando, mostrando os defeitos e atuando como ""professor"".","Código vulnerável, falhas principalmente no ChatGPT-3.5. Alucinações e falsos positivos, algumas inconsistências e limite de tolkens","Falta de datasets padronizados, necessidade de definir o número ideal de iterações para poder reparar o código, melhorar o manuseio de tolkens e verificar quais estratégias de prompt funcionam melhor",Desenvolvimento de frameworks híbridos e estudos sobre as implicações éticas e de privacidade no uso de LLMs para segurança.,"Alguns desafios incluem a segurança da própria ferramenta, dependência do contexto (baixa perfomance em linguagens como C e C+) e confiabilidade por não possuir boa auditoria em segurança",,
A18,Automatic Extraction and Formalization of Temporal Requirements from Text: A Survey,2025,6.0,Scopus,Fully attended to,Fully attended to,Partially attended to,Fully attended to,Fully attended to,Partially attended to,Fully attended to,"Leonardo Lima e Silva
Jeniffer","Marisol Barrientos, Karolin Winter e Stefanie Rinderle-Ma.",Alemanha e Países Baixos.,Technical University of Munich (Alemanha) e Eindhoven University of Technology (Países Baixos).,Business Information Week 2024,conference,"O estudo contribui com a automação da extração e formalização de requisitos temporais a partir de documentos diversos (especificações de sistema, textos legais e descrições de processos de negócio). O artigo apresenta uma Revisão Sistemática da Literatura (SLR) sobre o tema e propõe um novo método/ferramenta chamado NL2MTL. A contribuição foca em preencher lacunas como a sub-representação de textos legais, gerenciamento pobre de contexto de saída e a necessidade de automatizar a formalização considerando aspectos quantitativos e qualitativos do tempo.",Requisitos,O estudo explora o uso de Prompt Engineering (especificamente padrões de reflexão e receita/recipe) e In-context learning. A SLR também identifica trabalhos que utilizam Fine-tuning de modelos.,"O estudo e a ferramenta proposta (NL2MTL) utilizam principalmente o GPT-4. A revisão de literatura menciona o uso de GPT-3 , GPT-J-6B , T5 , BART , BERT , Bi-LSTM CRF e modelos Seq2Seq.",LLM,"GPT-x, outros","outros, prompt engineering",6000000000.0,"comercial, open source","A ferramenta principal apresentada é o protótipo NL2MTL. O estudo menciona o uso e extensão de ferramentas anteriores como nl2spec. Outras ferramentas e bibliotecas mencionadas incluem Stanford CoreNLP, WordNet, e analisadores baseados em Prolog","A avaliação do NL2MTL foi baseada nos ""quatro princípios chave de uma boa formalização"": correção (correctness), transparência (transparency), compreensibilidade (comprehensibility) e suporte a múltiplas interpretações (support for multiple interpretations). O método envolveu rodar a extração cinco vezes por formato de entrada para testar a estabilidade.","correção funcional, outros, qualidade","Automação da extração e formalização de requisitos temporais a partir de grandes volumes de documentos, o que é vital para conformidade. Capacidade de lidar com textos complexos e não estruturados (como textos legais e descrições de processos) utilizando LLMs modernos como GPT-4, superando limitações de parsers tradicionais. O método proposto (NL2MTL) melhora a transparência ao definir símbolos e parâmetros para evitar alucinações.","Modelos Seq2Seq podem interpretar mal dependências em expressões lógicas ou inverter sujeitos. No protótipo NL2MTL, em 25% dos testes, o sistema parou de traduzir proposições atômicas subsequentes após interpretar incorretamente um comando de ""parada"" no texto de entrada. Há dificuldade em garantir a ""correção"" absoluta devido a partes do texto não formalizadas.","Falta de colaboração interdisciplinar (ex: métodos de robótica não são citados em outras áreas). Terminologia inconsistente entre estudos (ex: definição de ""texto não estruturado""). Sub-representação de textos legais nos estudos existentes. Baixo suporte para formalização de informações temporais quantitativas (unidades exatas de tempo) em especificações formais geradas automaticamente.",Testar o protótipo NL2MTL em cenários do mundo real e conduzir estudos aprofundados com usuários especialistas de domínio. Analisar papéis excluídos na SLR para comparar metodologias. Focar em domínios específicos (como robótica ou veículos autônomos) para lidar com vocabulário especializado e qualidade de entrada.,Dificuldade em estabelecer métodos de avaliação comparáveis entre diferentes abordagens. Gerenciamento pobre de contexto na saída das ferramentas existentes. Ambiguidade e variação na qualidade do texto de entrada. Distinção entre informações temporais funcionais e não-funcionais.,"O artigo é um híbrido que contém uma Revisão Sistemática da Literatura (44 artigos analisados) e uma proposta de solução técnica (Design Science) com a criação do NL2MTL. Os autores usaram os padrões de prompt ""reflection"" e ""recipe"" para estruturar a interação com o GPT-4.","""This abundance of automation options often leaves domain experts puzzled about the most suitable approach for their specific problem."". ""NL2MTL allows for an automatic translation of system specifications, legal texts, and business process descriptions to MTL utilizing the power of state-of-the-art LLMs."". ""Symbols and parameters were clearly defined, enhancing transparency and preventing hallucination.""."
A19,Automating Code-Related Tasks Through Transformers: The Impact of Pre-training,2023,3.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Fully attended to,Fully attended to,Fully attended to,"Leonardo Lima e Silva
Jeniffer","Rosalia Tufano, Luca Pascarella, Gabriele Bavota",Suíça,Software Institute - USI Università della Svizzera italiana,arXiv,arxiv,"INCONCLUSIVO. O artigo foca estritamente na automação de tarefas relacionadas ao código-fonte (bug-fixing, code summarization e code completion) e no impacto de objetivos de pré-treinamento. Embora mencione a exclusão de tópicos não relacionados na sua revisão sistemática, não há contribuições diretas para a Engenharia de Requisitos exploradas no estudo experimental.","Construção/Codificação, Manutenção","? O estudo explora o impacto de diferentes objetivos de pré-treinamento (pre-training objectives) em modelos Transformers. As técnicas específicas de pré-treinamento investigadas incluem objetivos genéricos como Masked Language Model (MLM), Next Sentence Prediction (NSP) e Replaced Tokens Detection (RTD). Além disso, são explorados objetivos ""sob medida"" (task-specific) para tarefas de código: Injected-Mutants Fixing (IMF) para correção de bugs, Method Name Generation (MNG) para sumarização, e Code Block Selection (CBS) para completude de código.","O modelo central explorado é o T5 (Text-To-Text Transfer Transformer), especificamente a variante ""small"" (~60M parâmetros), escolhida devido ao custo computacional para treinar múltiplos modelos. A arquitetura possui 6 camadas tanto no encoder quanto no decoder. O estudo também discute, via revisão de literatura, o uso de BERT e CodeBERT",LLM,outros,outros,60000000.0,open source,"O estudo utiliza Google Colab (TPU) para o treinamento dos modelos. Para o pré-processamento, análise e mutação de código Java, é utilizada a biblioteca Javaparser. Ferramentas como langid e cld3 são usadas para filtragem de linguagem natural em Javadocs.","A avaliação principal é a porcentagem de predições corretas (correct predictions), onde a saída gerada deve ser idêntica à esperada. Como métricas complementares, o estudo utiliza BLEU-4 para sumarização de código e a distância de Levenshtein normalizada (nível de token) para completude de código. Estatisticamente, utilizam o teste de McNemar com correção de Holm e Odds Ratio (OR).","coerência, correção funcional, outros","O uso de pré-treinamento (pre-training) oferece um aumento significativo de desempenho (até 10x mais chances de acerto) quando o conjunto de dados para ajuste fino (fine-tuning) é pequeno. Isso é particularmente benéfico para tarefas onde dados rotulados são escassos, como correção automática de bugs (bug-fixing).","O pré-treinamento torna-se ineficaz ou não traz benefícios observáveis quando o conjunto de dados de fine-tuning é grande (tamanho comparável ao dataset de pré-treinamento), possivelmente devido ao ""catastrophic forgetting"". Além disso, modelos multilíngues podem ter desempenho inferior aos monolíngues.","Há uma lacuna na eficácia de objetivos de pré-treinamento especializados (task-specific); o estudo mostra que eles raramente superam significativamente o objetivo genérico MLM, sugerindo a necessidade de investigar como desenhar objetivos que capturem conhecimento ortogonal ao MLM. O estudo limitou-se à linguagem Java e granularidade de método, deixando em aberto a generalização para outras linguagens e contextos.","artigo foca em apresentar as conclusões do estudo empírico e listar ameaças à validade (como a limitação a Java e ao modelo T5), mas não contém uma seção explícita detalhando direções específicas de ""Trabalhos Futuros"" além da implicação de que generalizações são necessárias.","Um desafio central é a construção de datasets de pré-treinamento limpos e compiláveis para permitir o uso de ferramentas de mutação (como PIT), o que levou os autores a desenvolverem sua própria ferramenta baseada em AST para contornar problemas de compilação em projetos ""in the wild"". Outro desafio é a escassez de dados reais para tarefas como bug-fixing.","Uma das principais conclusões do artigo é que o objetivo de pré-treinamento Masked Language Model (MLM) é uma ""escolha segura"" e robusta para tarefas de código, sendo quase sempre o melhor ou estatisticamente equivalente ao melhor, mesmo quando comparado a objetivos desenhados especificamente para a tarefa final.","""Our results show that: (i) pre-training helps in boosting performance only if the amount of fine-tuning data available is small;"" 
""(ii) the MLM objective is usually sufficient to maximize the prediction performance of the model, even when comparing it with pre-training objectives specialized for the downstream task at hand."" 
""Having a large fine-tuning dataset may lead to 'override' what the model learned during pre-training, making the latter basically useless."""
A20,Beyond the Systematic: Forecasting Importance and Emergence of Research Areas in Applications of Software Traceability Using NLP,2024,0.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Brenno - EC1 - Full text not avaliable for free on the Web or on the CAPES Periódicos platform,,,,,,,,,,,,,,,,,,,,,,,,
A21,Code Generation Using Machine Learning: A Systematic Review,2022,6.0,Scopus,Partially attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Partially attended to,Fully attended to,"Filipe Campos Matunaga Batista;
Ana Karolina",Enrique Dehaerne; BAPPADITYA DEY; Sandip Halder; Stefan de Gendt; Wannes Meert,Bélgica,"Dept. of Computer Science, KU Leuven and Interuniversity Microelectronics Centre; Interuniversity Microelectronics Centre; Interuniversity Microelectronics Centre; Dept. of Computer Science, KU Leuven and Dept. of Chemistry, KU Leuven; Dept. of Computer Science, KU Leuven;",IEEE Access,journal,"Os estudos avaliados podem ser divididos em três paradigmas: ""descrição-para-código"", ""código-para-descrição"" e código-para-código"".
Código-para-Código: Envolve gerar código com inputs que não são códigos, é o paradigma mais popular, os inputs podem se dar de várias formas, sendo a mais popular, das categorias, a linguagem natural., seguida por exemplos, sendo as imagens um importante meio de entrada, pois auxiliam a gerar códigos de designs de telas. 
Código-para-Descrição: É o paradigma menos popular. Envolve realizar a documentação, sendo a única categoria desse paradigma envolvida nos estudos.   
Código-para-Código: Envolve gerar um código com outro código como entrada. A categoria mais famosa é ter um código com bugs na entrada para a máquina retirar o bug, outras categorias são tradução de código para outra linguagem de programação, refatorar código para melhor entendimento, e conclusão de código, onde a máquina termina um código incompleto.",Construção/Codificação,Não se aplica.,"Modelos de aprendizado de máquina descritos: Recurrent neural networks (RNN) são as mais populares nos estudos, usados em praticamente todas as tarefas, principalmente em geração de documentação; Transformers dependem exclusivamente de mecanismos de atenção para capturar dependências entre tokens em dados sequenciais, é o segundo mais popular, também são usadas em grande variedade de tarefas, pode ter um baixo desempenho comparado com o modelo anterior; Convolutional neural networks (CNN) funciona bem com imagens como entradas; MLaugmentedsearch garante um programa compilar e se comportar conforme especificado pelos exemplos de entrada e saída fornecidos.
;
RNN (LSTM, GRU), Transformer, CNN, Other Neural (MLP, Graph NN, Neural trees, ENN), Non-nerural (SM, RL, RF, KNN)",outro,outros,,,outro,Não se aplica,"A avaliação normalmente é feita usando ""Token match"", ""Dynamic Analysis"" ou ""Static Analysis"".
;
Os autores citam que em alguns casos a avaliação humana é indispensável mas que há a problemática de exigir uma pessoa especialista na linguagem e muito tempo para realizar a tarefa.",,citado em outros campos.,"Modelos com tokenizadores reconhecem um conjunto finito de tokens que são chamados de vocabulário do modelo. Sempre que um trecho da string de entrada não possui um token correspondente no vocabulário, um token especial <unknown> deve ser usado. Isso resulta em uma perda de informação que é chamada de problema out-of-vocabulary (OOV). Existindo três principais tipos de tokenizers para resolver esse problema, word-based, character-based,and subword-based tokenizers.","Não exemplificado.
;
Como foi citado no texto, devido ao fator dos autores terem optado por utilizar uma frase de busca ao invés de uma string de busca fez com que trabalhos com outros modelos que não foram levantados ficassem de fora da análise, realizar um novo trabalho que defina uma estratégia acurada de busca e seleção de estudos poderia ser uma oportunidade de pesquisa.","""Novas formas de usar Árvores de Sintaxe Abstrata (AST)"", ""Aprendizado em conjunto"" e ""Melhorando a eficiência do modelo de linguagem"", com detalhamento no artigo.",Citado em outros campos.,"Todos os estudos primários estão descritos em uma tabela onde é possível ver o ""ML model""; ""Dataset"", ""Results & Discussion""; ""Limitations and Future Work""; de cada estudo.
;
A descrição dos estudos que foram analisados trazendo para o leitor uma noção geral dos pontos de cada artigo selecionado é um plus que agrega valor ao artigo, por outro lado a metodologia aplicada deixou a desejar, os critérios de inclusão e exclusão que foram utilizados não são apresentados de forma individualizada e pontuada (são apresentados no texto corrido) e bem como outros artigos que li, não há um critério de avaliação e pontuação da qualidade dos artigos. Por fim, o fato de não terem utilizado uma string de busca e sim uma frase é uma problemática que inclusive é discutida no texto.",
A22,"Decoding ChatGPT: A taxonomy of existing research, current challenges, and possible future directions",2023,0.0,Scopus,,,,,,,,"Henrique da Rocha Lima -> Incluído E 
Heitor Dias -> Excluído  (Devido o fato do estudo não focar especificamente em aplicações de GenAI em ES, o estudo até menciona alguns pontos do chatGpt em ES, mas o estudo como um todo não se concentra na ES)","Sohail, Shahab Saquib
Farhat, Faiza
Himeur, Yassine
Nadeem, Mohammad
Madsen, Dag Øivind
Singh, Yashbir
Atalla, Shadi
Mansoor, Wathiq",India,"Department of Computer Science and Engineering, School of Engineering Sciences and Technology, Jamia Hamdard, New Delhi",Journal of King Saud University - Computer and Information Sciences,journal,"Técnicas e Ferramentas:
A Engenharia de Software (ES) fornece frameworks para correção automática de bugs, usando benchmarks como QuixBugs para comparar modelos como ChatGPT, Codex e CoCoNut. A engenharia de prompts tornou-se central para obter respostas eficazes em codificação, refatoração e requisitos, enquanto ferramentas de IA atuam como assistentes de código e apoio à depuração em tempo real.

Processos de Desenvolvimento:
A ES integra IA à gestão de arquitetura, auxiliando arquitetos na criação de roadmaps e sistemas orientados a serviços. Também permite a automação de etapas do ciclo de vida, como geração de APIs, elicitação de requisitos, testes, deployment e desacoplamento de bibliotecas.

Métricas e Avaliação:
Benchmarks rigorosos avaliam funcionalidade, segurança e eficiência do código gerado por IA. Além disso, métricas de qualidade medem melhorias em padrões de design, legibilidade e manutenibilidade após refatoração automática.",Construção/Codificação,"Aprendizado e Ajuste (Fine-Tuning):
Incluem técnicas como fine-tuning para adaptar modelos a domínios específicos, aprendizado zero-shot para resolver novas tarefas sem treino adicional e RLHF para alinhar respostas às preferências humanas em diálogos técnicos.

Engenharia de Prompts:
Considerada uma dimensão emergente da ES, envolve o design de instruções eficazes, o uso de dicas contextuais e o desenvolvimento de padrões de prompt para melhorar código, requisitos e design.

Aplicações Técnicas no Ciclo de Vida:
As técnicas são aplicadas à correção automática de bugs, automação de arquitetura e geração de especificações, integrando IA a diversas etapas do desenvolvimento de software.","Modelos Explorados:
Os estudos analisam LLMs como a série GPT (do GPT-1 ao GPT-4), com destaque para o ChatGPT na geração de código e automação de tarefas de ES. Também incluem o Codex, especializado em código, o CoCoNut para correção automática de bugs e modelos como BERT e RoBERTa para tarefas específicas de classificação e análise, onde superam modelos generativos em alguns cenários.

Modelos Menores (SLMs):
Além dos LLMs, são discutidos modelos menores ou mais especializados, como o GPT-1 e modelos voltados a tarefas específicas (ex.: RoBERTa), considerados mais eficientes em contextos restritos do que modelos generalistas.

Arquiteturas:
A arquitetura predominante é o Transformer, com encoder-decoder, mecanismo de atenção, tokenizer e camada softmax, permitindo processamento eficiente de textos longos e geração coerente de código e requisitos.

Prompts e Engenharia de Prompts:
A engenharia de prompts é tratada como essencial, incluindo catálogos de padrões de prompt, uso de dicas","LLM, SLM","GPT-x, outros",prompt engineering,,comercial,"ChatGPT, Codex e CoCoNut são usados como assistentes de código e para correção automática de bugs, enquanto BERT e RoBERTa servem como modelos comparativos em tarefas específicas.

QuixBugs é um benchmark padrão para avaliar correção de bugs, e ferramentas como DetectGPT ajudam a identificar conteúdos gerados por IA.

Frameworks de engenharia de prompts permitem automatizar partes do desenvolvimento, como criação de APIs, testes e deploy, e tecnologias multimodais ampliam essas capacidades com visão e voz.","QuixBugs é o principal benchmark usado para avaliar correção automática de bugs, e o desempenho da IA é comparado com ferramentas como Codex e CoCoNut, mostrando resultados semelhantes ou superiores.

A validação também envolve revisores humanos cegos e feedback dos usuários via RLHF, além da observação de arquitetos para avaliar decisões de design feitas pela IA.

Métricas como detecção de plágio, DetectGPT e perplexidade são usadas para avaliar originalidade e identificar conteúdos gerados por IA.

Por fim, avalia-se a capacidade da IA de explicar seu raciocínio e tornar suas decisões mais transparentes por meio de explicações lógicas e visualizações.","coerência, correção funcional, precisão, produtividade, qualidade, redução de esforço, segurança","Aumenta produtividade, automatiza correção de bugs, apoia iniciantes, auxilia na gestão de arquitetura e automatiza subprocessos como APIs, requisitos, testes e deploy.","Pode alucinar, ter dificuldade em tarefas complexas, gerar respostas inconsistentes e usar dados desatualizados.","Necessidade de detectar conteúdo gerado por IA, melhorar raciocínio lógico e ajustar modelos para domínios específicos.","Integração multimodal, personalização, incorporação de aspectos humanos (emoção/empatia) e treinamento contínuo.","Questões éticas e de propriedade intelectual, sobredependência dos desenvolvedores e falta de explicabilidade.",Engenharia de prompts e colaboração humano-IA são vistas como essenciais para uso seguro e eficaz.,"O ChatGPT tem desempenho comparável ou superior em correção de bugs, pode auxiliar fortemente arquitetos e demonstra forte capacidade zero-shot."
A23,Effectiveness of Generative Artificial Intelligence for Scientific Content Analysis,2023,0.5,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Partially attended to,Not attended to,Not attended to,"Ana Karolina (EXCLUÍDO: EC4- Does not address GenAI for SE activities)
Filipe Campos (EXCLUÍDO: EC1: Full text not available for free on the Web or on the CAPES Periódicos plataform)","Moritz Platt, Daniel Platt",Reino Unido,"King’s College London, UK","17th IEEE International Conference on Application of Information and Communication Technologies, AICT 2023 - Proceedings",conference,,,,,,,,,,,,,,,,,,,"""As the goal of the experiments was to generate results that reflected the level of sophistication of laypeople in AI technology, advanced techniques, such as fine tuning or improving data quality through optimization of the input text, were omitted."""
A24,Empowering business transformation: The positive impact and ethical considerations of generative AI in software product management - A systematic literature review,2023,5.0,Scopus,Partially attended to,Fully attended to,Not attended to,Partially attended to,Fully attended to,Fully attended to,Fully attended to,"Leonardo Lima e Silva
Jeniffer","Parikh, Nishant Ashokkumar",Estados Unidos,Capitol Technology University,"arXiv / Transformational Interventions for Business, Technology, and Healthcare",arxiv,"O estudo aponta que a IA generativa contribui para a ER através da automação da elicitação e análise de requisitos, gerando declarações de requisitos em linguagem natural a partir de dados estruturados. Também auxilia na detecção automática de conflitos em documentos de Especificação de Requisitos de Software (SRS) utilizando embeddings de sentenças e apoia a escrita e manutenção de documentação de software.","Construção/Codificação, Design, Gestão de projeto, Requisitos","As técnicas incluem geração automática de código , análise de feedback de clientes para extração de insights , geração de ideias (brainstorming) , incorporação de sentenças baseada em transformadores para detecção de conflitos e estimativa de pontos de história ágil via processamento de linguagem natural.","O artigo explora arquiteturas baseadas em Transformers , Redes Adversariais Generativas (GANs) e Autoencoders Variacionais (VAE). Modelos específicos mencionados incluem GPT-3 , GPT-2 , GPT-NEO-125M e GPT-NEO-1.3B , Codex , ALSI-Transformer , DALL-E2 e Google Bard.","LLM, multimodal","GPT-x, outros","outros, prompt engineering",125000000.0,"comercial, open source","As ferramentas mencionadas incluem GitHub Copilot, OpenAI ChatGPT, OpenAI DALL-E2, Google Bard e ferramentas experimentais como GPT2SP e ALSI-Transformer.","As técnicas de avaliação incluem métricas quantitativas como F1-score, pontuação BLEU , similaridade de cosseno e curvas ROC. Também foram utilizados experimentos para medir o aumento percentual de produtividade (velocidade na conclusão de tarefas) e precisão das estimativas de esforço em comparação com métodos tradicionais.","coerência, custo, outros, precisão, produtividade, qualidade","Redução significativa no tempo e custo de desenvolvimento; aumento da produtividade (ex: tarefas de codificação concluídas 55,8% mais rápido); melhoria na qualidade dos resultados do produto e experiências do usuário final; suporte a trabalhadores menos experientes, nivelando o desempenho; e automação de tarefas tediosas como documentação e análise de feedback.","A precisão e confiabilidade continuam sendo problemas, com riscos de ""alucinações"" (geração de informações incorretas); a natureza de ""caixa preta"" dos modelos limita a interpretabilidade e confiança e a dependência de dados de treinamento de qualidade pode propagar vieses.","Há uma lacuna na compreensão holística do impacto da IA generativa nos negócios e na gestão de produtos para além dos benefícios técnicos. A relação entre serviços de GenAI, engajamento do cliente e lealdade requer mais pesquisas.",Desenvolver modelos de IA generativa mais avançados e específicos para processos de gestão de produtos ; integrar IA com metodologias Ágeis de forma transparente ; criar assistentes de IA personalizados para gerentes de produto ; e avaliar o impacto de longo prazo nos fluxos de trabalho em termos de eficiência e custo.,"Considerações éticas como viés (bias), transparência e responsabilidade ; privacidade de dados e conformidade com regulamentações como GDPR ; riscos legais relacionados a direitos de propriedade intelectual e copyright de conteúdo gerado por IA ; e a necessidade de novas habilidades, como engenharia de prompt.","O artigo é uma revisão sistemática da literatura cobrindo publicações de 2016 a 2023 , utilizando o framework ISPMA para estruturar as aplicações de GenAI na gestão de produtos.","""The study shows that technology can assist in idea generation, market research, customer insights, product requirements engineering, and product development.""; ""Copilot group completed tasks 55.8% faster, marking the first experiment of its kind to provide empirical evidence of the potential of AI tools to enhance human productivity.""; ""However, the technology's accuracy, reliability, and ethical consideration persist."""
A25,Enhancing Software Requirements Engineering with Language Models and Prompting Techniques: Insights from the Current Research and Future Directions,2025,4.0,Scopus,Fully attended to,Partially attended to,Not attended to,Fully attended to,Fully attended to,Not attended to,Partially attended to,"Leonardo Lima e Silva
Jeniffer","Moemen Ebrahim, Shawkat Guirguis e Christine Basta.",Egito,"Institute of Graduate Studies and Research; Faculty of Computers and Data Science, Alexandria University.",Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop).,conference,"O artigo foca na aplicação de IA para a ER, e não o inverso. Contudo, contribui com um framework conceitual que integra Small Language Models (SLMs) e Knowledge-Augmented LMs (KALMs) com LangChain para sistematizar tarefas de ER. Além disso, estabelece diretrizes de engenharia de prompt baseadas em evidências (Contexto, Linguagem, Exemplos, Palavras-chave) específicas para melhorar a confiabilidade na geração de requisitos.",Requisitos,"O estudo explora o uso de Retrieval-Augmented Generation (RAG) para mitigar lacunas de domínio , o uso de Small Language Models (SLMs) para processamento local eficiente , e a orquestração de fluxos de trabalho via LangChain. Também são exploradas técnicas avançadas de prompt, como Chain-of-Verification (CoVe), Chain-of-Knowledge (CoK) e Chain-of-Thought (CoT).","Modelos: O texto menciona GPT-3 e GPT-4 , Llama , TinyLlama e MiniCPM.
Arquiteturas: Transformers , arquitetura modular via LangChain.
Prompts: Zero-shot, Chain-of-Thought (CoT), Chain-of-Verification (CoVe), Contrastive Chain-of-Thought (CCOT), Active Prompting, Automatic Prompt Engineer (APE), Take Step Back (TSB), Rephrase and Respond (RaR) e Chain of Knowledge (CoK).","LLM, SLM","GPT-x, Llama, TinyLlama","RAG, chain of thought, outros, prompt engineering",7000000000.0,"comercial, open source",A principal ferramenta discutida para suporte e orquestração é o LangChain. Ferramentas comerciais como GitHub Copilot e ChatGPT são mencionadas como aplicações práticas existentes.,"INCONCLUSIVO. O artigo afirma que a avaliação de LLMs em ER enfrenta desafios metodológicos devido à falta de datasets padronizados e métricas quantitativas estabelecidas. O framework proposto é teórico e explicitamente evita validação empírica neste estágio. Futuramente, sugere-se avaliação por especialistas.",,"Automação da elicitação de requisitos, detecção de ambiguidade e geração de especificações. Potencial para economia de custos, maior produtividade e melhor gerenciamento de projetos. Redução de erros humanos na documentação. Capacidade de simular papéis de usuários e analisar a qualidade dos requisitos.",Alucinações factuais e saídas não confiáveis. Ignorância do domínio e falta de consciência contextual sobre políticas organizacionais. Altos custos computacionais e operacionais para treinamento e inferência. Riscos de segurança e privacidade de dados. Sensibilidade extrema a variações no fraseado do prompt. Incapacidade de realizar raciocínio dedutivo rigoroso comparável a métodos formais.,"Falta de experimentação com datasets dedicados para tarefas de Engenharia de Requisitos. Ausência de datasets de referência padronizados com ""ground truth"" validado por especialistas. Falta de métricas quantitativas estabelecidas para medir objetivamente a qualidade da saída além do julgamento subjetivo.",Expandir a base de conhecimento dos KALMs para cobrir subdomínios adicionais de ER. Desenvolver templates de prompt padronizados para casos de uso específicos da indústria. Otimizar o pipeline de auto-prompting para fluxos de trabalho complexos de ER. Propor avaliação comparativa de soluções. Validação empírica e implementação técnica do framework proposto.,Riscos de Segurança e Privacidade (TL1). Qualidade e Formatação de Saída Não Confiáveis (TL2). Lacunas de Compreensão de Contexto e Domínio (TL3). Custos Computacionais e Operacionais (TL4). Desafios de Engenharia de Prompt (TL5). Limitações de Raciocínio e Análise (TL6).,"Este trabalho é estritamente uma revisão sistemática seguida de uma proposta de framework conceitual; ele não apresenta uma implementação prática (""proof of concept"") nem dados experimentais. O framework sugere o uso de SLMs para contornar custos e problemas de privacidade, enquanto usa RAG (KALMs) para resolver a falta de conhecimento de domínio.","""Incomplete or ambiguous requirements result in 28% of software defects as per (Mogyorodi, 2021)."" ""This paper proposes a conceptual framework that integrates Small Language Models (SLMs) and Knowledge-Augmented LMs (KALMs) with LangChain to address these limitations systematically."" ""We identify and categorize six technical challenges and two research gaps through a systematic review of LLM applications in SRE."" ""SLMs democratize NLP by reducing costs, lowering resource demands, and allowing faster experimentation for specialized applications."""
A26,Exploring the role of generative AI in enhancing cybersecurity in software development life cycle,2025,0.0,Scopus,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A27,Generating and Reviewing Programming Codes with Large Language Models: A Systematic Mapping Study,2024,6.0,Scopus,Fully attended to,Fully attended to,Fully attended to,Partially attended to,Fully attended to,Fully attended to,Partially attended to,Jeniffer e Leonardo,"Beatriz Ventorini Lins de Albuquerque, Antonio Fernando Souza da Cunha, Leonardo Souza, Sean Wolfgand Matsui Siqueira, Rodrigo Pereira dos Santos","Brasil (com colaborações internacionais citadas nos estudos mapeados: Tailândia, Japão, EUA, Bangladesh, Islândia, Suíça, Canadá, Reino Unido, Austrália, China, Holanda, Índia, Itália, Rússia)",Universidade Federal do Estado do Rio de Janeiro (UNIRIO) e Petrobras,Brazilian Symposium on Information Systems (SBSI '24),conference,"Contribui com um Mapeamento Sistemático da Literatura (MSL) que identifica modelos, estratégias de utilização, desafios e mecanismos de enfrentamento. Ele aplica a teoria Task-Technology Fit (TTF) para entender como as características dos LLMs se ajustam às tarefas de codificação.","Construção/Codificação, Design, Manutenção, Requisitos, Testes","Zero-shot prompting, Transfer Learning, Tokenização, Engenharia de Prompts, Cadeia de Pensamento (implícito em estratégias de raciocínio de modelos como AlphaCode).","GPT-x (ChatGPT, OpenAI Codex), Llama, GitHub Copilot (baseado em Codex), AlphaCode, CodeGen, InCoder, CodeGPT, GPT-Neo, StarCoder (citado como base), UniXcoder. Outros: BERT, CodeBERT, GraphCodeBERT (modelos baseados em Transformer para representação).","LLM, SLM, outro","GPT-x, Llama, outros","outros, prompt engineering",7000000000.0,"comercial, open source","GitHub Copilot, Microsoft Visual Studio IntelliCode, AlphaCode, NLI-GSC (ferramenta autoral), MultiPL-E (framework de benchmark).","Comparação empírica com humanos, benchmarks polyglot (MultiPL-E), análise estática de código, testes funcionais e métricas de PLN.","correção funcional, precisão, produtividade, qualidade, redução de esforço, segurança","Aumento da produtividade, automação de tarefas complexas, suporte a programadores iniciantes e otimização do ciclo de vida de desenvolvimento.","Qualidade inconsistente do código, geração de ""code smells"", dependência de dados de treinamento que podem conter plágio ou licenças restritivas.","Falta de evidências quantitativas para linguagens além de Python, necessidade de melhores métricas de avaliação que não sejam apenas de PLN, e integração de estrutura sintática no pré-treinamento.","Investigar o reparo automático de falhas de segurança, desenvolver ferramentas independentes de linguagem e aprimorar a robustez dos geradores baseados em Deep Learning.","Robustez (gerar códigos diferentes para prompts similares), interpretabilidade dos modelos e questões éticas/legais (licenciamento).","O artigo destaca que, embora a IA seja poderosa, a intervenção humana e o uso de analisadores estáticos (linters) continuam sendo essenciais para garantir a qualidade final do software. O estudo é muito recente (2024), refletindo o estado da arte da integração de LLMs na Engenharia de Software brasileira.","""A utilização de LLM pode ampliar significativamente essa otimização das tarefas de desenvolvimento de código e possibilitar a automação de tarefas mais complexas.""
""Padrões de código ruins podem vazar para a saída dos modelos geradores de código, incluindo problemas de código de segurança."""
A28,Generative AI for Requirements Engineering: A Systematic Literature Review,2025,0.0,Scopus,,,,,,,,,"Haowei Cheng, Jati H. Husen, Yijun Lu, Teeradaj Racharak, Nobukazu Yoshioka, Naoyasu Ubayashi, Hironori Washizaki",Japão e Indonésia,"Waseda University, Tokyo, Japan; Telkom University, Jawa Barat, Indonesia; Advanced Institute of So‐Go‐Chi (Convergence Knowledge) Informatics, Tohoku University, Miyagi, Japan; apan Advanced Institute of Science and Technology (JAIST), Ishikawa, Japan.",Wiley Online Library,journal,,Requisitos,,,,,,,,,,,,,,,,,
A29,"Generative Artificial Intelligence and Large Language Models: A Systematic Review of Architectures, Applications, and Future Directions",2025,0.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,"Heitor e Henrique da Rocha Lima - Excluído (O estudo traz um foco em IA generativa, mas não trabalha muito com a aplicação prática nas áreas de Engenharia de Software)",Bogdan-Iulian Ciubotaru,Romania,"Military Equipment and Technologies Research Agency (METRA), Ministry of National Defence Clinceni, Romania",25th International Conference on Control Systems and Computer Science (CSCS),,,,,,,,,,,,,,,,,,,,
A30,Generative Artificial Intelligence in Agile Software Development Processes: A Literature Review Focused on User eXperience,2025,5.5,Scopus,Fully attended to,Fully attended to,Partially attended to,Partially attended to,Fully attended to,Fully attended to,Partially attended to,Brenno,"Cornide-Reyes, Héctor C. C. and Monsalves, Diego and Durán, Eduardo and Silva-Aravena, Fabian and Morales, Jenny D.",Chile,"Facultad de Ingeniería, Departamento de Ingeniería Informática y Ciencias de la Computación
Facultad de Ciencias Sociales y Económicas, Departamento de Economía y Administración
Escuela de Ingeniería Informática",Springer,journal,"Descrito no artigo, será analisado a metodologia ágil de desenvolvimento de software e será focado na parte de design do software, mais precisamente na parte de UX. a partir dessa metodologia foi analisado qual área desse método se beneficia mais com a integração com GenAI , mostrando que a principal contribuição está no ciclo de vida do software. Além disso, foi citada a área de transformação de necessidades em requisitos.","Arquitetura, Construção/Codificação, Design, Requisitos, Testes","Geração automática de código a partir de linguagem natural, geração de casos teste, prototipagem de interface de usuário, geração de documentação e geração de histórias de usuários","foca em ChatGPT , GitHub Copilot , Tabnine, Cypress Copilot, mas cita outras LLMs de maneira generica",LLM,"GPT-x, outros","multiagent, outros",,comercial,"ChatGPT, GitHub Copilot, Tabnine e Cypress copilot","foram utilizadas técnicas de revisão literária, metodologia PICOC, estudos de casos e pesquisa","carga cognitiva, coerência, custo, precisão, produtividade, qualidade, redução de esforço, segurança","Aumento da eficiência através da automação de tarefas repetitivas, análises preditivas e documentação em tempo real, geração de historias de usuário, definição de prioridade de tarefas com base em requisitos de linguagem natural, automação de escrita e revisão de código (redução da carga de trabalho das equipes), geração de casos teste e detecção precoce de erros. Na fase de manutenção se destaca a usabilidade como auxiliar para a escalabilidade do software e ajuda a analisar métricas de desempenho.","Necessidade de estabelecer estratégias bem definidas para minimizar outras limitações como os riscos da qualidade dos dados, a segurança do código e a transparência do modelo utilizado","Foi notado uma lacuna na compreensão da aplicação da GenAI e seus impactos em algumas áreas críticas do Agile, como planejamento, manutenção e retrospectiva","1- Necessidade de uma avaliação empírica mais aprofundada para avaliar o impacto da GenAI na produtuvidade de equipes ágeis e na qualidade do software.
2- Analisar como as metodologias podem ser adaptadas para maximizar os benefícios da GenAI
3- Metodologias para garantir a ética e uso transparente da GenAI em processos ágeis e estratégias para mitigar riscos","Alguns desafios são mencionados como persistentes em usar GenAI, como a necessidade de confiabilidade nos modelos produzidos pela IA, a interpretabilidade dos seus resultados e as considerações de suas aplicações éticas. Além disso, cita-se o fato de muitas vezes a Ia escrever código com erros ou bugs, mostrando uma necessidade de integrar processos de validação, dependem muito da qualidade do banco de dados. Para as equipes, foi destacado a falta de treinamento técnico e a resistência a adesão da GenAI","O estudo focou bastante em uma metodologia, ágile, mostrando seus pontos fortes e fracos de interseção com GenAI, o que desperta a curiosidade de saber como cada método funcionaria com essa parceria ou se não haveria tanta diferença.",
A31,How Well Small Language Models Can Be Adapted for Software Maintenance and Refactoring Tasks,2026,0.0,Scopus,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A32,How reliance on GenAI might limit human creativity and critical thinking in Requirements Engineering,2025,0.0,Scopus,,,,,,,,Henrique da Rocha Lima E Heitor Dias - Excluido: texto completo indisponivel,"Cabrero-Daniel, Beatriz",Sweden,"Department of Computer Science and Engineering, Chalmers University of Technology, University of Gothenburg, Gothenburg, SE-41296,",CEUR Workshop Proceedings,conference,,,,,,,,,,,,,,,,,,,
A33,Impact of Artificial Intelligence on Open-Source Software Development,2025,3.0,Scopus,Fully attended to,Not attended to,Not attended to,Partially attended to,Partially attended to,Partially attended to,Partially attended to,Ana Karolina e Filipe Campos,"Vinod Kumar Ahuja, Jeremy Clark, Joshua Wurtenberg.",Estados Unidos,"Dept. of Computing & Software Engineering Florida Gulf Coast University Fort Myers, FL, USA","Proceedings of the International Florida Artificial Intelligence Research Society Conference, FLAIRS",conference,"O artigo apresenta uma revisão sistemática de literatura sobre os impactos da IA no desenvolvimento de Software de código aberto
;
Os resultados revelaram três áreas em que a IA está impactando o código aberto: criação e inovação de projetos, eficiência e gestão de desenvolvimento, e qualidade, segurança e ética.","Construção/Codificação, Gestão de projeto, Manutenção, Operações/DevOps, Testes","O artigo traz uma visão muito ampla sem focar especificamente nos resultados encontrados nos artigos analisados, o que acaba se traduzindo mais em tendencias atuais e futuras para o uso da IA no desenvolvimento de software de código aberto
;
Não se aplica.","Não são especificados modelos, técnicas, métodos, o artigo é bem superficial quanto aos resultados das analises dos artigos
;
Não se aplica",,,,,,";
Não se aplica.",";
Não se aplica.","produtividade, qualidade","O artigo traz essa visão em como a IA está beneficiando o desenvolvimento de software desde automação de atividades repetitivas, geração e complementação de código, detecção e análise de bugs, influencia direta como redução de custos pelo alto poder de criação de código da IA.
;
Várias ferramentas baseadas em IA, como geradores de código, detectores de bugs e ferramentas de gerenciamento de projetos com IA, estão reduzindo as contribuições manuais dos voluntários, otimizando os fluxos de trabalho de desenvolvimento e apoiando as colaborações. A IA também deixou mais acessível o trabalho de construir códigos, trazendo para dentro dessa área outras perspectivas, antes, abandonadas. 
As ferramentas de IA estão acelerando dramaticamente os ciclos de desenvolvimento de código aberto por meio de automação que antes era inimaginável, de maneira que tarefas que exigiam muitos recursos agora podem ser realizados com muito menos.
As tarefas relacionadas ao gerenciamento de projeto também foram f","O artigo discorre o fato de como a ampla adoção da IA ​​introduz preocupações éticas, incluindo questões de viés, privacidade e potencial uso indevido, sendo necessário a abordagem de práticas de desenvolvimento e uso responsável e ético dento das comunidades de desenvolvimento de software de código aberto.
;
Não se aplica.","Os autores discorrem que uma possível lacuna é o protocolo de buscas ter incluído apenas artigos escritos em inglês e ampliar esse critérios para outros idiomas poderia enriquecer os achados e consecutivamente as discussões dos resultados, o mesmo ocorre para o critério de incluir apenas artigos publicados em periódicos e revisados em pares, que outras fontes poderiam enriquecer as conclusões.
;
Não se aplica.",";
Mesmo com esse estudo a aplicação de IA à projetos open-source não é explorada suficientemente.
Estudos longitudinais examinando a evolução da integração de IA e OSS ao longo do tempo. Investigações empíricas sobre como a IA afeta a diversidade, inclusão e estruturas de governança dos contribuintes em comunidades OSS.Implicações éticas do uso da IA em OSS, especialmente em relação a viés, transparência e justiça. Análises comparativas entre metodologias de desenvolvimento OSS baseadas em IA e tradicionais. Investigar a relação recíproca entre OSS e IA—especificamente como os princípios de código aberto influenciam práticas de desenvolvimento de IA—contribuiria para um entendimento mais holístico desse dinâmico ecossistema tecnológico.",";
desafios relacionados à transparência do software, confiabilidade e o papel da supervisão humana no desenvolvimento assistido por IA.
Evidências apontam que a IA pode, inadvertidamente, limitar a inclusão de desenvolvedores, possivelmente devido à natureza corporativa de muitos modelos de IA.
A adoção generalizada da IA introduz preocupações éticas, incluindo questões de viés, privacidade e uso indevido potencial","Esse estudo tem como conteúdo como a IA afeta o desenvolvimento de código aberto, não explicitando um modelo em específico ou técnicas usadas, mas sim as consequências. Acredito que tenha sido uma revisão apenas para trazer uma visão ampla sobre o tema, o foco não foi em técnicas e nem em uma distribuição longitudinal do avanço do uso da IA em OSS, os autores trouxeram uma visão geral sobre áreas da OSS que estão usando IA e preocupações e benefícios do seu uso.",";
""The ubiquitous inclusion of AI has made the lack of software knowledge andskills more apparent, making it necessary for communities to address industry pain ppoints, such as filling skill gaps [6, 23], removing reliability concerns [33], and even fulfilling cloud computing needs and creating new operating systems to support AI [9]""
""A central takeaway from this study is the surge in new open-source projects, which address both the challenges and opportunities created by AI"""
A34,Impacts of the Usage of Generative Artificial Intelligence on Software Development Process,2024,5.5,Scopus,Fully attended to,Fully attended to,Not attended to,Partially attended to,Fully attended to,Fully attended to,Fully attended to,"Ana Karolina (EXCLÚIDO: EC2- Not Written in english)
Filipe Campos (EXCLÚIDO: EC2- Not Written in english)","Patrícia de Oliveira Santos, Allan Chamon, Pedro Nuno de Souza Moura, Bruna Diirr, Adriana Cesario de Faria Alvim, Rodrigo Pereira dos Santos",Brasil,Universidade Federal do Estado do Rio de Janeiro (UNIRIO),ACM International Conference Proceeding Series,conference,O artigo contribui para a Engenharia de Software ao analisar artigos que envolvam o uso da IA generativa em atividades do processo de desenvolvimento de software. As contribuições incluem: evidência empírica do uso real de GenAI no processo de ES e identificação de atividades mais impactadas pela IA generativa.,"Arquitetura, Construção/Codificação, Requisitos, Testes","O trabalho ressalta os achados através do mapeamento sistemático de literatura e dentro dos artigos analisados são destacadas as técnicas de IA que foram evidenciadas nos trabalhos que auxiliam certas atividades da Engenharia de Software como: algoritmos de ML e um modelo de LLM não especificado que podem auxiliar em atividades de analise de requisitos, arquitetura de software, codificação e testes.","O MSL cita o ChatGPT (modelos 3 e 4), o GitHub copilot, um chatbot não especificado e o Codex.",LLM,"GPT-x, outros",prompt engineering,,comercial,ChatGPT e GitHub,Não foram apresentadas técnicas de avalição,,"Os benefícios possíveis de serem identificados no artigo são: Melhoria da produtividade com o uso da IA, facilitação do processo de codificação e auxilio em tarefas repetitivas tanto na parte de codificação quanto em arquitetura.","As limitações são mais evidentes em preocupações sobre o quanto os profissionais podem confiar no produto da analise da IA como se o código é seguro ou não, se a resposta não é uma alucinação e estudos que tratam sobre produtividade não apresentarem dados quantitativos para enriquecer a análise, além disso os trabalhos encontrados se limitaram a poucas áreas da ES sendo a maioria para a área da codificação.","As oportunidades de pesquisa residem em justamente abranger outras áreas da ES no processo de inserção da IA em suas atividades, como evidenciado pelo MSL a maioria dos trabalhos estão focado na área de codificação e teste, ficando as outras áreas da ES pouco ou ainda não exploradas.","Como trabalho futuro os autores citam que poderá ser realizado um mapeamento mais abrangente contemplando outras bases acadêmicas
e outras atividades do processo de desenvolvimento, contemplando também as atividades das etapas de Operação e a Manutenção do
processo de desenvolvimento.","O maior desafio citado é na confiabilidade da resposta, sendo essencial o fator humano para validar a resposta da IA, essa confiabilidade também é refletida na codificação onde uma das preocupações é se o código gerado realmente é seguro.","O trabalho viola um dos critérios de exclusão (trabalho escrito em inglês) por si só ele já deveria ser excluído, com a análise do mesmo, não acredito que ele traga evidências que possam somar significativamente a ponto de abranger para o português esse critério, as informações apresentadas acabaram sendo mais do mesmo que já vimos em outros trabalhos.",
A35,Insight into code clone management through refactoring: a systematic literature review,2025,0.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Ana Karolina Excluído (EC4: Does not address genAI for SE activities),"Manpreet Kaur, Dhavleesh Rattan, Madan Lal",Índia,"Department of Computer Science and Engineering, Baba Banda Singh Bahadur Engineering College, Fatehgarh Sahib, Punjab, India;  Department of Computer Science and Engineering, Punjabi University, Patiala, Punjab, India",Computer Science Review,journal,,"Construção/Codificação, Manutenção",,,,,,,,,,,,,,,,,
A36,LLM-Based Code Generation: A Systematic Literature Review With Technical and Demographic Insights,2025,6.0,Scopus,Fully attended to,Fully attended to,Not attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Henrique da Rocha Lima E Heitor Dias,"Umama
Usman Danyaro, Kamaluddeen
Nasser, Maged
Zakari, Abubakar
Abdullahi, Shamsu
Khanzada, Atika
Muntasir Yakubu, Muhammad
Shoaib, Sara",malasia,"Universiti Teknologi PETRONAS, Faculty of Science, Management and Computing, Department of Computing, Perak, Seri Iskandar, 32610, Malaysia",,journal,"Técnicas e Abordagens
Esquemas de classificação organizam contribuições em modelos, frameworks, abordagens, estudos de avaliação e estudos investigativos.
Técnicas de refinamento incluem self-planning e melhoria genética.
Feedback interativo usa linguagem natural e geração orientada a testes para melhorar a precisão e lidar com ambiguidade.

Processos e Metodologias
Revisões sistemáticas da literatura (baseadas em PRISMA) garantem rigor e reprodutibilidade.
Benchmarks padronizados (HumanEval, MBPP, APPS) acompanham o progresso dos LLMs.
As avaliações são alinhadas a padrões de qualidade de software (ex.: ISO/IEC 25010).

Ferramentas e Frameworks
Ferramentas de avaliação como EvalPlus e CodeSecEval medem correção e segurança.
Análise estática e execução automática verificam o código.
Pipelines arquiteturais (ex.: L2MAC) usam sistemas multiagente para geração de código complexo.

Métricas
Correção funcional: Pass@k, taxa de sucesso em testes.
Execução: sucesso de compilação e correção em",Construção/Codificação,"Arquiteturas e Modelos Fundamentais
Transformers e atenção como base dos LLMs.
Arquiteturas codificador-decodificador (CodeT5+, T5).
Modelos específicos de código: Codex, CodeGen, StarCoder, LLaMA-3.

Estratégias de Aprendizado e Ajuste
PEFT para adaptação eficiente.
Reinforcement Learning (ex.: CodeRL).
Destilação de conhecimento (ex.: CodePLAN).
Aprendizado por imitação com feedback em linguagem natural (ILF).

Engenharia de Prompt e Técnicas de Raciocínio
In-Context Learning (ICL).
Self-planning (planejamento + implementação).
Brainstorming de estratégias antes do código.
Prompting de “pensamento lento”.
Prompting guiado por personalidade.

Frameworks Operacionais e de Refinamento
Arquiteturas multiagente e pipelines (ex.: L2MAC).
Busca em árvore guiada por agentes (CodeTree).
Algoritmos evolutivos e melhoria genética (GI/GE).
Amostragem especulativa para reduzir latência.

Técnicas de Recuperação e Verificação
RAG para fornecer contexto externo.
Feedback iterativo e autocorreção co","Modelos de Aprendizado de Máquina (LLMs)
Uso predominante de LLMs baseados em transformers.
Modelos de código: Codex, CodeT5/CodeT5+, CodeGen, StarCoder, CodeLlama, StarCoder2.
Modelos gerais: GPT-4o, GPT-4, GPT-3.5 Turbo, LLaMA-3, Gemini Pro, Claude.
Modelos especializados: WizardCoder-Python-13B, PEFT-Code, CodeRL.

Modelos de Linguagem Pequenos (SLMs)
Destilação de conhecimento (ex.: CodePLAN) para transferir capacidades de LLMs.
Uso de PEFT e quantização para eficiência e melhor desempenho com menos recursos.

Estratégias de Prompting
Raciocínio: Chain-of-Thought, Self-Planning, Slow Thinking.
Colaboração: Brainstorming e ClarifyGPT.
Contexto: Prompting por personalidade e em nível de repositório.
ICL: Uso de demonstrações (ex.: DemoCraft).

Arquiteturas de Sistemas
Arquiteturas de modelo: Transformers e Encoder-Decoder (ex.: T5).
Pipelines e agentes: L2MAC, multiagentes e CodeTree.
Verificação: Arquiteturas com ator-crítico e pipelines de autocorreção com feedback de execução e an","LLM, SLM","GPT-x, Llama, StarCoder, outros","chain of thought, outros",,"comercial, open source","Ferramentas de Avaliação e Benchmarking
Avaliam automaticamente a qualidade e correção do código gerado.
EvalPlus, CODET, AutoCodeEval, ClassEval, CodeSecEval e RMCBench.

Frameworks de Refinamento e Depuração
Ajudam a melhorar iterativamente o código gerado.
SELFEVOLVE, CodeTree, LlmFix e DeCon.

Ferramentas de Arquitetura e Gestão de Tarefas
Organizam o uso de IA em projetos de software complexos.
L2MAC, ClarifyGPT, ArchCode e RepoPrompt.

Ferramentas Práticas de Desenvolvimento (IDE)
Ferramentas já usadas no dia a dia.
GitHub Copilot, ToolGen e Mendeley.","Correção Funcional
Verifica se o código realmente funciona.
Pass@k, taxa de sucesso em testes e testes unitários.

Métricas de Execução
Avaliam se o código compila e roda corretamente.
Sucesso de compilação, corretude em tempo de execução e taxas de falha.

Similaridade e Classificação
Comparam código gerado com soluções de referência ou classificam código.
BLEU, CodeBLEU, ROUGE, Levenshtein, Acurácia, Precisão, Recall, F1.

Avaliação Humana e Feedback
Capturam qualidade, legibilidade e manutenibilidade.
Julgamento humano, complexidade ciclomática e taxa de conclusão de tarefas.

Segurança e Robustez
Avaliam riscos e comportamento ético.
Detecção de vulnerabilidades, mitigação de viés e taxas de recusa.

Técnicas Avançadas
Tornam a avaliação mais rigorosa.
Slow Thinking (CODEJUDGE), geração automática de testes (EvalPlus) e avaliação em nível de repositório/classe (HumanEvo, ClassEval).","cobertura, correção funcional, outros, precisão, qualidade, recall, segurança","A IA generativa aumenta significativamente a produtividade e a qualidade do software, automatizando tarefas como autocompletar código, detecção de erros, sumarização e tradução de requisitos em código executável, além de demonstrar forte capacidade de raciocínio e adaptação por meio de ajuste fino em dados específicos.","Os benchmarks atuais têm escopo restrito a funções isoladas, há inconsistência semântica entre linguagem natural e código, alto custo computacional para treinar modelos de base e funcionamento em “caixa-fechada”, dificultando a validação e compreensão das decisões do modelo.
;
Modelos apresentam queda significativa de desempenho em: problemas longos, tarefas multi-arquivo e código em nível de repositório","Faltam benchmarks em nível de sistema e projeto, padrões de qualidade alinhados a normas como ISO/IEC 25010, maior cobertura de domínios especializados e esquemas de anotação consistentes e multilíngues.","Os estudos apontam para mitigação de alucinações com verificação semântica e feedback adaptativo, integração de segurança em todo o pipeline, criação de métricas multidimensionais combinando avaliação automatizada e humana, e desenvolvimento de arquiteturas mais transparentes e interpretáveis.","Os principais desafios incluem alucinações, vulnerabilidades de segurança, baixa generalização para projetos complexos e novas linguagens, além de riscos adversariais por meio de prompts maliciosos.","O campo atingiu pico de publicações em 2024, é dominado principalmente por China e Estados Unidos, e embora a maioria dos estudos seja acadêmica, a colaboração com a indústria é essencial para aplicações práticas.
;
Na seção IV.B, o estudo evidenciou que propostas dos estudos em IA generativa para Engenharia de Software estão evoluindo de usos isolados de LLMs para soluções mais estruturadas e sistemáticas. Os frameworks propostos incorporam ciclos iterativos de planejamento, geração e avaliação, combinando LLMs com práticas clássicas de ES, como testes automatizados, execução real do código e validação contínua, o que revela um reconhecimento claro de que a geração direta de código, sem controle, é insuficiente para aplicações confiáveis.","O artigo destaca que alucinações podem minar a confiança dos desenvolvedores, que há uma mudança de foco para avaliações e frameworks mais viáveis, que benchmarks atuais podem superestimar capacidades práticas e que muitos modelos ainda operam como sistemas de caixa-fechada.
;
""O DeCon requer apenas um pequeno conjunto de entrada/saída (E/S). Resultados experimentais demonstram que o DeCon detecta, em média, mais de 64% de asserções incorretas, 63% usando GPT-3.5 e 65,5% usando GPT-4, em asserções produzidas por quatro LLMs de última geração. Além disso, o DeCon melhora o desempenho de geração de código desses modelos em 4% em termos de Pass@1. ""
""No estudo de [38], o autor propôs o CodeTree, uma estrutura projetada para aprimorar o desempenho de agentes LLM em tarefas de geração de código, abordando limitações no planejamento, geração e depuração em múltiplos estágios, especialmente em cenários com vastos espaços de busca. O CodeTree introduz uma estrutura de árvore unificada que perm"
A37,"LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision, and the Road Ahead",2025,4.0,Scopus,Partially attended to,Fully attended to,Not attended to,Fully attended to,Fully attended to,Not attended to,Partially attended to,Heitor,"Junda He, Christoph Treude e David Lo",Singapore,"Singapore Management University,Singapore","ACM Transactions on Software Engineering and MethodologyVolume 34, Issue 5: ACM TOSEM 2030 Roadmap for Software Engineering",journal,"A IA Generativa contribui para a Engenharia de Software ao automatizar tarefas de desenvolvimento, apoiar todas as fases do SDLC, aumentar produtividade, melhorar a qualidade dos artefatos, reduzir esforço humano, apoiar a tomada de decisão e viabilizar sistemas multiagentes colaborativos","Arquitetura, Construção/Codificação, Design, Gestão de projeto, Manutenção, Operações/DevOps, Requisitos, Testes","Técnicas de IA generativa baseadas principalmente em Large Language Models integrados a sistemas multiagentes, incluindo geração automática de código, decomposição e planejamento de tarefas, simulação de papéis da engenharia de software, validação cruzada entre agentes, geração de testes, debugging automático, raciocínio reflexivo e geração orientada a processos de desenvolvimento ao longo do ciclo de vida do software.","- Large Language Models de grande porte, como ChatGPT, GPT-3.5/4, LLaMA, Claude e Gemini, utilizados como núcleo cognitivo de sistemas multiagentes
- Modelos menores (SLMs) não são foco central 
- As técnicas de prompting incluem prompting orientado a papéis de Engenharia de Software, prompting baseado em tarefas, reflexão iterativa e validação por crítica ou debate
- As arquiteturas predominantes são sistemas multiagentes baseados em LLM, organizados de forma hierárquica, descentralizada ou híbrida",LLM,"Claude, GPT-x, Llama","multiagent, prompt engineering, self refine",,,"Frameworks e sistemas multiagentes baseados em LLM, formados por plataformas de orquestração e agentes com papéis especializados. O estudo cita exemplos como Elicitron, PairCoder, Fuzz4All, MASAI e ChatDev, entre outros.","Os estudos de IA Generativa para Engenharia de Software avaliam os modelos principalmente por meio de correção funcional, execução e testes, validação cruzada entre agentes, consenso e ranqueamento de resultados, qualidade dos artefatos de software, estudos de caso empíricos e, em alguns cenários, avaliação humana, priorizando métricas alinhadas às práticas reais da ES em vez de métricas puramente linguísticas","correção funcional, custo, precisão, produtividade, qualidade, recall, redução de esforço, segurança","1 - Resolução autônoma de problemas
2 - Maior robustez e tolerância a falhas
3 - Escalabilidade para sistemas complexos
4 - Aceleração do ciclo de vida de software - Automatizar atividades em todas as fases do SDLC: engenharia de requisitos, geração de código, testes e QA, detecção de vulnerabilidades e bugs, manutenção e depuração, desenvolvimento end-to-end (Waterfall e Agile).","IA Generativa na Engenharia de Software é limitado por alucinações, ausência de garantias formais de correção correta, dependência de intervenção humana, alto custo computacional, baixa evidência em sistemas industriais de larga escala, falta de padronização na avaliação, limitações métricas e riscos de segurança","Ausência de garantias formais de corretude, falta de benchmarks padronizados, baixa evidência em sistemas industriais de larga escala, alto custo computacional, limitações de explicabilidade, integração insuficiente com processos de ES, pouca atenção ao fator humano, desafios de segurança e ausência de arquiteturas consolidadas para coordenação de agentes","1 - Combinar LLMs e sistemas multiagentes com: verificação formal, model checking e contratos e invariantes formais
2 - Validar sistemas GenAI em: projetos reais, grandes bases de código e ambientes industriais.
3 - Redução do custo de sistemas multiagentes
4 - Estudo sistemático de: arquiteturas multiagentes, mecanismos de comunicação, atribuição dinâmica de papéis e estratégias de consenso
5 - Criação de benchmarks específicos para ES + GenAI, padronização de métricas, protocolos de avaliação reprodutíveis
6 - Sistemas GenAI capazes de: atuar continuamente em todas as fases do SDLC, adaptar-se a mudanças de requisitos e participar como membros ativos de equipes ágeis 
7 - Tornar decisões dos sistemas GenAI: explicáveis e auditáveis
8 - Avaliação centrada no fator humano
9 - Garantir que sistemas GenAI: não introduzam vulnerabilidades, sejam robustos contra uso malicioso e adotem princípios de segurança por design","Confiabilidade e alucinações dos modelos, ausência de garantias formais, coordenação eficiente de agentes, escalabilidade para sistemas reais, alto custo computacional, avaliação não padronizada, integração com processos de ES, falta de explicabilidade, desafios humanos e organizacionais e questões de segurança e uso responsável","O estudo traz dois caso de teste no desenvolvimento de um jogo.

O estudo não traz um modelo específico de IA Generativa, trabalhando apenas de forma geral os LLMs, como ChatGpt, Claude e etc. Apenas mencionando como o núcleo de processamento dos multi-agentes.","""Nesta seção, revisamos estudos recentes sobre sistemas LMA em ES, organizando essas aplicações através de vários estágios do ciclo de vida de desenvolvimento de software (SDLC), incluindo engenharia de requisitos, geração de código, QA e manutenção de software. Também examinamos estudos sobre sistemas LMA para desenvolvimento de software de ponta a ponta (end-to-end), cobrindo múltiplas fases do SDLC em vez de estágios isolados.""

""O Elicitron [9] é um framework LMA que foca especificamente no estágio de elicitação. Ele utiliza agentes baseados em LLM para representar uma gama diversa de usuários simulados. Esses agentes se engajam em interações simuladas com o produto, fornecendo insights sobre as necessidades dos usuários ao articular suas ações, observações e desafios. O MARE [59] é um framework LMA que cobre múltiplas fases da engenharia de requisitos, incluindo elicitação, modelagem, verificação e especificação. Ele emprega cinco agentes distintos: stakeholder, coletor, modelador"
A38,Landscape and Taxonomy of Prompt Engineering Patterns in Software Engineering,2025,3.0,Scopus,Partially attended to,Partially attended to,Not attended to,Partially attended to,Fully attended to,Not attended to,Partially attended to,Heitor e Henrique da Rocha Lima,Yuya Sasaki; Hironori Washizaki; Jialong Li; Nobukazu Yoshioka; Naoyasu Ubayashi; Yoshiaki Fukazawa,Japão,"Waseda University, Tokyo 169-8555, Japan",IEEE Computer Society,journal,"A ES fornece técnicas que tornam sistemas de IA/ML mais confiáveis, reutilizáveis e compreensíveis (como engenharia de requisitos para IA/ML, prompt engineering e prompt patterns, arquiteturas de software para sistemas de ML e teuso e padrões de projeto","Construção/Codificação, Design, Manutenção, Testes","Prompt engineering, few-shot learning, zero-shot learning, interactive prompting, prompt translation e context management","O estudo investiga o uso de LLMs baseados em Transformer, como Codex, GPT-3/3.5 e modelos especializados em código (CodeT5, CodeGen, PolyCoder), aplicados à Engenharia de Software. A adaptação desses modelos ocorre exclusivamente por meio de prompt engineering, incluindo prompts few-shot, zero-shot, encadeados, interativos e introspectivos. O artigo não propõe novas arquiteturas de aprendizado de máquina, nem distingue formalmente SLMs, focando em arquiteturas de uso baseadas em interação humano–modelo e ajuste via prompts.",LLM,GPT-x,"chain of thought, prompt engineering, reAct",,,Não se aplica,"O estudo avalia o uso de IA generativa em Engenharia de Software principalmente por meio de métricas de qualidade de software baseadas na ISO/IEC 25010, classificação sistemática dos padrões de prompt, análise de cobertura dos estudos e avaliação qualitativa dos resultados reportados. Não são conduzidos benchmarks quantitativos tradicionais de aprendizado de máquina, sendo a avaliação orientada às práticas e critérios da Engenharia de Software.","outros, qualidade, segurança","O estudo aponta que o uso de GenAI em Engenharia de Software traz benefícios como melhoria da qualidade do software (avaliada via ISO/IEC 25010), aumento da eficiência e produtividade, suporte a tarefas complexas, melhor interação humano–IA, flexibilidade de adaptação por meio de prompt engineering e aplicação em múltiplas atividades do ciclo de vida de software.","""One limitation is that our findings reflect AI models as of mid-2023, when LLMs have shorter context lengths and limited inference capabilities. As LLMs evolve, prompt strategies must adapt to remain effective.""","1 - Engenharia de requisitos: ""Underexplored domains: Expand to areas such as software requirements,15 leveraging LLMs to streamline elicitation and design processes""
2 - Avaliação quantitativa rigorosa: "" Formal analysis: Develop frameworks for quantitative evaluation of prompt effectiveness in the real world, standardizing metrics across LLMs""
3 - Integração multimodal: ""Multimodal LLMs: Leverage LLM advancements to integrate diverse inputs such as diagrams for enhanced task support""
4 - Validação empírica em contextos reais: ""Ethics and security: Address biases and secure practices to build trust in LLM applications""","""Answer to RQ3: Future Research Should Enhance LLM Capabilities in Underexplored Software Domains, Implement Formal Analysis Frameworks to Validate Implementations Through Real-World Studies, Explore Nontextual Inputs for Multimodal LLMs, and Secure Ethical Standards ""","1 - Dependência de prompts bem projetados
2 - Falta de sistematização no uso de prompts
3 - Risco de respostas incorretas ou alucinações
4 - Dificuldade em avaliar qualidade de forma objetiva
5 - Uso desigual entre atividades de ES","A principal contribuição deste artigo é: ""SLR of prompt engineering patterns in software engineering. We propose a taxonomy of these patterns, emphasizing their role in improving the accuracy, efficiency, and scalability of LLM-driven tasks. By analyzing both the state-of-the-art techniques from 2023 and emerging capabilities of LLMs in 2024, we demonstrate that effective prompt patterns are crucial for maximizing the potential of LLMs. This study provides insights to help researchers and practitioners better understand and apply these techniques in the evolving landscape of LLM applications. a This article substantially extends our preliminary article presented at 2024COMPSAC.1 We have reviewed and added patterns, revised the descriptions, and included a quality-based pattern analysis.""

Obs.: O artigo afirma que usou de literatura cinza em sua composição de estudos -> ""Our taxonomy is based on a comprehensive literature review of both peer-reviewed and gray literature, capturing the","""We identified 26 prompt engineering patterns and classified them into four major categories:
1) PA. Learning approach: Eight articles address the pattern that is used to provide the context necessary for their purpose to LLMs. The fewshot approach was introduced in many articles, whereas some used zero shot.
2) PB. Interaction-focused methods: Eight articles discuss methods that are used to enrich the output. These methods range from submitting relatively simple requests to an LLM, to more extensive task decomposition through mutual communication.
3) PC. Task-specific patterns: Eight articles discuss the specific patterns of tasks around software engineering. There were many patterns for code generation or specification, or comment generation from code.
4) PD. Model optimization: Two articles introduced prompt engineering patterns that are related to model tuning. The articles in this category introduced prompts to tune the model parameters to specified tasks to elicit the model’s pot"
A39,Large Language Model for Vulnerability Detection and Repair: Literature Review and the Road Ahead,2025,6.5,Scopus,Fully attended to,Fully attended to,Fully attended to,Partially attended to,Fully attended to,Fully attended to,Fully attended to,,,,,,,,,,,,,,,,,,,,,,,,,
A40,Large Language Models for Early-Stage Software Project Estimation: A Systematic Mapping Study,2025,7.0,Scopus,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,,,,,,,,,,,,,,,,,,,,,,,,,
A41,Large Language Models for Software Engineering: A Systematic Literature Review,2024,7.0,Scopus,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Brenno,"Hou, Xinyi and Zhao, Yanjie and Liu, Yue and Yang, Zhou and Wang, Kailong and Li, Li and Luo, Xiapu Daniel and Lo, David and Grundy, John C. and Wang, Haoyu","China, Singapura e Austrália",Huazhong University os Science and Technology,ACM - Digital Library,journal,"O artigo foca principalmente no uso de LLMs para ES, mas também destaca a contribuição da ES na criação de benchmarks específicos para código, técnicas de avaliação robustas para modelos de linguagem em tarefas de programação e engenharia de prompts aplicada a contextos de software.","Arquitetura, Construção/Codificação, Design, Gestão de projeto, Manutenção, Requisitos, Testes","As principais técnicas observadas são Prompt Engineering, Ajuste fino de modelos pré-treinados em datasets de código e RAG","Os modelos com mais destaque no artigo são GPT-3, GPT-3.5 (ChatGPT), GPT-4, Codex, LLaMA, StarCoder, CodeGen, PaLM, seguido por T5, CodeT5, BART, PLBART e depois por BERT, CodeBERT, CuBERT.",LLM,"GPT-x, Llama, outros","RAG, chain of thought, prompt engineering",,comercial,"As ferramentas que deram suporte a esse estudo foram ferramentas de LangChain (para orquestrar LLM's), ferramentas de análises como Pytest e plataformas de datasets","Foram exploradas técnicas de Benchmark automatizado, avaliação humana e comparação com linhas de base","correção funcional, precisão, qualidade","Foram destacados benefícios como o aumento da produtividade de forma significativa, a capacidade de generalização de múltiplas linguagens de programação e a facilitação de automação de algumas tarefas repetitivas.","As limitações identificadas incluem alucinações (quando o código está incorreto por exemplo), dificuldade de processar repositórios inteiros, conhecimento desatualizado e respostas inconsistentes para um mesmo prompt","Falta de benchmarks para tarefas complexas de nível de repositório (além de funções simples), necessidade de técnicas para lidar com a evolução rápida das bibliotecas de software, melhorar a explicabilidade e a capacidade de depuração dos modelos","É destacado para trabalhos futuros a melhoria de Benchmarks, LLMs especializados para engenharia de software, melhoria na qualidade e confiança e a integração com ferramentas tradicionais","Foram encontrados desafios no quesito de segurança quanto ao vazamento de dados, o elevado custo computacional para treinamento de modelos grandes e a dificuldade de confiar cegamente nos códigos gerados por causa dos erros","Como vários outros estudos, esse destaca muito o quesito de erros de códigos e a segurança de dados, creio ser uma área que necessite de atenção",
A42,Large Language Models for Service-Oriented Computing (LLM4SOC): Review and Research Directions,2026,0.0,Scopus,,,,,,,,Henrique da Rocha Lima - Texto completo indisponível,,,,,,,,,,,,,,,,,,,,,,,,
A43,Large Language Models for Software Engineering: A Systematic Mapping Study,2024,0.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,"Jeniffer - (Artigo EXCLUÍDO por não ter acesso completo em nenhuma fonte.)
Leonardo - (Artigo EXCLUÍDO por não ter acesso completo em nenhuma fonte.)","Görmez, Muhammet Kürşat and Yilmaz, Murat and Clarke, Paul M.",,EuroSPI,"Communications in Computer and Information Science ((CCIS,volume 2179))",conference,,,,,,,,,,,,,,,,,,,
A44,Learning-Based Automated Program Repair: A Systematic Literature Review,2025,5.0,Scopus,Partially attended to,Fully attended to,Partially attended to,Partially attended to,Fully attended to,Partially attended to,Fully attended to,Jeniffer e Leonardo,"Qijia Chen, Dongcheng Li, Man Zhao, W. Eric Wong, Hui Li",China (maioria) e EUA (dois autores),"School of Computer Science, China University of Geosciences, Wuhan 430078, China; Department of Computer Science, California State Polytechnic University, Humboldt, CA 95519, EUA; Department of Computer Science, University of Texas at Dallas, Richardson, TX 75080, EUA",Complex System Modeling and Simulation,journal,"Técnicas: Geração de patches via NMT, representações de código (sequência, árvore, grafo), fine-tuning de LLMs.
Processos: Localização de falhas, geração de patches, verificação de patches.
Ferramentas: Frameworks de APR como DeepFix, SequenceR, CodeT5, ChatGPT.
Métricas: Precisão, recall, F1, BLEU, CPR, AUC.","Construção/Codificação, Manutenção, Testes",Aprendizado supervisionado (ex.: RNN e LSTM para correção de erros de sintaxe); Aprendizado não supervisionado (para reparo sem dados rotulados explícitos); Aprendizado por transferência (fine-tuning de modelos pré-treinados como BERT para tarefas de reparo); Aprendizado ensemble (combinação de múltiplos modelos para melhorar efetividade e estabilidade); Aprendizado baseado em modelos de linguagem (usando LLMs para gerar patches em tarefas complexas).,"MLMs/SLMs: RNN, LSTM, GRU, CNN, Transformer, GNN (Graph Neural Networks), BERT, GPT, T5, Codex (menções a modelos menores implícitas em contextos de eficiência). Prompts: Prompts multimodais, consultas iterativas, seleção baseada em casos de teste. Arquiteturas: Encoder-decoder (para NMT), Seq2Seq, Tree-LSTM (para representações baseadas em árvore), GNN (para grafos de código).","LLM, SLM, outro",GPT-x,"chain of thought, outros, prompt engineering",13000000000.0,"comercial, open source","DeepFix, SequenceR, CoCoNuT, TFix, CURE, DEAR, VRepair, Repilot, InferFix, MMAPR, ThinkRepair","Validação com datasets padrão (Defects4J, QuixBugs)
Execução de testes unitários
Comparação com patches humanos
Métricas de similaridade (BLEU)","outros, precisão, recall","Automatiza o reparo de defeitos, reduz custos de debugging e manutenção; Aplica-se a cenários amplos, incluindo multilíngues; Melhora a eficiência (ex.: LLMs reparam 46%–164% mais erros que métodos DL tradicionais); Integra conhecimento para padrões de reparo; Aumenta a confiabilidade de código gerado por modelos.",Baixa taxa de sucesso em reparos (<20% para defeitos complexos); Overfitting de patches (corrigem testes mas não o defeito real); Dependência de dados labeled escassos; Altos custos computacionais em ensemble e LLMs; Fraca generalização para tipos de erros não vistos ou estruturas novas; Dificuldades em interpretação de modelos complexos.,Incorporar mais conhecimento de domínio e análise de programas para reparos complexos (ex.: interações multimódulos); Melhorar generalização para defeitos não vistos; Explorar reparo multilíngue e de vulnerabilidades; Desenvolver métricas mais robustas para avaliação; Integrar testes automáticos para mitigar overfitting.,Incorporar domain knowledge e técnicas de análise de programas para melhorar reparo de defeitos complexos; Desenvolver testes automáticos e de regressão mais robustos para evitar novos erros; Explorar LLMs para reparo multilíngue e em cenários reais; Melhorar eficiência e acurácia de APR; Realizar mais estudos empíricos sobre performance de modelos pré-treinados em vulnerabilidades.,Acurácia em reparos complexos e vulnerabilidades; Generalização para novos tipos de erros ou linguagens; Verificação de patches e riscos de overfitting; Complexidade de linguagens de programação e datasets; Altos custos computacionais e dependência de dados de alta qualidade; Interpretação e explicabilidade de modelos black-box.,"O artigo apresenta uma revisão sistemática abrangente sobre o uso de técnicas de Deep Learning aplicadas ao reparo automático de programas (APR). Os autores organizam o vasto campo de estudos em uma taxonomia estruturada, facilitando a compreensão de como a área evoluiu de modelos estatísticos simples para arquiteturas neurais complexas.","""The success rate of existing models is relatively low, especially for complex programming tasks. For example, while deep learning models have strong expressive power, they are highly dependent on data and struggle to generalize across domains.""
""Patch generation is the core of automated program repair technology. Even when faults are located correctly, existing APR techniques can only fix a small proportion of defects (< 20%)."""
A45,Leveraging AI-driven requirements for SysML modeling of the IoBT: A comprehensive investigation,2025,4.5,Scopus,Partially attended to,Fully attended to,Partially attended to,Partially attended to,Fully attended to,Partially attended to,Partially attended to,Heitor e Henrique da Rocha Lima,Joseph Brooks,Estados Unidos,Middle Georgia State University,Issues in Information Systems,journal,"A ES fornece técnicas para projetar, estruturar e manter sistemas de IA/ML (arquitetura de Software, engenharia de requisitos para IA, design e manutenibilidade de modelos). Integração com MBSE, onde a ES aparece explicitamente como o meio para operacionalizar IA via MBSE. Uso de SysML como ferramenta. Processos estruturados e workflows.",Requisitos,"LLMs (ex.: ChatGPT), NLP generativo, geração automática de requisitos, tradução texto-para-modelo (SysML), prompting estruturado e estratégias iterativas com human-in-the-loop.","- O estudo trabalha em foco nos MLMs em foco de LLMs como o chatGpt. Detalhe importante: o estudo não propoe novos tipos de LLMs
- Os modelos SLMs não são muito trabalhados nem específicados no estudo
- Prompting estruturado, prompting iterativo e estratégias com human-in-the-loop
- Arquitetura conceitual pipeline integrando LLMs à engenharia de requisitos e MBSE/SysML",LLM,GPT-x,"prompt engineering, self refine",,,"ChatGPT (LLM), SysML, ferramentas MBSE (genéricas) e framework conceitual proposto pelo estudo.","IA generativa por meio de validação qualitativa baseada em especialistas e por estudo de caso no domínio IoBT, sem empregar métricas quantitativas ou benchmarking",,"O estudo demonstra que o uso de GenAI na Engenharia de Software melhora eficiência, precisão, consistência e escalabilidade da Engenharia de Requisitos, além de fortalecer a integração com MBSE e SysML, reduzindo erros humanos e apoiando a evolução contínua de sistemas complexos","""No entanto, em alinhamento com Blasek et al. (2023), este estudo conclui que os requisitos gerados por IA frequentemente carecem de rastreabilidade estruturada dentro de frameworks MBSE baseados em SysML, limitando sua utilidade operacional."" -> ""However, in alignment with Blasek et al. (2023), this study finds that AI-generated requirements often lack structured traceability within SysML-based MBSE frameworks, limiting their operational utility. ""

- Falta de padronização, rastreabilidade, validação formal, adaptação em tempo real e dependência de supervisão humana","""Uma das lacunas mais proeminentes é a falta de frameworks padronizados para integrar requisitos de segurança gerados por IA em ferramentas de MBSE, como o SysML. Embora pesquisas existentes tenham explorado o papel da IA na detecção de ameaças, análise de anomalias e automação de segurança, não é prontamente aparente na literatura o que foi feito para estabelecer mecanismos de rastreabilidade bidirecional que garantam que as políticas de segurança derivadas por IA permaneçam consistentes, adaptáveis e verificáveis dentro de modelos de sistema estruturados (Apvrille & Sultan, 2024; Rosenberg et al., 2024)."" -> ""One of the most prominent gaps is the lack of standardized frameworks for integrating AI-generated security requirements into MBSE tools, such as SysML. While existing research has explored AI's role in threat detection, anomaly analysis, and security automation, it is not readily apparent within the literature what has been done to establish bidirectional traceability mechanism","- Padronizar Frameworks de Integração IA-SysML: Desenvolver uma estrutura de modelagem universal IA-SysML para automação de segurança estruturada.
Adaptação de Segurança Impulsionada por IA em Tempo Real: Aperfeiçoar modelos de IA para ajustar dinamicamente as políticas de segurança com base em ameaças em evolução.
- Validação Empírica em Implantações Militares: Testar a automação de segurança orientada por IA em ambientes reais de IoBT para validar a eficácia.
- Mecanismos de Defesa de IA Adversária: Melhorar as defesas de IA contra ameaças cibernéticas adversárias, como envenenamento e manipulação de dados.
- Alinhamento com Padrões Internacionais de Cibersegurança: Garantir que a automação de segurança impulsionada por IA esteja alinhada com a OTAN, o DoD e outras políticas e acordos militares globais.","1 - Garantir a qualidade e correção dos requisitos gerados
2 - Dependência de especialistas humanos (human-in-the-loop)
3 - Tradução confiável de texto natural para modelos formais (SysML)
4 - Garantir requisitos de segurança corretos em um domínio crítico (IoBT)","Obs.: O estudo não apresentou nenhuma das ""Métricas utilizadas"" de forma explicíta, por isso foi escolhido deixar sem marcar

Obs.: O estudo trabalha com IA generativa em engenharia de requisitos, mas em cima de um escopo específico que é o da segurança de IoT na área militar","""This research addresses a critical gap in AI-driven security requirements engineering by exploring the
effective integration of SysML and advanced AI to formulate comprehensive security requirements for
IoBT devices.""

""By integrating AI-driven security requirement derivation with SysML automation, this research provides a unified, scalable framework for contemporary requirements engineering, promoting traceability, adaptability, and compliance in modern cyber-physical and military defense systems (Apvrille & Sultan, 2024; Rosenberg et al., 2024).""

""However, in alignment with Blasek et al. (2023), this study finds that AI-generated requirements often lack structured traceability within SysML-based MBSE frameworks, limiting their operational utility. A key finding is the need for real-time adaptability in AI security frameworks to counter evolving threats."""
A46,Machine Learning Techniques for Automatic Program Repair: A Systematic Literature Mapping,2025,0.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Brenno - EC1 - Full text not avaliable for free on the Web or on the CAPES Periódicos platform,,,,,,,,,,,,,,,,,,,,,,,,
A47,Machine learning approaches for automated software traceability: A systematic literature review,2025,0.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Líbna Raffaely - excluído pelo critério EC4( Does not address GenAI for SE activities),"Alturayeif, Nouf and Hassine, Jameleddine and Ahmad, Irfan",,,,,,,,,,,,,,,,,,,,,,,
A48,Machine learning for requirements engineering (ML4RE): A systematic literature review complemented by practitioners’ voices from Stack Overflow,2024,7.0,Scopus,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,"Leonardo Lima e Silva
Jeniffer","Tong Li, Xinran Zhang, Yunduo Wang, Qixiang Zhou, Yiting Wang, Fangqi Dong.",China.,"Faculty of Information Technology, Beijing University of Technology; School of Software, Beihang University.",Information and Software Technology.,journal,"O artigo apresenta um mapeamento sistemático de como o Aprendizado de Máquina (ML) apoia as atividades de Engenharia de Requisitos (ER). As principais contribuições identificadas nas publicações acadêmicas (""white part"") concentram-se na Análise de Requisitos (43,48%) e Elicitação de Requisitos (28,50%). As tarefas específicas mais exploradas incluem classificação de requisitos (a mais comum), modelagem de requisitos, extração e classificação de feedback de usuários, rastreabilidade e avaliação de qualidade. O estudo também destaca o uso de ferramentas industriais (como Jira e Microsoft TFS) na prática (""grey part"") focadas em Gerenciamento de Requisitos, contrastando com o foco acadêmico em algoritmos.",Requisitos,"Embora o estudo revise majoritariamente técnicas de ML tradicional e Deep Learning (SVM, CNN, Árvores de Decisão), ele identifica o uso de modelos pré-treinados e embeddings como BERT e Word2Vec nas publicações analisadas. Como sugestão para trabalhos futuros e tendência recente (2020-2022), o artigo aponta explicitamente a exploração de Large Language Models (LLMs) e modelos generativos (como GPT) para a construção de assistentes inteligentes de perguntas e respostas.","Os modelos e arquiteturas explorados na literatura revisada incluem SVM (o mais frequente), CNN (Convolutional Neural Networks), Decision Tree, BERT (Bidirectional Encoder Representations from Transformers), Random Forest, BiLSTM e LSTM. O roadmap apresentado indica uma evolução de algoritmos tradicionais para redes neurais básicas, deep learning e, mais recentemente (2020-2022), modelos pré-treinados e LLMs.","LLM, outro","GPT-x, outros",outros,0.0,outro,"No contexto acadêmico de ML4RE, as ferramentas mais utilizadas são Scikit-learn, Weka, TensorFlow, Keras e Pytorch. Na prática industrial (Stack Overflow), as ferramentas predominantes são de gestão, como Microsoft TFS, Jira, IBM Rational DOORS, Rally e Azure DevOps. O artigo sugere a integração de ML nessas ferramentas industriais no futuro.","INCONCLUSIVO. O artigo menciona ""avaliação de qualidade de requisitos"" como uma tarefa e cita que estudos anteriores identificaram métricas de avaliação, mas não detalha quais métricas específicas de avaliação de IA Generativa — como fidelidade ou alucinação — foram utilizadas nos artigos revisados","outros, qualidade","O uso de LLMs e assistentes inteligentes oferece: (1) um repositório abrangente de conhecimento de domínio devido ao pré-treinamento extensivo; (2) capacidades superiores de compreensão e raciocínio para resolver problemas complexos de ER; e (3) responsividade em tempo real para fornecer respostas eficientes e detalhadas. Além disso, oferece uma abordagem mais inteligente e eficiente para lidar com dados de requisitos e automatizar esforços manuais.","Técnicas avançadas de ML e Deep Learning (frequentemente usadas em pesquisa acadêmica) implicam alta complexidade e custo, exigindo conhecimento especializado e recursos computacionais substanciais, o que contrasta com a necessidade industrial de praticidade e custo-benefício.","O artigo identifica oportunidades no desenvolvimento de assistentes inteligentes de perguntas e respostas utilizando LLMs. Há também uma lacuna na integração de técnicas de ML em ferramentas industriais existentes. Além disso, nota-se uma falta de pesquisas acadêmicas focadas em ""User Stories"" e ""Casos de Uso"", que são altamente relevantes para a indústria.",Os autores sugerem: (1) Construir assistentes inteligentes baseados em LLMs com fine-tuning para o domínio de ER; (2) Desenvolver ferramentas adaptativas inteligentes que integrem métodos de ML às ferramentas industriais; (3) Fortalecer a colaboração academia-indústria para acesso a dados reais (como user stories); (4) Promover iniciativas open-source compartilhando modelos e dados em plataformas como Zenodo e GitHub.,"Os desafios incluem a desconexão entre a pesquisa acadêmica (focada em inovação/algoritmos complexos) e a prática industrial (focada em ferramentas de gestão e problemas práticos). Há também dificuldades relacionadas à privacidade e sensibilidade dos dados industriais, dificultando o acesso acadêmico , e a complexidade para praticantes industriais reproduzirem códigos de artigos acadêmicos.","O estudo faz uma distinção clara entre a ""parte branca"" (literatura acadêmica) e a ""parte cinza"" (Stack Overflow). A academia foca em Elicitação e Validação usando SVM, CNN e BERT, enquanto a prática (Stack Overflow) foca em Gerenciamento e Especificação usando ferramentas como Jira e TFS.","""The white part underscores the use of ML technologies such as SVM, CNN, and BERT. In contrast, the grey part relies more on tools such as Microsoft TFS, Jira, and IBM Rational DOORS..."". ""It is anticipated that future research in ML4RE will continue to explore large language models extensively."". ""Our suggestions include the development of intelligent question-answering assistants employing large language models...""."
A49,Prompt Engineering Guidelines for Using Large Language Models in Requirements Engineering,2026,6.0,Scopus,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Partially attended to,Partially attended to,Fully attended to,Líbna Raffaely,"Krishna Ronanki, Simon Arvidsson,  Johan Axell,",Suécia,Chalmers University of Technology,Lecture Notes in Computer Science,conference,"O artigo contribui para a Engenharia de Software ao identificar e sistematizar guidelines de engenharia de prompt relevantes para apoiar o uso LLMs em atividades de Engenharia de Requisitos, mostrando como a qualidade e precisão das saídas geradas por LLMs dependem diretamente da forma como os prompts são formulados e adaptados ao contexto de requisitos de software, e, ao mesmo tempo.",Requisitos,"O artigo explora técnicas de IA relacionadas ao uso de LLM  para apoiar atividades de engenharia de requisitos, com foco em Prompt Engineering para controlar a natureza das respostas produzidas pelos modelos, ele contextualiza o uso de prompts como ferramenta importante para obter resultados de qualidade em tarefas de requisitos com IA generativa.",LLM,LLM,,prompt engineering,,outro,"Não descreve ferramentas específicas, apenas avalia o uso de prompt  engineering",artigo está centrada em entrevistas com especialistas da área de Engenharia de Requisitos sobre as vantagens e limitações da aplicação das diretrizes de  engenharia de prompting,"outros, qualidade","há o destaque da utilização de IA generativa para melhorar a qualidade e eficiência de atividades de engenharia de requisitos, como a geração, interpretação e validação de requisitos, desde que a engenharia de prompts seja aplicada de forma cuidadosa para garantir que as respostas dos modelos sejam contextualmente relevantes, corretas e alinhadas aos objetivos da tarefa de requisito e sem alucinações",Há uma escassez de diretrizes específicas de engenharia de prompt para atividades de requisito,Há a oportunidade de desenvolver  diretrizes mais robustas e contextualizadas na engenharia de prompt para atividades de engenharia de requisitos,,,,
A50,Prompt Engineering for Requirements Engineering: A Literature Review and Roadmap,2025,6.5,Scopus,Fully attended to,Fully attended to,Partially attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Ana Karolina,"Kaicheng Huang, Fanyu Wang, Yutan Huang, Chetan Arora",Australia,"Faculty of Information Technology, Monash University, Melbourne, Australia","Proceedings - 2025 IEEE 33rd International Requirements Engineering Conference Workshops, REW 2025",conference,A revisão sistemática faz um mapeamento dos estudos que tratem sobre a aplicação da técnica de prompot dentro da área de Engenharia de Requisitos em busca de mapear as técnicas mais eficazes e direções futuras para a área.,Requisitos,"CoT, ReAct, K-shot, RAG","1) GPTs: GPT4, GPT4o, GPT3.5-Turbo, GPT3.5-Turbo-instruction, GPT3.5;
2) Llama: Llama-13B, Llama2-70B, CodeLlama-34B)
3) Outros: Nous-Hermes-2, CodeGeeX, ERNIE-Bot, Whisper, Bard, T5-Large, text-davinci-003
4) PLM: BERT, ALBERT, RoBERTa, XLNet, NoRBERT
5) Gemini: Gemini-Pro
6) Mistral: Mistral-7B, Mixtral-8×7B
7) Phi: Phi-3-Medium
8) Deepseek: DeepSeek-Coder-V2
9) Claude: Claude 3",LLM,,"RAG, chain of thought, prompt engineering, reAct",,,Não são apresentadas.,"Ablação, BLEU/ROUGE, SUS",cobertura,"O uso de LLMs na Engenharia de Requisitos permite automatizar e acelerar tarefas como elicitação, classificação, detecção de conflitos, recuperação de links de rastreabilidade e geração automatizada de testes. Com os resultados gerados é possível reduzir o retrabalho custoso e o desvio de escopo, como por exemplo com o uso de prompts self-reflection que força os modelos a criticar e revisar seus rascunhos, assegurando isso. Além disso, os autores citam por exemplo a rápida prototipagem com a geração de código, permitindo apresentar os cliente uma visão do que será produzido.","Falta de avaliação: Os autores apontam que existe uma escassez de avaliações o que traz incertezas sobre a eficácia da abordagem.
Desafio multimodal: existe uma lacuna no processamento de entradas não textuais","O artigo apresenta que os estudos achados não são orientados para a área de elicitação de requisitos, a sua grande maioria lida com requisitos já prontos realizando outras tarefas, outro ponto importante é a escassez de estudos que tratem outras entradas além da textual, poucos estudos orientados a UML trataram entradas que fossem imagem mas em sua grande maioria são entradas textuais, direcionando os resultados para um único caminho.","Os autores sugerem a produção de estudos que foquem em uma elicitação multimodal com o objetivo de suprimir o foco exclusivo em texto, com isso eles sugerem combinar diagramas e requisitos em linguagem natural para que o modelo identifique inconsistências ou gere links de rastreabilidade sem perder informações visuais;
Como a fase de elicitação é pouco explorada, o artigo propõe o desenvolvimento de agentes conversacionais que entrevistem os stakeholders;
Para resolver a falta de avaliação sistemática, os autores sugerem o desenvolvimento de sistemas que consigam medir o impacto de mudanças de forma precisa, para isso é sugerido adaptar pipelines de recuperação (RAG) para que cada prompt inclua IDs únicos de requisitos. Assim, qualquer mudança gerada pelo modelo dispara um relatório automático;
Por fim, os autores sugerem agregar conjuntos de dados em um benchmark único para resolver a dificuldade de replicação e comparação entre estudos.","Incerteza e falta de controle: Usuários frequentemente encontram inconsistências ao realizar tarefas de inferência via API, o que desafia a confiabilidade;
Alucinações",,"""As an important part of RE, model-based representation is not frequently explored in PE4RE research, which should be investigated in the future.""
""We found that in the selected studies, none of the papers formally report requirements generation or elicitation. """
A51,Prompting Techniques for Secure Code Generation: A Systematic Investigation,2025,6.0,Scopus,Fully attended to,Fully attended to,Partially attended to,Fully attended to,Partially attended to,Fully attended to,Fully attended to,Brenno,"Tony, Catherine and Díaz Ferreyra, Nicolás E. and Mutas, Markus and Dhif, Salem and Scandariato, Riccardo",Alemanha,Hamburgo University of Technology,ACM - Digital Library,journal,"A ES contribui através de um processo de Revisão Sistemática (SLR), ferramentas de análise estática, métricas de qualidade de código e engenharia de requisitos em prompts",Construção/Codificação,"Ao todo pode ser indentificado mais de uma dezena de técnicas exploradas no artigo, dentre as quais se destacam: Zero-shot, One-shot, Few-shot, Self-refine, Progressive Hint, Chain-of-Thought (CoT) e Zero-shot CoT","GPT - 3, GPT - 3.5 e GPT - 4",LLM,GPT-x,"chain of thought, prompt engineering",,comercial,"As ferramentas identificadas que auxiliaram o estudo foram Bandit, CodeQL e Dolos","Análise estática de segurança (pelo Bandit), análise manual de validade e teste de vazamento de dados","correção funcional, precisão, segurança","Alguns beneficios são atuar como ponto de partida, reduzindo a necessidade de pesquisa online, a capacidade de gerar implementações funcionais a partir de linguagem natural, técnicas de prompting e uso de padrões de codificação segura","O código gerado frequentemente contém vulnerabilidades de segurança, desenvolvedores tendem a confiar excessivamente (over-reliance) na IA, aceitando código inseguro sem questionar, técnicas de prompting como ""Persona"" (agir como especialista) apresentaram o pior desempenho na geração de código seguro e Alucinação de métodos",A correlação entre estratégias de prompting e a geração de código seguro ainda é pouco explorada na literatura e falta de exploração de técnicas baseadas em refinamento,Explorar abordagens de otimização de prompts e Expandir a investigação de métodos baseados em refinamento que alavanquem as capacidades de autocrítica dos LLMs,"arefas que envolvem múltiplas funcionalidades (ex: aplicações web com banco de dados) desviam o foco do modelo da segurança, resultando em vulnerabilidades frequentes como senhas hard-coded, vazamento de dados, que segue com a vulnerabilidade persistente","O estudo aborda principalmente a codificação, mostrando em primeira mão suas funcionalidades e suas limitações, acredito que, como destacado em outros estudos, o vício em erros é a principal deficiência na atualidade e que, apesar de muito citada na literatura, não foi devidamente abordada",
A52,Prompts Engineering Challenges in Software Code Generation,2025,4.5,Scopus,Fully attended to,Fully attended to,Not attended to,Partially attended to,Fully attended to,Partially attended to,Partially attended to,Henrique da Rocha Lima E Heitor Dias,"Gutierrez, Yazmin
Camacho, Erika
Pardo, Cesar
Villarreal, Vladimir",Colombia,"University of Cauca, GTI Research Group, Cauca, Popayán, Colombia","8th International Congress on Environmental Intelligence, Software Engineering, and Electronic and Mobile Health, AmITIC 2025",conference,"Processos e Metodologias
Revisões Sistemáticas da Literatura (SLR): Uso do protocolo de Kitchenham para sintetizar evidências e identificar tendências.
Goal-Question-Metric (GQM): Definição de objetivos e orientação da coleta de dados.
Estratégias Iterativas: Uso de sequenciamento de questões e feedback para interação com modelos.
Novo Paradigma de QA: Engenharia de prompts como controle do não-determinismo e garantia de confiabilidade.

Técnicas
Engenharia de Prompts Estruturada: Design sistemático de instruções.
Encadeamento de IA (AI Chaining): Ligação de múltiplos prompts para tarefas complexas.
Estratégias de Ajuste: Few-shot, Chain-of-Thought e PEFT para otimização.
Refinamento e Reparo de Código: Revisão, correção e otimização de código gerado.
Detecção de Vulnerabilidades: Uso de prompts para identificar falhas de segurança.

Ferramentas e Frameworks
Sistemas Multiagente: Uso de frameworks como ChatDev.
Análise de Ferramentas: Estudos sobre GitHub Copilot.
Integração em IDEs: D",Construção/Codificação,"Paradigmas de Prompting (Engenharia de Prompts)
Técnica central de interação com modelos, incluindo:
Few-shot: Aprendizado em contexto (88 estudos).
Chain-of-Thought: Melhoria de raciocínio (18 estudos).
Metaprompts: Instruções de alto nível.
Prompting Estruturado: Design sistemático de prompts.

Estratégias de Encadeamento e Decomposição
AI Chaining: Cadeias de prompts para tarefas complexas.
Interactive Decomposition: Quebra interativa de tarefas (ex.: ANPL).
Self-Planning: Planejamento automático das etapas pelo modelo.

Arquiteturas de Sistemas e Agentes
Sistemas Multiagente: Frameworks como ChatDev.
Self-collaboration: Colaboração entre instâncias do modelo.
Multi-LLM Debugging: Uso de múltiplos modelos para depuração.

Técnicas de Otimização e Ajuste Fino
PEFT: Ajuste eficiente com poucos parâmetros.
Instruction Tuning com Feedback Humano: Treinamento baseado em instruções.

Técnicas de Refinamento e Segurança
Program Repair: Correção automática de bugs e vulnerabilidades.
Data A","Modelos Explorados (LLMs)
ChatGPT (ex.: GPT-3.5-turbo), OpenAI Codex e GitHub Copilot são os mais citados em geração de código, depuração e colaboração. Uma revisão identificou mais de 70 modelos diferentes aplicados em ES.

Técnicas de Prompts
Few-shot e Chain-of-Thought, metaprompts, prompt patterns, prompting estruturado/pedagógico e knowledge-aware prompting para melhorar raciocínio, qualidade de código, refatoração, requisitos e design.

Arquiteturas e Frameworks
Sistemas multiagente (ChatDev), AI Chaining, auto-colaboração e self-planning, ANPL (decomposição interativa) e multi-LLM debugging (RGD).",LLM,GPT-x,prompt engineering,,comercial,"Modelos de Linguagem (LLMs): ChatGPT (especialmente GPT-3.5-turbo) e OpenAI Codex são os mais usados para geração, depuração e explicação de código.
Assistentes de Programação: GitHub Copilot é amplamente estudado quanto à usabilidade e robustez do código gerado.
Frameworks e Sistemas Especializados:
ChatDev (sistema multiagente), ANPL (programação natural por decomposição), CodeDoctor (comentários automatizados em revisão de código) e RGD (depuração multi-LLM).
Ambientes de Desenvolvimento: Tendência de integrar design e automação de prompts diretamente em IDEs.
Ferramentas de Pesquisa: Google Scholar, IEEE, Web of Science, ScienceDirect, ACM DL, Scopus e Springer para revisões e síntese de evidências.","Classificação e Metodologias de Pesquisa
Evaluation Research (mais comum), Validation Research, Revisões Sistemáticas (SLR) com protocolo de Kitchenham e abordagem GQM.","precisão, recall","Otimização da Interação: Engenharia de prompts transforma linguagem natural em código eficaz.
Capacidades Cognitivas: IA permite planejamento, raciocínio e geração de múltiplos artefatos.
Melhoria na Qualidade: Prompts estruturados aumentam precisão e robustez do código.
Aumento de Autonomia: Sistemas multiagente (ex.: ChatDev) ampliam autonomia e escalabilidade.
Produtividade: Impacto positivo na produtividade e no desenvolvimento de software.","Dependência de Dados: Forte dependência dos dados de treinamento e limitações de escala.
Erros Semânticos: Código sintaticamente correto, mas com erros lógicos e más práticas.
Contextualização Limitada: Dificuldade em aplicar algoritmos e estruturas em novos contextos.
Ambiguidade: Problemas na interpretação e avaliação das respostas geradas.","Segurança e Vulnerabilidades: Área pouco explorada.
Validação Industrial: Necessidade de mais estudos em ambientes reais.
Padrões de Prompts: Oportunidade de definir padrões específicos para Engenharia de Software.
Análise Ética: Necessidade de fortalecer ética e transparência na interação humano-IA.","Métricas de Eficácia: Criar métricas formais para avaliar prompts.
Integração em IDEs: Desenvolver ferramentas de design de prompts dentro de IDEs.
Automação de Prompts: Automatizar o próprio processo de criação de prompts.
Impacto de Longo Prazo: Avaliar efeitos da IA na qualidade do código e produtividade ao longo do tempo.","Não-determinismo: Pequenas variações no prompt geram saídas imprevisíveis.
Complexidade do Design: Dificuldade em manter prompts concisos e eficazes.
Plágio Algorítmico: Risco de uso de código gerado como próprio.
Dependência Excessiva: Perda de habilidades e compreensão por iniciantes.
Risco de Mau Uso: Possibilidade de gerar código malicioso ou ferramentas de ataque.","Tendência de Crescimento: Aumento significativo de publicações entre 2023 e 2024.
Natureza da Engenharia de Prompts: Componente central, não apenas complementar, na geração automática de código.","PE como Defesa: Engenharia de prompts como primeira linha de defesa em QA.
Analogia com Programação: Estruturar prompts é equivalente a aprender a gramática de uma linguagem.
Sobre Plágio: O problema é a terceirização do processo cognitivo e a falsa competência.
Sobre Usabilidade: Programadores novatos relatam surpresa com a precisão do Copilot (“é estranho que ele saiba o que eu quero”)."
A53,Psycholinguistic analyses in software engineering text: A systematic mapping study,2026,0.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,"Líbna Raffaely - Excluído: De acordo com o critério  EC4(Não aborda a IA GenAI para atividades de SE),","Amirali Sajadi, Kostadin Damevski, Preetha Chatterjee",Estados Unidos,"Drexel University,Virginia Commonwealth University",Information and Software Technology,journal,,,,,,,,,,,,,,,,,,,
A54,Quality Assurance for LLM-Generated Test Cases: A Systematic Literature Review,2024,5.5,Scopus,Fully attended to,Fully attended to,Not attended to,Partially attended to,Fully attended to,Fully attended to,Fully attended to,Henrique da Rocha Lima E Heitor Dias,"Edirisinghe, Hasali
Wickramaarachchi, Dilani",Sri Lanka,"University of Kelaniya, Department of Industrial Management Faculty of Science","2024 8th SLAAI - International Conference on Artificial Intelligence, SLAAI-ICAI 2024",conference,"Processos e Metodologias Sistemáticas:
A Engenharia de Software (ES) contribui com metodologias disciplinadas para pesquisa e desenvolvimento em IA, como o uso das diretrizes PRISMA para garantir seleção e análise rigorosas e reprodutíveis da literatura, além de Revisões Sistemáticas (SLR) para sintetizar evidências sobre o impacto de ferramentas de IA, como LLMs, em domínios específicos como testes de caixa-preta.

Frameworks de Garantia de Qualidade (QA):
As fontes identificam três tipos principais de frameworks: os tradicionais (como análise de valor limite, tabelas de decisão e diagramas de transição de estados), os aprimorados por IA (como TESTPILOT e XUAT-Copilot, que usam LLMs para gerar testes automaticamente) e as abordagens híbridas, que combinam métodos clássicos com automação por IA para equilibrar eficiência e supervisão humana.

Atributos-Chave de Qualidade:
A ES define atributos essenciais para avaliar saídas de modelos de IA, incluindo acurácia (detecção correta de defe",Testes,"Modelos de Linguagem:
GPT-4 e Codex são os principais, usados para gerar testes com mais precisão e menor tempo.

Prompting e Raciocínio:
Incluem engenharia de prompt, Chain-of-Thought e clarificação de requisitos para melhorar a qualidade das saídas.

Frameworks e Arquiteturas:
Sistemas multiagente e frameworks como TESTPILOT automatizam e estruturam a geração de testes.

Otimização de Processos:
A IA também reduz suítes de teste, prevê testes instáveis e migra scripts automaticamente.","Modelos de ML (LLMs/MLMs):
GPT-4, Codex e modelos da família GPT são os principais, usados para automatizar testes com alta precisão e grande redução de tempo.

Técnicas de Prompts:
Incluem engenharia de prompt, R3 Prompting, comparação entre fine-tuning e prompting, e prompt tuning em caixa preta.

Arquiteturas e Frameworks:
Sistemas multiagente (XUAT-Copilot), frameworks adaptativos (TESTPILOT), metamórficos (METAL), análise universal (LUNA), clarificação de requisitos (ClarifyGPT), minimização de testes (LTM), predição de flaky tests (Flakify) e arquiteturas híbridas com métodos tradicionais.",LLM,"GPT-x, outros",prompt engineering,,comercial,"Frameworks de Automação de Testes:
TESTPILOT, XUAT-Copilot e ClarifyGPT são os principais, integrando LLMs ao ciclo de desenvolvimento para geração adaptativa de testes, automação de UAT e clarificação de requisitos.

Ferramentas de Análise e Garantia de Qualidade:
Incluem METAL, LUNA, Flakify, LTM e RITFIS, usadas para validar consultas a LLMs, prever testes flaky, minimizar suítes de teste e garantir robustez.

Ferramentas de Apoio à Pesquisa em ES:
Bases como IEEE Xplore, ACM DL, Google Scholar e SpringerLink são usadas para coleta de estudos, enquanto o Mendeley auxilia na gestão de referências.","Metodologias de Revisão e Síntese:
Pesquisadores usam Revisões Sistemáticas da Literatura (SLR), geralmente seguindo PRISMA, e abordagens temáticas para sintetizar resultados e classificar frameworks, atributos de qualidade e desafios.

Atributos de Qualidade Críticos:
A avaliação foca em acurácia, cobertura, completude, eficácia, eficiência e rastreabilidade dos casos de teste gerados por IA.

Métricas Quantitativas de Desempenho:
Incluem cobertura de comandos, taxa de detecção de falhas, tempo de execução e noise ratio para medir qualidade e eficiência.

Frameworks de Avaliação e Teste:
Dividem-se em tradicionais, aprimorados por IA (como METAL e LUNA) e híbridos, combinando automação com supervisão humana.

Técnicas de Validação e Robustez:
Envolvem teste metamórfico, testes de robustez de entrada (RITFIS) e comparação entre prompting e fine-tuning.","cobertura, precisão, qualidade, recall, segurança","LLMs aumentam a produtividade ao automatizar a geração de testes, reduzem significativamente o tempo de desenvolvimento, alcançam alta cobertura de código e melhoram a detecção de falhas quando combinados com supervisão humana.","Os modelos apresentam imprevisibilidade, alto custo computacional, baixa interpretabilidade, dificuldade de rastreabilidade até requisitos e ausência de métricas padronizadas para avaliação consistente.","Faltam benchmarks realistas em nível de sistema, métricas alinhadas a padrões de qualidade, abordagens multilíngues consistentes e estudos em domínios especializados como saúde, finanças e robótica.","Desenvolver técnicas de mitigação de alucinações, integrar segurança em todo o pipeline, criar métricas multidimensionais e construir arquiteturas mais transparentes e interpretáveis.
;
- ""O desenvolvimento de algoritmos mais eficientes ou sistemas híbridos que possam escalar sem exigir recursos computacionais excessivos é uma necessidade.""
- Padronizar métricas de avaliação","Incluem alucinações, vulnerabilidades de segurança, generalização limitada para projetos reais, riscos adversariais e dependência excessiva por parte de desenvolvedores.","A pesquisa cresceu fortemente em 2024, é dominada por China e EUA, e colaborações entre academia e indústria são vistas como essenciais para aplicação prática.
;
O estudo desenvolve a ideia de que a utilização de framework QA que incorporam IA, como TESTPILOT e XUAT-Copilot, são muito úteis devido a adaptação, mas em decorrência dos altos recursos computacionais necessários para treinar e executar LLMs o estudo fornece uma alternativa ao utilizar um método híbrido, juntando as abordagens QA tradicionais com as aprimoradas por IA.","As fontes destacam que alucinações minam a confiança, que benchmarks atuais superestimam capacidades reais, e que a maioria dos modelos opera como sistemas de caixa-preta sem explicação de raciocínio.
;
""Embora os LLMs pudessem gerar casos de teste relevantes, permaneceram desafios em vincular esses casos de teste aos requisitos originais do software, particularmente em estruturas mais automatizadas [35], [36].""
""A revisão constatou que casos de teste gerados por LLMs podem alcançar alta eficácia na detecção de falhas de software quando combinados com supervisão humana. Vários estudos demonstraram que casos de teste gerados por LLMs alcançaram cobertura de sentença e taxas de detecção de falhas significativas [23],[29]. Embora os LLMs ofereçam capacidades de automação e maior cobertura de testes, a imprevisibilidade das saídas dos LLMs ao lidar com condições de contorno ou cenários de teste complexos foi notada como um desafio [50],[53],[59]. Essa imprevisibilidade necessita de interve"
A55,Research directions for using LLM in software requirement engineering: a systematic review,2025,5.0,Scopus,Fully attended to,Fully attended to,Not attended to,Partially attended to,Fully attended to,Fully attended to,Partially attended to,"Filipe Campos Matunaga Batista
Ana Karolina",Arshia Hemmat; Mohammadreza Sharbaf; Shekoufeh Kolahdouz-Rahimi; Kevin Lano; Sobhan Y. Tehrani,Irã; Irã; Reino Unido; Reino Unido; Reino Unido;,"Department of Software Engineering, University of Isfahan, Isfahan, Iran; School of Arts, University of Roehampton, London, United Kingdom; Department of Informatics, King’s College London, London, United Kingdom; Department of Computer Science, University College London, London, United Kingdom;",Frontiers in Computer Science,journal,"Categorias de entrada no campo de Engenharia de Requisitos: Requisitos em linguagem natural, Documentação técnica, Códigos de programação, Exemplos e esboços, Modelo e especificações formais.
Categorias de saída no campo de engenharia de software: Modelagem e diagramas, Requisitos e especificações de software, Especificações formais e DSL, Simulação e previsões, Código e pseudocódigo.
(consultar o detalhamento no artigo caso necessário)",Requisitos,"fine tuning (Full fine-tuning, Prompt tuning, Context tuning, Low-rank adaptation (LoRA), Custom decoder fine-tuning, Instruction fine-tuning, Fine-tuning with domain-specific knowledge) - Detalhes sobre cada uma das técnicas no artigo;
prompt engineering (Zeroshot prompting, Fewshot prompting, Iterative prompts, Contextual prompts) - Detalhes sobre cada uma delas no artigo.","Tipos de modelos usados em engenharia de requisitos: GGPT, Codex,",LLM,"GPT-x, Llama, outros","outros, prompt engineering",,,Não se aplica.,"As métricas usadas foram correção e completude, desempenho, concordância e consistência, precisão e recall, Avaliação qualitativa e baseada em especialistas, qualidade e manutenibilidade de código. - Detalhes sobre cada uma das métricas no artigo.",,"1. Ajuda na geração de documentos de requisitos, código do sistema e casos de teste (GPT)
2. Traduzir requisitos de linguagem natural em código executável, transformando requisitos de alto nível e implementações técnicas específicas. (Codex)
3. Realiza tarefas como classificação de requisitos, detecção de contradições e extração de palavras-chave (BERT)
4. Parafrasear e resumir requisitos. (T5 e Llama)
LLMs podem:
ajudar a identificar terminologia ausente ou informações críticas nos requisitos iniciais, fornecer feedback sobre a viabilidade e clareza dos requisitos, converter histórias de usuário em requisitos estruturados, facilitar a elicitação interativa de requisitos interpretando e analisando as contribuições das partes interessadas. (elicitação e análise de requisitos);
Gerar diagramas UML como diagramas de casos de uso, classes e sequência com base em requisitos em linguagem natural, traduzir requisitos de alto nível em especificações mais formais ou estruturadas, criar especifi",,Ainda existem lacunas na pesquisa focada em LLMs desenvolvidos especificamente para tarefas de RE.,"1. A integração prática de LLMs na Engenharia de Requisitos ainda é pouco explorada, com estudos empíricos abordando aplicações no mundo real sendo limitados. 
2. Pesquisas futuras devem se concentrar no desenvolvimento de estruturas robustas para validar e otimizar os resultados de LLMs, adaptados às demandas detalhadas da Engenharia de Requisitos.

A seguir tópicos indicados no artigo, sem o detalhamento de cada um deles: Avaliação e métricas, Melhoria de modelo e fine-tuning, Engenharia de prompts e técnicas, integração e adaptação, Desempenho e confiabilidade, Abordagens híbridas.","Os principais desafios incluem a validação dos requisitos gerados por LLMs, a abordagem de questões como alucinação e consistência, e o aprimoramento das técnicas de ajuste fino para tarefas de ER específicas do domínio.

Desafios de compreensão e conhecimento, Problemas de qualidade e completude de output, Limitações técnicas e procedimentais, Desafios em código e testes, Desafios de prompts e entrada, Limitações empíricas e experimentais, Problemas de formatação e estrutura.. (tópicos retirados do próprio artigo)","Principais conclusões:
1. A combinação do GGPT e Codex reflete uma estratégia de usar LLMs para balancear as tarefas realizadas.
2. Os estudos revelam uma dependência de requisitos em linguagem natural, documentos técnicos e trechos de código como entradas principais, com saídas que variam de diagramas UML e casos de teste a especificações de requisitos estruturadas. LLMs servem como ferramentas adaptáveis capazes de apoiar múltiplos aspectos dos fluxos de trabalho de RE.
3. LLMs são efetivamente integrados em diferentes etapas do processo de RE, particularmente na elicitação, modelagem e validação de requisitos.
4. As descobertas indicam uma preferência por técnicas de ajuste eficientes em parâmetros. A análise revelou que uma parte substancial dos modelos pesquisados não utiliza técnicas de fine-tuning no contexto de SRE.
5. Few-shot prompting, é particularmente benéfico na geração de resultados específicos de SE. Contextual prompts melhora ainda mais a precisão da saída incorporando","""A major pattern identified is the difficulty LLMs face in handling domain-specific knowledge and context, as seen in issues like hallucination, incomplete outputs, and limitations in addressing complex syntaxes or structured requirements."""
A56,Reusable and generic design decisions for developing UML-based domain-specific languages,2017,0.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,"Filipe Campos Matunaga Batista - Excluído (EC4: Does not address genAI for SE activities).
Ana Karolina- Excluído (EC4: Does not address genAI for SE activities).",,,,,,,,,,,,,,,,,,,,,,,,
A57,Software Engineering and Foundation Models: Insights from Industry Blogs Using a Jury of Foundation Models,2025,3.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Fully attended to,Fully attended to,Fully attended to,Ana Karolina e Filipe Campos,"Hao Li, Cor-Paul Bezemer, Ahmed E. Hassan",Canada,"Queen’s University Kingston, Canada, University of Alberta Edmonton, Canada",IEEE/ACM International Conference on Software Engineering - Software Engineering in Practice,conference,"O artigo se trata da análise do que poderia se enquadrar em literatura cinzenta (os autores analisaram blogs e foruns) em busca dos principais temas abordados pelos profissionais, dentre eles temos: desenvolvimento de software (geração de código), garantia de qualidade (detecção de vulnerabilidade), manutenção (refatoração de código), implantação e operação de modelos, encadeamento de prompot e fluxo de trabalho.
;
O desenvolvimento e operação de modelos é a atividade mais frequentemente discutida em posts de blog da indústria SE4FM, além disso,, o uso na nuvem facilita o uso de modelos tão grandes sob demanda sem a necessidade de comprar hardware muito caro. Entretanto, há um interesse crescente na implantação de modelos em dispositivos locais, como dispositivos de borda ou móveis, e computadores pessoais, para evitar o gasto com hardware como servidores por exemplo.
Atividades de arquitetura de sistemas e orquestração, incluindo a construção de agentes de IA e encadeamento de modelos","Construção/Codificação, Manutenção, Testes",";
fill-in-the-middle, só foi citado apenas uma vez como um exemplo de uso de FMs em ES.
RAG, também só foi citada uma vez na aplicação de gerenciamento de dados. Dando um destaque para bancos de dados especializados, especialmente bancos de dados vetoriais.
LoRA, citada na área de customização de modelo, reduz o número de parâmetros treináveis e diminui os requisitos de GPU, tornando-o econômico. Com diferentes adaptadores LoRA, um único FM pode se adaptar para lidar com diferentes tarefas. Também nessa área, a personalização de modelos pode alcançada por meio de técnicas de fine-tuning para adaptar FMs a necessidades específicas de aplicação.","o artigo utilizou o que é chamado de FM/LLM jury que de acordo com a descrição do artigo é uma combinação de diferentes FMs para rotular as postagens dos blogs que foram analisados, ou seja, para aplicar a metodologia os autores também utilizaram LLM para não terem que ler uma por uma postagem.
;
Foundation models.","LLM, outro",outros,"RAG, multiagent",,,";
Não é abordado",";
Blogs das empresas destacam o uso de adversarial testing para identificar vulnerabilidades do modelo, enquanto avaliadores automatizados são frequentemente utilizados para realizar avaliações de segurança consistentes. Além disso, os profissionais estão adotando cada vez mais estratégias de teste automatizado para FMs, usando freuentemente benchmarks acadêmicos como o BIG-bench, porém ainda é necessário conjuntos de dados customizados para domínios específicos.",,";
A geração de código surge como a tarefa mais proeminente dos posts, de forma que os Foundation Models podem ajudar a gerar códigos tanto em linguagens modernas quanto em sistemas legado. além de aplicados à domínios específicos como SQL, destacando a versatilidade dos FMs. Além disso podem ajudar com compreensão de código, resumo de código, otimização de código e recomendações de API.
Para a garantia de qualidade as FMs são usadas para automatizar a detecção e análise de vulnerabilidades e exposições comuns principalmente, além de geração de testes e automação,
O uso de FMs na manutenção de software foca na refatoração, tradução e transformação de bases de código existentes, auxiliando as empresas a atualizar seus sistemas.",";
Não é abordado.",";
O gerenciamento de software recebe menos atenção nos blogs de FM4SE, e não foram encontradas discussões sobre engenharia de requisitos ou design de software.
A construção de prompts recebe menos atenção, e não foram encontradas discussões sobre engenharia de requisitos.",";
FM4SE:
1. Usar FMs para modernização e transformação de código legado.
2. Avaliar assistentes de código em fluxos de trabalho de desenvolvimento de software para tarefas além da geração de código.
3. Validação no mundo real de pesquisas sobre a aplicação de FMs na gestão de software, engenharia de requisitos e design de software.
SE4FM: 
1. Pesquisadores devem expandir a pesquisa sobre SE4FM.
2. Engenharia de desempenho para sistemas baseados em FM.
3. O impacto da mudança do treinamento completo do modelo para o ajuste fino em atividades de engenharia de software, como gerenciamento de dependências e ativos.
4.O fluxo de trabalho de FM ou orquestração e agentes de IA por meio de atividades de engenharia de software.
5. Apoiar os pipelines de dados em evolução nos sistemas baseados em FM.",";
Alucinações produzidas.",";
Modelos foram usados para coletar os posts em blogs de tecnologias de empresas, tendo uma parte do artigo mostrando como foi feita essa coleta.
Esse artigo aborda um pouco mais sobre Engenharia de Software para Fundation Models do que Fundation Models para Engenharia de Software.",";
""The interaction between SE and FMs has led to the emergence of two key trends: (1) FMs for SE (FM4SE), where FMs are leveraged to automate or enhance various SE tasks, such as code generation and testing, and (2) SE for FMs (SE4FM), where SE practices are adapted to the development and deployment of FMs.""
""we analyze blog posts from leading technology companies, focusing on how practitioners discuss the challenges and approaches related to FM4SE and SE4FM""
""industry blogs focus more on code refactoring and revision, while academic research papers focus more on program repair.""
""A closely related discussion topic is building AI agents, which extend the functionality of FMs by integrating external tools and orchestrating workflows. Inmulti-agent systems, multiple AI agents collaborate using a complex workflow to handle different parts of a task [B1166]. These AI agents can autonomously decide which tools to use, retrieve necessary data, and execute predefined plans based on user input"
A58,State of the Art of the Security of Code Generated by LLMs: A Systematic Literature Review,2024,6.0,Scopus,Partially attended to,Fully attended to,Partially attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Heitor e Henrique da Rocha Lima,"Leonardo Criollo Ramírez¹, Xavier Limón², Ángel J. Sánchez-García e Juan Carlos Pérez-Arriaga³",Mexico,"Universidad Veracruzana, Facultad de Estadística e Informática",2024 12th International Conference in Software Engineering Research and Innovation (CONISOFT),conference,Não se aplica,Construção/Codificação,"- Geração automática de código com LLMs
- Prompt engineering para influenciar e melhorar a qualidade/segurança do código gerado.
- Iterative repair / geração iterativa, em que o código gerado é reavaliado e refinado em ciclos sucessivos.
- Pós-processamento do código gerado, incluindo análise estática e linting.
- Uso de múltiplos modelos de IA, onde um modelo gera código e outro analisa vulnerabilidades.","O documento explora Large Language Models (LLMs), não mencionando nenhum em específico ao longo do texto, exceto na ""TABLE II: Search terms used to build the search string."" na qual são mencionados os termos de busca. Lá é mencionado os termos ""GPT-3, GPT-4, ChatGPT, GPT-Neo, GitHub Copilot, Codex e LLaMA"". SLMs não são abordados, portanto não se aplica. Quanto a prompts, o estudo discute prompt engineering, uso de comentários em linguagem natural, assinaturas de funções e prompting iterativo para mitigar vulnerabilidades. Porém não traz um template para ser usado. O estudo discute arquiteturas de uso em Engenharia de Software sendo elas: integração de pipelines DevSecOps, arquiteturas com múltiplos modelos (um para gerar código e outro para analisar vulnerabilidades) e ferramentas de análise estática, mencionando que tais metodos são uteis para melhorar a qualidade do código

OBS.: O estudo não discorre especificamente sobre modelos específicos, nem mencionando o tamanho do modelo, o",LLM,"GPT-x, outros",prompt engineering,,,"- Pipelines de DevSecOps
- Análise por outros modelos de IA
- Analisadores Estáticos de Código
- Ferramentas de Linting","1 - Análise estática e linting de código
2 - Avaliação cruzada por modelos de IA (LLMs como avaliadores)
3 - Reparo iterativo e pós-processamento
4 - Benchmarks e datasets de segurança (Avaliação empírica)
5 - Comparação humano vs IA
6 - Integração em pipelines DevSecOps","precisão, recall","Aumento da produtividade, melhoria da qualidade do software, agilização da escrita de código, automação de tarefas repetitivas e geração dinâmica de código compilável","As limitações apresentadas pelo estudo de usar genAI para ES, no que se refere a codificação, está na segurança daquilo que é gerado pelos Grandes Modelos de Linguagem (LLMs), uma vez que foi constatado que as saídas dos modelos de IA geram, de forma recorrente, erros que comprometem a segurança do sistema. Alguns dos erros como, segundo o estudo: ""Our analysis revealed a range of vulnerabilities present in code generated by LLMs, encompassing Simple Stupid Bugs, security-related code smells, Common Weakness Enumeration (CWE) listed vulnerabilities, smart contractspecific vulnerabilities, outdated packages/algorithms, bad coding practices, and incomplete exception handling.""","De acordo com o estudo, na época em questão, não foi identificados estudos que trabalham em especifico os ataques ou ameaças as vulnerabilidades: ""Our Systematic Literature Leview (SLR) has not yet identified any studies that specifically map attacks or threats to the vulnerabilities found in code generated by LLMs. To address this gap, we will expand the scope of the SLR by incorporating a multivocal review approach, which will involve exploring and analyzing grey literature. This broader approach will help us gather additional insights and potentially uncover relevant information regarding the relationship between vulnerabilities in LLM-generated code and potential attack vectors or threats."". Também segundo o estudo, há uma ausência de estudos trabalhando em cima de modelos de ameaça específico incorporando geração de código LLM em um fluxo de trabalho de desenvolvimento seguro: ""To date, there is a lack of studies that propose a specific threat model incorporating LLM code generati","O estudo indica como trabalhos futuros a ampliação do estudo por meio de uma revisão multivocal, incorporando literatura cinzenta para mapear melhor ataques e ameaças associadas ao código gerado por LLMs. Também aponta a necessidade de definir modelos de ameaça específicos que integrem a geração de código por LLMs a fluxos de desenvolvimento seguro.","Devido o fato dos modelos gerarem códigos com erros de segurança, torna difícil a confiança nesses mesmos códigos.","O trabalho sintetiza estratégias de mitigação (prompt engineering, geração iterativa, pós-processamento) e ferramentas complementares (análise estática, DevSecOps, múltiplos modelos) para apoiar o uso seguro de IA generativa no desenvolvimento de software.","""The presence and frequency of vulnerabilities in code generated by Large Language Models (LLMs) can vary depending on the specific context in which the tools are utilized. Factors such as the programming language used in the generated code and the complexity of the task [25] can impact the quality of the output.""

""However, several studies, including the works of Jesse et al. [16], Pearce et al. [6], and Perry et al. [22], have indicated that popular LLM-powered solutions like GitHub Copilot and ChatGPT tend to produce code with vulnerabilities at a higher rate compared to code written by humans without assistance. These studies have found that anywhere between 40% [6] and 70% [17] of the generated code by the models could potentially be vulnerable. Additionally, the models occasionally generate twice as much faulty code as correct code [16]."""
A59,Systematic Literature Review of Prompt Engineering Patterns in Software Engineering,2024,5.5,Scopus,Fully attended to,Fully attended to,Partially attended to,Partially attended to,Fully attended to,Fully attended to,Partially attended to,Jeniffer e Leonardo,"Yuya Sasaki, Hironori Washizaki, Jialong Li, Dominik Sander, Nobukazu Yoshioka, Yoshiaki Fukazawa",Japão e Alemanha,"Waseda University (Japão), University of Hamburg (Alemanha)","2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)",conference,"Técnicas: Revisão Sistemática da Literatura (SLR), Snowballing manual. Processos: Taxonomia de padrões de engenharia de prompt (Learning-Driven, Interaction-Focused, Task-Specific, Systematization). Ferramentas: Frameworks para catalogação de padrões. Métricas: Avaliação de eficácia dos prompts em tarefas de ES.","Construção/Codificação, Design, Manutenção, Testes","Prompt Design (padrões reutilizáveis), Model Tuning (ajuste fino), Parameter Adjustment (temperatura, top-p), In-context learning.","Modelos: GPT-3, GPT-3.5, Codex (baseado em GPT-3), CodeGen, CodeT5, PolyCoder, BERT (PRCBERT). Prompts: Few-shot, Zero-shot, Chain-of-thought (implícito em ""AI Chains""), Interactive Prompting, Iterative Refinement. Arquiteturas: Transformers (implícito nos modelos citados).",LLM,GPT-x,"multiagent, outros, prompt engineering",7000000000.0,"comercial, open source","Codex, GitHub Copilot (mencionado em referências), ferramentas de merge automatizado (merge tool usando k-shot).","Avaliação empírica, comparação de saídas por diferentes wordings de prompt, análise de validade sintática e correção funcional.","correção funcional, precisão, qualidade, segurança","Melhora na eficiência da geração de código, redução no tempo de depuração, melhoria na confiabilidade do código, automação de tarefas complexas (como resolução de conflitos de merge).","Evolução rápida da área (risco de obsolescência), dependência da qualidade do prompt (sensibilidade ao wording), limitações em domínios menos explorados como Requisitos.","Exploração em Engenharia de Requisitos, análise formal da eficácia dos prompts, uso de prompts não-textuais (multimodais).","Examinar aplicabilidade em novos modelos de IA, explorar eficácia em todo o ciclo de vida de desenvolvimento, aprofundar em tarefas individuais.","Fragmentação do conhecimento em engenharia de prompt, falta de entendimento abrangente, necessidade de sistematização e padrões éticos.",O artigo propõe uma taxonomia pioneira para organizar o conhecimento fragmentado sobre engenharia de prompt na ES.,"""Prompt engineering is essential for optimizing their practical utility in software engineering activities.""
""Our taxonomy offers a foundational framework that clarifies the roles of prompt engineering and measures its impact.""  
""The advent of multimodal LLMs... introduces the potential for leveraging nontextual inputs such as diagrams or photos."""
A60,Talking to Data: A Systematic Review of the Rise of Conversational Agents for Visual Analytics,2025,7.0,Scopus,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Brenno,"Martins, Mafalda and Jardim, Bruno and de Castro Neto, Miguel and Barriguinha, André",Portugal,universidade NOVA de Lisboa,IEEE Acess,journal,"O artigo mostra contribuições como o detalhamento da arquitetura de sistemas baseadas em agentes para a geração de código, define processos de validação, os quais no artigo são feitos a partir de agentes de depuração que corrigem os códigos gerados por outros agentes. Além disso, categoriza as ferramentas de interação e define métricas de avaliação dos códigos gerados","Arquitetura, Construção/Codificação, Design, Testes","As principais técnicas exploradas são Natural Language to SQL para interação com banco de dados e Geração de Código, especificadamente Python e especificações declarativas para visualização. Houve o uso de RAG também","Foi utilizado a família GPT (GPT-3.5, GPT-4, GPT-4 Turbo, GPT-4o) predominantemente, mas também foi utilizado Llama 2, Vicuna, Gemini Pro/Vision e CodeLlama","LLM, multimodal","GPT-x, Llama, Mistral, outros","RAG, chain of thought, multiagent, prompt engineering, reAct, self refine",,"comercial, open source","As ferramentas principais de orquestração são LangChain e LlamaIndex. Para manipulação de dados e execução de código gerado, utilizam-se Pandas, Matplotlib, Seaborn, Plotly e Vega-Lite. Frameworks de interface como Streamlit e Chainlit são usados para prototipagem rápida dos chatbots","Dei destaque para 3 técnicas:
1- Estudo de caso (Testes com cenários realistas e dados sintéticos ou reais)
2- Estudo com usuário (Avaliação de usabilidade e satisfação)
3- Benchmarks quantitativos (Uso de datasets padronizados para medir a precisão de geração de código)","carga cognitiva, coerência, correção funcional, precisão, produtividade, qualidade","Permite que usuários sem conhecimento técnico da área gere scripts de código, aumentando a democratização da análise de dados. Além disso, outro beneficio foi o aumento da produtividade na escrita de código repetitivo e permite interações mais naturais e flexíveis com sistema de dados","Alguma limitações citadas são alucinações (geração de códigos defeituosos ou dados falsos), fragilidade dos prompts (qualquer alteração mínima pode gerar mudanças muito grandes) e limitações de tokens (dificuldade em passar dados de bancos inteiros)",Faltam estudos focados em domínios específicos (como administração pública) e sistemas que lidem bem com consultas multi-turno complexas (manutenção de contexto longo). Há uma lacuna na transparência dos modelos (como eles decidem qual gráfico gerar) e na padronização das avaliações,"desenvolvimento de frameworks de avaliação mais robustos e benchmarks padronizados, também destaca a tendência de sistemas multi-agentes com capacidades de auto-correção (debugging) e a integração de conhecimento externo (RAG mais avançado) para melhorar a precisão em domínios específicos",Os maiores desafios se concentram em segurança e privacidade dos dados ao enviar para APIs de LLMs e a manutenção de código gerado por IA que muitas vezes apresentam bugs sutis ou usam bibliotecas já descontinuadas,"Embora o artigo mostre uma democratização através da IA generativa e um aumento de de produtividade, ficou claro que ainda é algo frágil que pode comprometer a segurança de dados, a sua privacidade e que para usufruir dessa tecnologias deve-se ter cuidado pois são muito sensíveis a mudanças de comandos e scripts, o que coloca essa democratização em cheque","""The first consists of rule-based systems that rely on manually defined heuristics and structured parsing... the current stage applies large language models (LLMs). [...] Their capacity to understand intent, reason over multi-turn dialogue, and autonomously generate visualization code from text inputs, opens exciting new possibilities for building intelligent data assistants."" - Achei interessante porque mostra a mudança do paradigma da arquitetura"
A61,The Role of Generative AI Models in Requirements Engineering: A Systematic Literature Review,2025,4.5,Scopus,Fully attended to,Fully attended to,Not attended to,Partially attended to,Fully attended to,Partially attended to,Partially attended to,Henrique da Rocha Lima E Heitor Dias,"Vasudevan, Poonkuzhali and Reddivari, Sandeep",United States,"University of North Florida, Jacksonville, FL",ACMSE 2025 - Proceedings of the 2025 ACM Southeast Conference,conference,"transforma prompts em artefatos formais (modelos de metas, histórias de usuários, roteiros) e integra IA generativa ao ciclo de vida do software. Usa processos estruturados (MAPE-K, classificação de Kitchenham) para garantir confiabilidade.
Técnicas de fine-tuning e engenharia de prompts reduzem alucinação e fragilidade, aumentam transparência e reprodutibilidade, e asseguram validação, consistência e rastreabilidade dos requisitos.",Requisitos,"Estudos usam principalmente modelos Transformer, com destaque para BERT (45%) e GPT (38%), além de GANs e VAEs. As técnicas mais comuns são engenharia de prompts e padrões de prompt para gerar artefatos como scripts, sumários e histórias de usuário.
Também são usados fine-tuning, retreinamento e transfer learning com datasets específicos para melhorar a classificação. Abordagens zero-shot e few-shot processam requisitos sem muitos dados rotulados. A integração ocorre via processos como MAPE-K e técnicas clássicas de PLN, como tokenização e lematização.","Os estudos usam majoritariamente modelos Transformer, com destaque para BERT (~45%) e a série GPT (~38%), além de GANs, VAEs e modelos como RoBERTa, T5, BART, Pegasus, Sentence-BERT, MiniLM, Starcoder e GPT-J-6B.
A interação ocorre via engenharia de prompts e padrões de prompt para gerar artefatos como histórias de usuário, scripts de entrevista e resumos de requisitos. Também são usados fine-tuning, transfer learning e abordagens zero-shot/few-shot com datasets como PROMISE e PURE. A integração operacional inclui o loop MAPE-K e ferramentas como DeepL para detecção de vieses de gênero.",LLM,"GPT-x, StarCoder",prompt engineering,,"comercial, open source","As ferramentas concentram-se em LLMs e suas plataformas: OpenAI (GPT-2, 3, 3.5, 4, Code-cushman), Google (BERT, T5, BARD, Pegasus), Meta (RoBERTa, BART), Nvidia (StarCoder) e EleutherAI (GPT-J-6B).
Como suporte, usam HuggingFace (ex.: Sentence-BERT), DeepL para tradução e detecção de vieses, engenharia de prompts e padrões de prompt para gerar artefatos, e datasets PROMISE e PURE para fine-tuning.","As técnicas de avaliação usam principalmente a classificação de Kitchenham para medir a força da evidência, variando de demonstrações simples até aplicação industrial. Cerca de 39% dos estudos usam experimentos acadêmicos controlados e análises comparativas.
Também há estudos industriais, avaliações por especialistas e observações práticas. Muitos trabalhos comparam modelos (ex.: GPT-3 vs. BERT em requisitos) e utilizam demonstrações técnicas via engenharia de prompts para validar a viabilidade das soluções.","coerência, precisão, qualidade, recall","A utilização de modelos de IA generativa, especialmente os Grandes Modelos de Linguagem (LLMs), oferece uma versatilidade significativa em diversas tarefas de ER, permitindo a automação e otimização de processos que tradicionalmente dependem de linguagem natural. Esses modelos demonstram eficácia na geração de artefatos, como histórias de usuários, roteiros de entrevista de elicitação e resumos de requisitos, o que contribui para a aceleração do desenvolvimento de software. Além disso, a aplicação de técnicas como o ajuste fino (fine-tuning) permite que modelos genéricos identifiquem, classifiquem e extraiam requisitos de fontes textuais de forma eficiente","Uma das principais limitações identificadas é a dependência excessiva de LLMs, o que restringe a exploração de outros modelos de GenAI (como GANs ou VAEs) que poderiam endereçar desafios específicos de forma mais eficaz. O desempenho desses modelos é altamente dependente da qualidade dos dados de treinamento; dados inadequados ou imprecisos podem resultar em saídas enviesadas ou performances subótimas. Outra limitação crítica é a natureza de ""caixa-preta"" dos modelos, que dificulta a interpretação de seu funcionamento interno, gerando desafios para a transparência e a responsabilidade no processo de engenharia.","Existe uma lacuna clara na literatura quanto à aplicação de GenAI nas fases de validação e gerenciamento de requisitos, que são as atividades menos exploradas em comparação com análise e elicitação. Além disso, a pesquisa atual carece de uma maior variedade de modelos e técnicas fora do eixo Transformers (BERT/GPT), indicando que ferramentas mais eficazes podem ainda não ter sido desenvolvidas ou publicadas. Há também uma necessidade de fortalecer a evidência científica industrial, já que a maioria dos estudos atuais é baseada em demonstrações ou experimentos acadêmicos controlados.",Os autores sugerem que pesquisas futuras devem focar na investigação da aplicabilidade e disponibilidade de outros modelos de GenAI além dos LLMs para tarefas de ER. O objetivo é descobrir métodos que possam mitigar as limitações atuais e oferecer soluções mais robustas para os desafios complexos da Engenharia de Software.,"Os principais desafios envolvem a garantia de confiabilidade e precisão, dada a propensão de modelos generativos a produzir resultados baseados em dados de treinamento que podem conter vieses. A integração de IA no ciclo de vida do software exige processos que garantam a auditabilidade e a consistência dos requisitos gerados, enfrentando o risco de alucinações dos modelos.","O estudo revela que o campo está em rápida expansão, com a maior parte da literatura produzida na última década e concentrada em bases como IEEE (55%) e Springer (14%). O modelo BERT é o mais prevalente nas pesquisas (45%), seguido de perto pela série GPT (38%). Para avaliar o rigor das pesquisas, os autores utilizam a classificação de Kitchenham, que mede a força da evidência científica apresentada nos estudos.","Viés de Gênero: Uso do DeepL para detectar vieses, traduzindo tarefas para o finlandês (sem gênero) e de volta ao inglês, analisando atribuições de gênero a funções técnicas.
MAPE-K Loop: Integração de LLMs ao loop MAPE-K para gerar automaticamente modelos de metas de requisitos não funcionais.
Títulos Provocativos: Referência ao artigo “Is BERT the New Silver Bullet?”, sobre classificação de dependência de requisitos.]
;
O Ciclo MAPE-K (Monitorar, Analisar, Planejar e Executar) é uma técnica para controlar um sistema de software executando quatro passos em um ciclo. LLMs são utilizados no processo MAPE-K para gerar modelos de metas de requisitos não funcionais [36]. O tradutor de idiomas DeepL foi usado em um estudo para identificar viés de gênero na ER, analisando pronomes em tarefas. As tarefas foram traduzidas para finlandês, uma língua sem gênero, e de volta para o inglês usando o DeepL [45]."
A62,The use of large language models for program repair,2025,5.0,Scopus,Partially attended to,Fully attended to,Partially attended to,Fully attended to,Fully attended to,Partially attended to,Partially attended to,Heitor e Henrique da Rocha Lima,"Fida Zubair, Maryam Al-Hitmi , Cagatay Catal",Qatar,"Department of Computer Science and Engineering, College of Engineering, Qatar University, 2713, Doha, Qatar",Computer Standards & Interfaces,journal,"Uso de testes automatizados como oráculo de correção. Integração da IA generativa ao processo de manutenção de software, especificamente à atividade de correção de defeitos. Uso de baselines consolidados de APR. Emprego de pipelines de compilação e teste automatizados, fundamentais para validar patches gerados por LLMs. Adoção da métrica Correção funcional (passar nos testes)",Construção/Codificação,"1 - Modelos de Linguagem de Grande Porte (LLMs) para geração de código
2 - Formulação do reparo como Tradução Neural (Neural Machine Translation – NMT)
3 - Arquiteturas generativas baseadas em Transformers
4 - Fine-tuning
5 - Prompt-based code generation
6 - Geração colaborativa e iterativa de patches","Para is MLMs, o estudo explorou: GPT, GPT-2, GPT-3, GPT-3.5, GPT-4, Codex, ChatGPT, GPT-Neo, GPT-J, GPT-NeoX, CodeGen, InCoder, StarCoder. Já para os SLMs, o estudo explorou: Principais SLMs explorados: BERT, CodeBERT, GraphCodeBERT, RoBERTa, UniXcoder

O estudo identifica três arquiteturas principais, todas baseadas em Transformers: Decoder-only, Encoder–Decoder e Encoder-only. Além disso, o estudo também apontou os seguintes tipos de prompts: prompts instrucionais, prompts baseados em descrição de bugs, Few-shot prompts e prompts de refinamento iterativo","LLM, SLM, multimodal","GPT-x, StarCoder, outros","outros, prompt engineering",,,"Os estudos analisados utilizam principalmente frameworks de aprendizado profundo, como PyTorch e TensorFlow, juntamente com bibliotecas de modelos pré-treinados, como Hugging Face Transformers, para dar suporte à aplicação de IA generativa em Engenharia de Software. A validação dos resultados é realizada por meio de ferramentas tradicionais de ES, como pipelines de testes automatizados e benchmarks amplamente utilizados, incluindo Defects4J.","Avaliação baseada em suítes de testes automatizados, distinção entre patches plausíveis e patches semanticamente corretos, avaliação quantitativa por métricas de desempenho (ex.: top-k accuracy), avaliação comparativa com baselines, uso de benchmarks padronizados de Engenharia de Software.","correção funcional, precisão, recall","""Ao incorporar esses modelos em seus fluxos de trabalho diários, os desenvolvedores podem experimentar maior flexibilidade no gerenciamento de software."" -> ""Studies like [2] demonstrate the use of CodeT5, a pre-trained model, on datasets like Defects4j to target specific aspects of program repair such as validation and input representation. - Introduction""

""A utilização desses modelos dentro das equipes de desenvolvimento de software permite uma resolução de problemas mais rápida e uma melhoria contínua no design e implementação de software.""->""Utilizing these models within software development teams allows for faster problem resolution and continuous improvement in software design and implementation""","As limitações incluem geração de patches plausíveis porém incorretos, dependência da qualidade dos testes, baixa explicabilidade, sensibilidade a prompts, limitações de generalização, alto custo computacional e avaliação restrita a ambientes experimentais.","""O número relativamente baixo de artigos sobre bugs de vulnerabilidade de segurança indica uma lacuna potencial na pesquisa.""->""The relatively low number of papers on security vulnerability bugs indicates a potential gap in research. ""

""Erros semânticos e sintáticos são os erros mais focados para reparo de programas. Há um foco claro em bugs de software quando comparado a vulnerabilidades de segurança. Isso indica uma ênfase mais forte no reparo da funcionalidade do software em vez de problemas específicos de segurança. Essa tendência sugere uma lacuna potencial na pesquisa.""->""Semantic and syntax errors are the most focused errors for program repair. There is a clear focus on software bugs when compared to security vulnerabilities. This indicates a stronger emphasis on software functionality repair rather than security-specific issues. This trend suggests a potential gap in research.""","Melhoria da correção semântica dos patches, o estudo de estratégias avançadas de fine-tuning, a avaliação da generalização em novos domínios e linguagens, a análise de custos computacionais, o aprimoramento das técnicas de avaliação e a integração dos LLMs a processos reais de Engenharia de Software.","Alguns dos desafios associados aos LLMs são a complexidade e escala dos dados, sensibilidade à tokenização, exigencia de recursos computacionais substanciais, complexidade do ajuste fine, restrições contextuias, conhecimento sendo temporário, complexidade de avaliação e vies na saída","O artigo atua principalmente como uma síntese e caracterização do estado da arte, e não como proposição de uma nova técnica.","“Fine-tuning Adaptability to specific program repair tasks through focused training. The fine-tuning of pre-trained models can effectively use existing knowledge to solve a particular problem.”

""The novelty of this work lies in its comprehensive exploration of the role of LLMs in program repair, providing valuable insights into their applications and effectiveness. The contributions of this article are as follows:
1 - This article represents the most recent and comprehensive SLR focusing on LLMs for program repair. Our research investigates various applications and assesses the impact of LLMs on program repair methodologies.
2 - Our SLR thoroughly examines the datasets utilized in LLM-based program repair, providing insights into the breadth and quality of available data. Furthermore, an in-depth exploration of the different LLM architectures employed in program repair enhances our understanding of this evolving field.
3 - Our SLR carefully investigates the fundamental characteristics"
A63,Time-Series Large Language Models: A Systematic Review of State-of-the-Art,2025,0.0,Scopus,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Not attended to,Líbna Raffaely  - excluído pelo critério EC4( Does not address GenAI for SE activities),"Abdullahi, Shamsu and Danyaro, Kamaluddeen Usman and Zakari, Abubakar and Abdul Aziz, Izzatdin and Amila Wan Abdullah Zawawi, Noor and Adamu, Shamsuddeen","Malaysia, Nigeria","Department of Computer and Information Sciences, Department of Computer Science, Civil and Environmental Engineering Department",IEEE,journal,"Este artigo sintetiza o estado da arte das abordagens que aplicam Large Language Models (LLMs) a dados temporais, mostrando como esses modelos evoluíram arquiteturalmente e em estratégias de tokenização para analisar séries temporais, e ao destacar tarefas, conjuntos de dados e métricas de avaliação; embora o foco principal não seja diretamente na engenharia de software tradicional, ele mostra como LLMs podem ser usados como base para análises sequenciais e preditivas que eventualmente suportam sistemas de software que dependem de séries temporais, como sistemas preditivos, monitoramento e automação de decisões",,,,,,,,,,,,,,,,,,
A64,Towards Using Personas in Requirements Engineering: What Has Been Changed Recently?,2025,6.0,Scopus,Fully attended to,Fully attended to,Partially attended to,Fully attended to,Fully attended to,Partially attended to,Fully attended to,"Leonardo Lima e Silva
Jeniffer","Chowdhury Shahriar Muzammel, Maria Spichkova, James Harland.",Austrália.,RMIT University.,33rd IEEE International Requirements Engineering Conference Workshops (REW'25).,workshop,"O artigo apresenta um Mapeamento Sistemático (SMS) que identifica como técnicas de IA são aplicadas na construção e validação de personas dentro da Engenharia de Requisitos. O estudo destaca o uso de IA para gerar descrições de personas a partir de feedback de usuários e a utilização de agentes de IA para auxiliar na geração de personas baseadas em experiências de usuários finais. Além disso, aponta o uso de IA para suporte em atividades de elicitação e validação de requisitos.",Requisitos,"O estudo explora o uso de Grafos de Conhecimento combinados com LLMs , agentes de IA (AI agents) e prompts baseados em cenários (scenario-based prompts) para gerar personas.",O artigo cita explicitamente o uso do ChatGPT-4 para gerar descrições de personas. Também menciona genericamente o uso de LLMs no contexto de discussão sobre viés na representação de personas.,LLM,GPT-x,"outros, prompt engineering",0.0,comercial,O artigo identifica ferramentas como o PersonaGen (que utiliza grafo de conhecimento e ChatGPT-4 para gerar personas a partir de feedback) e menciona a ferramenta Crafter para geração de personas.,"O estudo destaca o surgimento de ""Validação baseada em IA"" (AI-based validation) como uma nova categoria de técnica de avaliação. Além disso, menciona o uso de personas geradas para avaliar artefatos de design e a validação das próprias personas através de entrevistas, cenários e documentos de validação.",outros,O uso de IA permite otimizar (streamline) o uso de personas na Engenharia de Requisitos. Soluções baseadas em IA ajudam a identificar requisitos desconhecidos ou negligenciados e possibilitam a geração de personas virtuais para aumentar a diversidade e inclusão em sistemas de IA.,"A criação de personas, incluindo métodos via IA, pode embutir viés (bias). A dependência de personas geradas pode causar uma desconexão física com o usuário real, reintroduzindo vieses do projetista e levando a requisitos incorretos.","A validação da correção (correctness) das personas geradas permanece uma questão em aberto (""open issue""). Há uma oportunidade para desenvolver técnicas de validação eficazes, especialmente para ambientes de Engenharia de Requisitos baseada em multidões (CrowdRE), onde a IA poderia identificar requisitos desconhecidos em larga escala.","Melhorar a automação e escalabilidade baseadas em IA. Fortalecer processos metodológicos para apoiar a confiabilidade, bem como a diversidade e inclusão nas personas geradas. Investigar como personas podem identificar requisitos desconhecidos automaticamente em larga escala.",Os principais desafios envolvem a validação da acurácia das personas geradas e o gerenciamento de vieses (bias) inerentes à criação de personas e aos modelos subjacentes. A falta de interação direta com usuários finais é citada como um desafio crítico.,"Este artigo é um estudo de replicação (Systematic Mapping Study) que atualiza um estudo anterior, cobrindo especificamente o período de abril de 2023 a abril de 2025 para capturar o impacto recente da IA Generativa e GenAI na área. Observou-se um aumento no uso de templates para representação de personas em detrimento de narrativas.","""We identified that a number of studies applied AI-based solutions for persona construction and validation."" ""Subjective personas without empirical data may negatively impact software development"". ""The longer you physically disconnect from that person, the more your own bias comes into play again"". ""Validating the correctness of the Personas is an open issue""."
A65,Unlocking the Potential of the Prompt Engineering Paradigm in Software Engineering: A Systematic Literature Review,2025,5.5,Scopus,Partially attended to,Fully attended to,Not attended to,Fully attended to,Fully attended to,Fully attended to,Fully attended to,Heitor e Henrique da Rocha Lima,"Irdina Wanda Syahputri, Eko K. Budiardjo e Panca O. Hadi Putra",Indonesia,"Faculty of Computer Science, Universitas Indonesia",AI (MDPI),journal,"Transformar prompts em artefatos de engenharia, integrar IA ao ciclo de vida do software, fornecer processos estruturados, escaláveis e auditáveis, reduzir riscos como alucinação, fragilidade e falta de reprodutibilidade.","Construção/Codificação, Testes","Prompt Engineering é a técnica central de IA que o estudo analisou, por meio de prompts cuidadosamente orquestrados, é possível usar LLMs para gerar código, detectar bugs, executar testes de software, rastrear requisitos e documentar. O estudo também explora as vertentes de prompt engineering, como manual prompt crafting, few-shot prompting, chain-of-thought prompting, soft prompt tuning; Além disso, o estudo propõe uma taxonomia de técnicas de prompt engineering e realiza um mapeamento sistemático da literatura em Engenharia de Software.; Automatic prompt generation, prompt refinement loops e integração com processos human-in-the-loop.","O estudo mostra que a base técnica dominante da IA generativa em ES são Large Language Models (LLMs), tratados como foundation models, porém não aprofunda arquiteturas proprietárias específicas. O estudo não foca em SLMs, apenas identifica seu uso indireto em modelos de recuperação (IR / embeddings) usados em conjunto com LLMs.

No que se refere aos prompts explorados, o estudo dedica uma classificação explícita dos tipos de prompts, sendo eles: Zero-shot prompts, Few-shot prompts, Chain-of-Thought (CoT) prompts, Task-specific prompts, soft prompts e automatically generated prompts. Sobres essas questões de Prompt Engineering, podem ser encontradas na Seção 3.2 e nas tabelas 3, 4 e 5

O estudo não propõe novas arquiteturas neurais, mas identifica arquiteturas de uso (LLM puro, LLM com Retrieval-Augmented Generation e Prompt Engineering as Code, frequentemente integradas a processos human-in-the-loop).; Zero-shot prompts, few-shot prompts, chain-of-thought (CoT) prompts, task-specific p",LLM,GPT-x,"RAG, chain of thought, prompt engineering",,,Não se aplica,"- Precision, recall e F1
- BLEU e ROUGE
- Avaliação humana estruturada 
- Comparações entre técnicas de prompt engineering
- Uso de benchmarks existentes e experimentos controlados, embora destaque limitações dessas abordagens para capturar plenamente a qualidade do software.","outros, precisão, qualidade, recall","""A engenharia de prompts desempenha um papel central na mitigação das limitações da IA Gen, influenciando o comportamento do LLM por meio da estruturação deliberada de prompts [1]"" -> ""Prompt engineering plays a central role in mitigating GenAI’s limitations by influencing LLM behavior through deliberate prompt structuring [1]""; Ganhos em produtividade, redução de esforço cognitivo, apoio à tomada de decisão e aceleração do ciclo de desenvolvimento.","O estudo identifica limitações importantes no uso de IA generativa para Engenharia de Software, incluindo forte dependência de prompt engineering, baixa reprodutibilidade, ausência de métricas específicas de ES, risco de alucinações, necessidade de intervenção humana, dificuldade de integração ao ciclo de vida completo do software e limitações de generalização para contextos industriais.; Dependência de dados de alta qualidade e dificuldade de validação automática dos resultados.","""Questões comuns incluem overfitting em conjuntos de dados de tarefas restritas, fragilidade do prompt sob pequenas variações de entrada e alta sobrecarga computacional durante o fine-tuning ou geração [13]. Essas lacunas abrem caminhos para o desenvolvimento de novas estruturas de EP que podem se adaptar dinamicamente aos contextos em evolução dos projetos de ES, aumentando tanto a eficácia quanto a eficiência."" -> ""Common issues include overfitting to narrow task datasets, prompt fragility under small input variations, and high computational overhead during fine-tuning or generation [13]. These gaps open pathways for developing novel PE frameworks that can dynamically adapt to the evolving contexts of SE projects, enhancing both effectiveness and efficiency.""; Falta de benchmarks padronizados, ausência de frameworks de governança e carência de métricas específicas de Engenharia de Software.","O artigo indica como trabalhos futuros a definição de métricas específicas de Engenharia de Software, a padronização e reprodutibilidade dos experimentos, a sistematização do prompt engineering, a integração da genAI ao ciclo de vida completo do software, avaliações em cenários industriais reais, estratégias para redução de alucinações e o avanço de técnicas automáticas de criação e otimização de prompts.; Desenvolvimento de mecanismos de governança, versionamento de prompts e conformidade ética.","1 - Dependência crítica de Prompt Engineering
2 - Baixa reprodutibilidade experimental
3 - Ausência de métricas específicas de ES
4 - Alucinações e respostas tecnicamente incorretas
5 - Necessidade constante de intervenção humana
6 - Dificuldade de integração ao ciclo de vida completo do software
7 - Generalização limitada dos resultados
8 - Dependência de contexto e dados externos
9 - Falta de padronização e governança","O estudo trouxe imagens implementações práticas de RAG em diversos cenários, como detecção de bugs, engenharia de requisitos e metodologias de software","""PE has been employed to enhance a variety of SE activities, including code generation, bug detection, software traceability, and automated documentation, ultimately contributing to increased developer productivity and reduced error rates throughout the software development life cycle [6,7]. However, the diversity and complexity of SE tasks suggest that a one-size-fits-all approach to prompt engineering is insufficient.""

""One of the unique contributions of this paper is its focus on the gaps in the implementation of PE across the entire software development life cycle, covering stages such as requirement gathering, AI 2025, 6, 206 4 of 37 design, implementation, testing, deployment, and maintenance. Moreover, this paper highlights the dependency of PE on domain knowledge and the importance of proper prompt design to ensure that these techniques can adapt to the dynamic context of SE. Through the use of co-citation network mapping and thematic analysis, this study provides a clearer pi"
A66,Using LLMs to enhance code quality: A systematic literature review,2026,6.0,Scopus,Fully attended to,Fully attended to,Fully attended to,Partially attended to,Fully attended to,Partially attended to,Fully attended to,Henrique da Rocha Lima E Heitor Dias,"Alomari, Nawaf and Redah, Moussa and Ashraf, Ahmed and Alshayeb, Mohammad R.",Arábia saudita,"Information and Computer Science Department, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia
Interdisciplinary Research Center for Intelligent Secure Systems, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia",Information and Software Technology,journal,"Refatoração automatica, detecção de code smells, automatização de testes e a execução de outras tarefas que contribuam para a qualidade de codigo","Construção/Codificação, Testes","Zero-Shot Learning: O modelo realiza a tarefa (como detecção de code smells ou refatoração) baseando-se apenas na descrição do comando, sem exemplos prévios
Few-Shot Learning: Incluem-se exemplos de demonstração no prompt para melhorar o desempenho do modelo. Esta é a técnica de prompting mais frequente nos estudos analisados
In-Context Learning: O modelo interpreta a tarefa com base no contexto fornecido diretamente no prompt
Chain-of-Thought (CoT): Orienta o modelo a seguir um raciocínio lógico passo a passo antes de apresentar a resposta final, sendo útil para tarefas complexas, embora ainda seja pouco explorada em ES
Least-to-Most Prompting: Uma técnica onde o problema é decomposto em subproblemas menores
Instruction Tuning: Ajuste do modelo para seguir instruções específicas
Transfer Learning: Aplicação de conhecimento de um domínio para outro
Arquiteturas Encoder-Decoder: O uso de modelos como o CodeT5, onde um codificador processa o código original e um decodificador gera a vers","Série GPT/OpenAI: GPT-2, GPT-3, GPT-3.5, GPT-3.5-turbo, GPT-4, GPT-4-turbo, Codex, Text-davinci-003, Code-davinci-002, ChatGPT.
Família Llama/Meta: LLaMA, LLaMA-1, LLaMA-2, LLaMA-7B, Llama-2-70B, Llama-2-70B-cha, CodeLlama, Code-Llama-34B.
Modelos Específicos para Código: CodeBERT, GraphCodeBERT, CodeGPT, CodeT5, CodeT5+, Unixcoder, RefBERT, JavaBERT, CodeBERTa, CodeFuse-13B, StarCoder, CODEGEN, Magicoder, SumLLaMA, DoctorCoder, INCODER, RefT5, InstructCoder.
Modelos de Representação (BERT e variações): BERT, RoBERTa, DistilBERT, DistilGPT, CuBERT, ELMo, CodeELBE.
Outros Modelos: PaLM 2, Mistral-7B, BLOOM, KSCLP, FINDGATE, LineVul, DeepDFA+LineVul
Arquiteturas: Transformer, Transformer encoder, CoRT.
Modelos de Deep Learning Tradicionais: CNN (Convolutional Neural Networks), LSTM (Long Short-Term Memory), Bi-LSTM, RNN (Recurrent Neural Networks), ANN (Artificial Neural Networks)","LLM, SLM, multimodal, outro","GPT-x, Mistral, TinyLlama, outros","chain of thought, outros, prompt engineering, self refine",175000000000.0,,"Infraestrutura e Frameworks de Desenvolvimento
LangChain: Utilizado para o refinamento iterativo de scripts de teste gerados por IA.
GitHub CI/CD Framework: Utilizado para criar pipelines automatizados que detectam code smells e aplicam refatoração em cada mudança de código.
APIs (ex: OpenAI API): Permitem o acesso e a utilização de modelos de código fechado (como a série GPT), possibilitando técnicas de prompting e, em alguns casos, fine-tuning dentro de restrições específicas.

Assistentes e Chatbots de Codificação
ChatGPT, Codex e GitHub Copilot: Identificados como assistentes de codificação que reagem a entradas de código em contextos educacionais e profissionais.
AICodeReview: Uma ferramenta específica citada para avançar a qualidade do código através de revisões automatizadas aprimoradas por IA.
InstructCoder: Utilizada para edição de código através de ajuste de instruções (instruction tuning).

Ferramentas de Avaliação e Validação
GCOV: Ferramenta utilizada para validar a cobert","Metodologias de Validação (RQ6)
Os estudos utilizam diferentes abordagens para garantir a confiabilidade dos resultados:
Conjuntos de Dados de Validação (Validation Datasets): É o método mais frequente, onde o desempenho do modelo é avaliado em um subconjunto de dados designado para este fim.
Validação por Especialistas (Expert Validation): Envolve a avaliação por profissionais da área para garantir a precisão e a relevância contextual das saídas do modelo.
Datasets de Benchmark: Uso de conjuntos de dados padronizados, como HumanEval (para geração de código) e Defects4J (para localização e reparo de bugs), para permitir comparações objetivas.
Comparação com Baselines: O desempenho da IA é medido em relação a ferramentas tradicionais (como JExtract para refatoração ou ATLAS para testes) ou modelos de aprendizado de máquina anteriores.
Validação Qualitativa vs. Quantitativa: Os pesquisadores buscam um equilíbrio entre a eficácia técnica (métrica quantitativa) e a aplicabilidade em cenári","outros, precisão, recall","Superioridade sobre abordagens tradicionais: LLMs frequentemente superam métodos baseados em regras, heurísticas ou aprendizado de máquina tradicional (como KNN) na detecção de code smells e na localização de falhas.
Generalização e Eficiência de Dados: Modelos ajustados (fine-tuned) generalizam melhor para conjuntos de dados não vistos e são mais eficientes em termos de dados, exigindo menos exemplos rotulados do que o aprendizado supervisionado tradicional.
Maior Cobertura de Testes: Em comparação com ferramentas especializadas como ATLAS e TOGA, as abordagens baseadas em LLM alcançam uma cobertura de código significativamente maior ao analisar simultaneamente os requisitos e a aplicação.
Automação e Redução de Custos: A GenAI permite a automação completa ou semiautomática de processos de refatoração e revisão de código, reduzindo o esforço manual, a probabilidade de erros humanos e os custos operacionais.
Compreensão Semântica: Devido à arquitetura baseada em Transformers, os LLMs c","Falta de Confiabilidade no Código Gerado: O código refatorado por LLMs muitas vezes não é executável imediatamente, apresentando erros sintáticos ou falhas de compilação.
Alucinações: Um problema crítico é a geração de sugestões incorretas ou irrelevantes; em alguns estudos, a taxa de alucinação chegou a 76,3%.
Restrições de Contexto: O tamanho limitado da janela de contexto dos modelos atuais dificulta a realização de refatorações complexas ""entre classes"" (between-classes), que exigem uma visão sistêmica de múltiplos arquivos e dependências.
Custo Computacional: Hospedar e executar LLMs de grande escala exige poder computacional massivo, o que pode ser proibitivo para certas organizações.","Atributos de Qualidade Externa: Existe uma falta de estudos que conectem diretamente o uso de LLMs a melhorias em atributos externos, como manutenibilidade e confiabilidade.
Diversidade de Linguagens: A pesquisa atual está fortemente concentrada em Java e Python, deixando uma lacuna para a criação de conjuntos de dados e avaliações em linguagens menos predominantes.
Técnicas de Prompting Avançadas: Métodos como Chain-of-Thought (CoT) e Aprendizado por Reforço com Feedback Humano (RLHF) ainda são pouco explorados no contexto da qualidade de código.","Fine-tuning para Refatoração: Priorizar o ajuste fino de modelos em vez de apenas prompting para obter resultados mais estáveis e confiáveis em tarefas de transformação de código.
Criação de Benchmarks Especializados: Desenvolver conjuntos de dados de referência padronizados para tarefas específicas, como detecção de smells e refatoração, para permitir comparações justas entre modelos.
Datasets de Pares de Refatoração: Construir e expandir bases de dados que contenham exemplos pareados de código antes e depois da refatoração.
Expansão do Escopo da SLR: Realizar revisões sistemáticas focadas em outras áreas da ES, como experiência do usuário (UX), produtividade do desenvolvedor e processos de desenvolvimento.;
Trabalhos futuros poderiam investigar mais a fundo o potencial de Chain of Thought (CoT) para aumentar a precisão e a confiabilidade dos LLMs em tarefas relacionadas a código.","Formulações de Sequência para Sequência: É desafiador formular tarefas de refatoração como problemas de tradução de código que preservem a funcionalidade original enquanto modificam apenas partes específicas.
Transparência Metodológica: Muitos estudos não detalham suas estratégias de prompting ou configurações de hiperparâmetros, o que prejudica a reprodutibilidade e a comparação de resultados.
Hardware e Recursos: O desafio de implantar modelos de alta capacidade (como os de 70B parâmetros) em máquinas com recursos limitados, forçando um compromisso entre desempenho e viabilidade técnica.",";O estudo traz uma relação dos principais code smells encontrados nos estudos primários, e também fornece as principais atividades que os LLMs podem trabalhar na codificação. O estudo também identifica que, com base nos seus estudos, a tarefa mais aplicada a melhoria de código foi a refatoração, com a Extract Method sendo a técnica mais usual. O estudo também conclui que: ""Na detecção de code smells, o uso de prompts é preferido devido à sua aplicabilidade em diferentes linguagens e por ser o método mais comumente abordado."". Também fornece os hiperparametros, que foram ajustados, utilizados nos estudos de LLMs. O estudo também proporciona uma relação de quais as métricas mais utilizadas para as tarefas e técnicas. O estudo traz uma relação dos conjuntos de dados utilizados, com sua linguagem de programação e seu tamanho","O Problema da Alucinação na Refatoração: Embora a refatoração seja a tarefa mais estudada (mencionada em 11 dos 49 estudos), os resultados mostram que o código gerado frequentemente não é confiável,. Em um estudo específico (PS13), os pesquisadores descobriram que 76,3% das sugestões de refatoração feitas pela IA eram ""alucinações"", sendo que 57,4% continham erros sintáticos que impediam a compilação.
Superioridade sobre Ferramentas Tradicionais: Apesar dos erros, o artigo destaca que os LLMs conseguem superar ferramentas clássicas de engenharia de software em certas métricas. Por exemplo, uma abordagem baseada em LLM superou a ferramenta de análise estática JExtract, alcançando uma taxa de sucesso de 53,4% contra 39,4% da ferramenta tradicional. Além disso, em testes automatizados, as IAs conseguiram uma cobertura de código de 80% a 100%, superando ferramentas padrão como ATLAS e TOGA,.
Dominância Geográfica Inesperada: Um dado estatístico curioso é a distribuição da pesquisa nesta ár"
A67,Using Reinforcement Learning for Security Testing: A Systematic Mapping Study,2025,5.0,Scopus,Partially attended to,Partially attended to,Partially attended to,Fully attended to,Fully attended to,Partially attended to,Fully attended to,Jeniffer e Leonardo,"Tanwir Ahmad, Matko Butkovic, Dragos Truscan",Finlândia,"Dept. of Information Technology, Åbo Akademi University, Turku, Finland","IEEE ICST Workshops (International Conference on Software Testing, Verification and Validation – Workshops)",workshop,"A principal contribuição da ES é o domínio do problema (Teste de Segurança) e a metodologia de pesquisa (SMS) . As técnicas de ES aplicadas/otimizadas por RL incluem: Geração de Testes (para Penetration Testing e Fuzzing), Automação de Testes de Segurança e Otimização de Processos de Teste (e.g., agendamento de mutação em fuzzing ). Ferramentas de ES como AFL (fuzzing) e metodologias de teste como Penetration Testing e Vulnerability Scanning são o foco da aplicação de RL.","Manutenção, Operações/DevOps, Testes",Apenas uma técnica de GenAI foi identificada: a combinação de um Modelo de Linguagem Pré-treinado Generativo (GPT) com o algoritmo RL PPO para black-box testing de Web Application Firewalls (WAFs).,"Uso extensivo de Reinforcement Learning (RL) para automação de security testing (pen testing, fuzzing, vulnerability discovery).
Combinação de GPT com PPO (Proximal Policy Optimization). Dentre os algoritmos de RL, alem de PPO, temos DQN (mais frequente), Q-Learning (tabular), DDQN, Dueling DQN, Dueling DDQN, CQL, DDPG (Deep Deterministic Policy Gradient), A2C (Advantage Actor-Critic), A3C (Asynchronous Advantage Actor-Critic), TD3 (Twin Delayed DDPG).","LLM, outro",GPT-x,multiagent,7000000000.0,"open source, outro",GPTFuzzer (Fuzzing com RL + LLM),"Simulação (para testar desempenho e robustez em ambiente controlado), Experimento (para testar em ambientes reais, oferecendo relevância prática) e Estudo de Caso (para analisar a aplicação da metodologia em um contexto específico).","cobertura, correção funcional, precisão, redução de esforço, segurança","Automação do processo de teste (reduzindo a intervenção humana), Otimização da geração de testes (focando em partes relevantes do sistema), Adaptação a novos cenários e ameaças em tempo real, Identificação de Vulnerabilidades Não Intuitivas e vetores de ataque, Escalabilidade do processo de teste de segurança (especialmente em grandes espaços de estado e ação).","Generalização (dificuldade em aplicar modelos treinados a novos ambientes ou topologias de rede), Robustez (sensibilidade a pequenas mudanças no ambiente), Interpretabilidade (dificuldade em entender as decisões do agente de RL), Falta de Padronização (ausência de benchmarks, conjuntos de dados e métricas de avaliação padronizadas).","Teste de Regressão de Segurança (aplicar RL para garantir que sistemas em evolução mantenham a segurança), Padronização de ambientes de teste, benchmarks e métricas, Expansão do penetration testing guiado por RL para melhorar a adaptabilidade a redes desconhecidas e reduzir falsos positivos, Melhoria do Suporte a Ferramentas para adoção industrial.","O artigo conclui que trabalhos futuros devem focar em abordar as lacunas identificadas, como a falta de estudos sobre teste de regressão de segurança e a necessidade de padronização e melhoria da interpretabilidade dos modelos de RL.","Generalização, Robustez e Interpretabilidade limitam a aplicabilidade prática das abordagens baseadas em RL no teste de segurança. A literatura também não aborda adequadamente as metodologias DevOps e DevSecOps.","O estudo de mapeamento sistemático analisou 47 estudos primários publicados nos últimos 10 anos (2014-2024), observando uma tendência crescente de interesse na área. O Penetration Testing é o método de teste de segurança mais estudado (30 estudos), seguido por Fuzz Testing (8 estudos). O algoritmo DQN e suas variantes são os mais utilizados.","Aqui estão trechos significativos e literais do artigo, que sintetizam as principais descobertas dos autores:

""The primary goal of using RL in security testing is to automate the generation of test cases that can effectively find vulnerabilities by learning from the feedback provided by the target system.""

""Unlike traditional fuzzing, where test inputs are often generated randomly, RL-based approaches can adapt their strategy based on the rewards received, focusing the search on more promising areas of the input space.""

""The design of the reward function is the most critical and challenging part of applying RL to security testing, as it must guide the agent toward discovering complex security flaws without getting stuck in local optima."""
A68,"Why Adapt RAG for Agile? Challenges, Frameworks, and the Role of Evaluator Agent",2026,4.5,Scopus,Not attended to,Fully attended to,Not attended to,Partially attended to,Fully attended to,Fully attended to,Fully attended to,Ana Karolina E Filipe Campos,"Ayman Asad Khan, Md Toufique Hasan, Mika Saari, Kai-Kristian Kemell e Jussi Rasku",Finlândia,"Tampere University, Tampere, Finlândia","Agile Processes in Software  Engineering and Extreme  Programming – Workshops (XP 2025 Workshops Brugg-Windisch, Switzerland, June 2–5, 2025 Revised Selected Papers)",conference,"A contribuição do artigo a alguma área da Engenharia de Software reside na integração de técnicas de IA Generativa (RAG + LLMs) aos processos de Engenharia de Software, com foco em avaliação contínua, feedback em tempo real e alinhamento com métodos ágeis. Os autores também buscam por trabalhos que possam amparar a definição e adaptação de frameworks de avaliação para sistemas RAG.","Arquitetura, Construção/Codificação, Design, Gestão de projeto, Manutenção, Operações/DevOps, Requisitos, Testes","O artigo levanta a possibilidade de se adaptar a técnica RAG para ser utilizada na abordagem de desenvolvimento de software ágil. Se trata de mapeamento sistemático de estudos e para isso os autores se amparam em duas questões de pesquisa, 1) Quais são as estruturas de avaliação existentes para RAG e 2) Como essas estruturas poderiam ser adaptadas para serem aplicadas ao desenvolvimento ágil. Como a ideia central do artigo é criar uma solução para a utilização de LLMs no desenvolvimento ágil que envolva utilizar RAG e a abordagem ágil é um tipo de processo da Engenharia de Software, ela acaba envolvendo todas as atividades da Engenharia de Software relacionadas ao ciclo de vida do software.","O trabalho apresenta as informações encontradas nos artigos selecionados e dentre eles existem resultados com LLMs baseados em RAG, estruturas de avaliação multimodal, IA generativa, agentes de IA (StackRAG)","LLM, multimodal",,"RAG, multiagent, self refine",,,"Sistemas RAG integrados a LLMs, ferramentas de avaliação automática, sistemas de gestão ágil.","Métricas NLG como BLEU e ROUGE, avaliação humana, avaliação multimodal, Inverted Question Matching (IQM), modelo de autoavaliação (	Hammane et al.).; 
Uma framework chamada RAGVAL, um agente chamado StackRAG,","cobertura, coerência, correção funcional, custo, precisão, produtividade, qualidade, recall, redução de esforço, segurança","O uso da IA associada a técnica RAG permitirá o feedback em tempo real em ambientes ágeis (o que é essencial para a metodologia vista que ela é baseada em ciclos curtos que exigem rápida resposta) como consequência teremos a melhoria contínua da qualidade do software, uma redução de esforço humano em avaliação e um maior alinhamento entre IA e os objetivos do sprint.","A escassez de estudos que trazem metodologias de avaliação ao uso de LLMs utilizando RAG em metodologias ágeis, como essa associação ainda é pouco explorada existe uma dificuldade em medir desempenho em tempo real e com isso pouca maturidade de frameworks específicos para metodologias ágeis.; 
As LLMs são limitadas pela sua incapacidade de acessar informações em tempo real ou específicas de um domínio, reduzindo sua adaptabilidade em ambientes dinâmicos, porém o RAG supera esse problema.","A lacuna e consecutivamente a oportunidade de pesquisa foi justamente a percepção de que ao utilizar LLMs em conjunto com metodologias ágeis, os LLMs não são capazes de suprir a necessidade de feedback continuo das metodologias ágeis por sua natureza estática e monolitica, os autores perceberam que ao introduzir a técnica RAG de IA que permite um consulta externa a fontes confiáveis, essa lacuna poderia ser preenchida. O trabalho busca então procurar por outros trabalhos que tragam a intersecção entre esses temas e que tragam frameworks de avaliação de RAG com o intuito de avaliar como que a técnica RAG poderia ser inserida a um ambiente de desenvolvimento ágil.","Os autores destacam como o escopo do estudo limita a abrangência (a pesquisa se limitou a base de dados do IEEE Xplore) eles ressaltam que trabalhos futuros devem ampliar as fontes utilizadas como por exemplo utilizar a  ACM ou o Springer para investigar como os agentes de avaliação melhoram a adaptabilidade dos RAGs em contextos ágeis. Eles desenvolveram a seguinte pergunta de pesquisa futura: Qual o papel dos agentes de avaliação na melhoria da adaptabilidade dos sistemas RAG em ambientes ágeis? Além disso, eles destacam que trabalhos futuros devem se concentrar em testes empíricos dos frameworks adaptados em ambientes ágeis reais e no desenvolvimento de novos frameworks personalizados especificamente para os desafios únicos da integração de sistemas RAG com princípios ágeis.","Como os frameworks atuais não permitem um feedback em tempo real e uma avaliação contínua existe a necessidade de criação de novos frameworks que preencham essa lacuna e isso por si só é um desafio (ou com outro olhar, uma oportunidade) a se superar, o tema por si só apresenta novas oportunidades por se tratar de um assunto ainda pouco explorado onde esse artigo permitiu visualizar um panorama do tema.",";
O artigo também dá um detalhamento sobre o que é um método ágil e como dá para usar o RAG para realizar isso.","""Integrating RAG and multi-agent systems into Agile workflows can close  feedback loops, enhance collaboration, and boost product quality through continuous, context-aware adaptation""
""However, most Gen-AI tools or systems have a lot of knowledge which is static and monolithic, it can’t easily learn new things or explain where the information is from to meet the needs of dynamic environments.""
""Future work should focus on empirical testing of the adapted frameworks in real world Agile environments and the development of new frameworks tailored specifically to the unique challenges of integrating RAG systems with Agile principles."""
